{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c32a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\abhi\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cce974",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_meta = 'dataset.json'\n",
    "\n",
    "file_meta = open(path_meta)\n",
    "data_meta = json.loads(file_meta.read())\n",
    "file_meta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82bef1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'description',\n",
       " 'reference',\n",
       " 'licence',\n",
       " 'release',\n",
       " 'tensorImageSize',\n",
       " 'modality',\n",
       " 'labels',\n",
       " 'numTraining',\n",
       " 'numTest',\n",
       " 'training',\n",
       " 'test']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(data_meta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ad47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [current_sample['image'] for current_sample in data_meta['training'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f81076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [current_sample['label'] for current_sample in data_meta['training'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebf183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [current_sample for current_sample in data_meta['test'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c093dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nib.load(path_dummy_im).get_fdata()\n",
    "shape_list = []\n",
    "for current_sample in data_meta['training']:\n",
    "    shape_list.append(list(nib.load(current_sample['image']).get_fdata().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95a324b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list_np = np.array(shape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "639f6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ee3142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(shape_list_np[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1510221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(shape_list_np[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3cb54bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(shape_list_np[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9e3332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49,  66,  43,  41,  50,  47,  49,  37,  37,  36,  36,  45,  39,\n",
       "        43,  56,  59,  52,  49,  40,  43,  39, 108,  60, 138,  45,  44,\n",
       "        45,  41,  86,  26,  41,  34,  30,  42,  38,  33,  37,  42,  40,\n",
       "        39,  49,  40,  40,  49,  37,  44,  37,  39,  47,  92,  45,  54,\n",
       "        50,  54,  45,  36,  38,  39,  56,  47,  45,  45,  36,  41,  41,\n",
       "       154,  45,  37,  46,  37,  45,  49,  42,  49,  32,  44,  37,  39,\n",
       "        37,  53,  43,  39,  55,  52,  45,  81,  48,  59,  48,  55,  44,\n",
       "        44,  53, 117,  50,  46, 144,  50,  50,  48,  58,  58,  51, 177,\n",
       "        52,  42,  54,  46,  46,  39,  36,  30,  81,  61, 107,  54, 151,\n",
       "       121, 105,  32,  82,  36,  43,  32,  53,  71,  31,  46,  40,  54,\n",
       "       102,  42,  34,  38,  44,  60,  30,  52,  30,  47,  47,  95,  82,\n",
       "       105,  88, 164,  52, 174,  99,  52,  47,  50, 164,  37,  49,  99,\n",
       "        45,  41,  42,  34,  45,  40,  51,  52,  38,  32,  45, 104, 171,\n",
       "        35,  34,  65,  24,  24, 131, 146,  51, 127,  63, 161,  51,  41,\n",
       "        51,  51, 148, 141,  47, 158, 131,  35, 174,  83, 145,  27,  30,\n",
       "        40, 164, 164,  26,  45, 143,  44, 168,  41,  48, 144,  38,  35,\n",
       "       121, 141,  47,  45,  58, 144, 151,  43,  37,  52, 161, 120,  41,\n",
       "        44,  49, 174, 154, 109,  55,  49,  42, 141,  49,  99, 155, 136,\n",
       "        30, 171,  56,  24, 141,  47,  50, 114,  40,  44,  89, 151,  43,\n",
       "       105,  80, 141, 178,  38, 161,  50, 181, 158,  61,  42, 151,  47,\n",
       "        47,  55,  53, 161,  34, 131,  49,  30, 148,  33, 144,  49, 138,\n",
       "       134,  37, 152,  41, 134,  47,  27, 134,  34,  30, 134,  48, 148,\n",
       "        34,  55, 138,  52,  97,  49,  48, 128,  87, 168,  47,  50,  50,\n",
       "        31,  47, 114, 169])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_list_np[:,  -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7d4512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(shape_list_np[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05f0e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.702970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.876379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  303.000000\n",
       "mean    69.702970\n",
       "std     43.876379\n",
       "min     24.000000\n",
       "25%     41.000000\n",
       "50%     49.000000\n",
       "75%     93.500000\n",
       "max    181.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffb6faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d857adc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0     49\n",
       "1     66\n",
       "2     43\n",
       "3     41\n",
       "4     50\n",
       "..   ...\n",
       "298   50\n",
       "299   31\n",
       "300   47\n",
       "301  114\n",
       "302  169\n",
       "\n",
       "[303 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae53100b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.487119366686363"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([np.random.rand() for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9969feb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.438976"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19**3 / 25**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f04eb325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[0] < 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c80d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nib.load(data_meta['training'][0]['label']).get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238ffd49-9902-4295-b28c-78c7dbf46699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6866150086\n",
      "5607115\n",
      "347759\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.where(a==0)))\n",
    "print(np.sum(np.where(a==1)))\n",
    "print(np.sum(np.where(a==2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d0fd482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:\t\t5242880\n",
      "\n",
      "\t\t0.000000\n",
      "\t\t1.000000\n",
      "\t\t0.000000\n",
      "\n",
      "\t\t0.000000\n",
      "\t\t1.000000\n",
      "\t\t0.000000\n",
      "\n",
      "count:\t5242880\n",
      "5242880\n",
      "0\n",
      "this\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\AppData\\Local\\Temp/ipykernel_16020/1074060611.py:22: RuntimeWarning: overflow encountered in long_scalars\n",
      "  count = count * count\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'current_weight' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16020/1074060611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mgeneralized_dice_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16020/1074060611.py\u001b[0m in \u001b[0;36mgeneralized_dice_loss\u001b[1;34m(im_real, im_pred, eps)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;31m# if current_weight == np.inf:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m#     current_weight = 1e-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'current_weight:\\t{current_weight}\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'current_weight' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def generalized_dice_loss(im_real, im_pred, eps = 1e-12):\n",
    "    im_real = np.array(im_real, dtype=np.double)\n",
    "    im_pred = np.array(im_pred, dtype=np.double)\n",
    "    \n",
    "    total_voxels = im_real.shape[0] * im_real.shape[1] * im_real.shape[2]\n",
    "    \n",
    "    print(f'total:\\t\\t{total_voxels}\\n')\n",
    "    [print(f'\\t\\t{(np.sum(np.where(im_real == index, 1, 0)) / total_voxels):.6f}') for index in range(3)]\n",
    "    print()\n",
    "    [print(f'\\t\\t{(np.sum(np.where(im_pred == index, 1, 0)) / total_voxels):.6f}') for index in range(3)]\n",
    "    print()\n",
    "    \n",
    "    weights = np.zeros(3)\n",
    "    for index in range(3):\n",
    "        if index == 1:\n",
    "            count = np.sum(np.where(im_real == index, 1, 0))\n",
    "            print(f'count:\\t{count}')\n",
    "            if count == 0:\n",
    "                current_weight = 1\n",
    "            else:\n",
    "                print(count)\n",
    "                count = count * count\n",
    "                print(count)\n",
    "                print('this')\n",
    "                print((np.power(count, 2)))\n",
    "                # if current_weight == np.inf:\n",
    "                #     current_weight = 1e-2\n",
    "            print(f'current_weight:\\t{current_weight}\\n')\n",
    "            weights[index] = current_weight\n",
    "    \n",
    "#     print(f'weights:\\t{weights}')\n",
    "    \n",
    "#     numerator = [np.sum(np.where(im_real==index, 1, 0) * np.where(im_pred==index, 1, 0)) * weights[index] for index in range(3)]\n",
    "#     print(numerator)\n",
    "    \n",
    "#     denominator = [np.sum(np.where(im_real==index, 1, 0) + np.where(im_pred==index, 1, 0)) + weights[index] for index in range(3)]\n",
    "#     print(denominator)\n",
    "    \n",
    "#     return 1 - ((2 * sum(numerator)) / (sum(denominator) + eps))\n",
    "    \n",
    "a = nib.load(data_meta['training'][0]['label']).get_fdata()[:, :, :20]\n",
    "b = nib.load(data_meta['training'][1]['label']).get_fdata()[:, :, :20]\n",
    "\n",
    "a = np.ones_like(a)\n",
    "b = a.copy()\n",
    "\n",
    "generalized_dice_loss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb56d5-57a7-4b9e-ade8-fe83adffdacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf53bc-d745-4b70-836e-05fd867f17e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27487790694400"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = 5242880\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(tensor):\n",
    "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
    "    The shapes are transformed as follows:\n",
    "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
    "    \"\"\"\n",
    "    # number of channels\n",
    "    C = tensor.size(1)\n",
    "    # new axis order\n",
    "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
    "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
    "    transposed = tensor.permute(axis_order)\n",
    "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
    "    return transposed.contiguous().view(C, -1)\n",
    "\n",
    "class _AbstractDiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for different implementations of Dice loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight=None, normalization='sigmoid'):\n",
    "        super(_AbstractDiceLoss, self).__init__()\n",
    "        self.register_buffer('weight', weight)\n",
    "        # The output from the network during training is assumed to be un-normalized probabilities and we would\n",
    "        # like to normalize the logits. Since Dice (or soft Dice in this case) is usually used for binary data,\n",
    "        # normalizing the channels with Sigmoid is the default choice even for multi-class segmentation problems.\n",
    "        # However if one would like to apply Softmax in order to get the proper probability distribution from the\n",
    "        # output, just specify `normalization=Softmax`\n",
    "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
    "        if normalization == 'sigmoid':\n",
    "            self.normalization = nn.Sigmoid()\n",
    "        elif normalization == 'softmax':\n",
    "            self.normalization = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            self.normalization = lambda x: x\n",
    "\n",
    "    def dice(self, input, target):\n",
    "        # actual Dice score computation; to be implemented by the subclass\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # get probabilities from logits\n",
    "        input = self.normalization(input)\n",
    "\n",
    "        # compute per channel Dice coefficient\n",
    "        per_channel_dice = self.dice(input, target)\n",
    "\n",
    "        # average Dice score across all channels/classes\n",
    "        return 1. - torch.mean(per_channel_dice)\n",
    "\n",
    "class GeneralizedDiceLoss(_AbstractDiceLoss):\n",
    "    \"\"\"Computes Generalized Dice Loss (GDL) as described in https://arxiv.org/pdf/1707.03237.pdf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalization='sigmoid', epsilon=1e-6):\n",
    "        super().__init__(weight=None, normalization=normalization)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def dice(self, input, target):\n",
    "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "\n",
    "        input = flatten(input)\n",
    "        target = flatten(target)\n",
    "        target = target.float()\n",
    "\n",
    "        if input.size(0) == 1:\n",
    "            # for GDL to make sense we need at least 2 channels (see https://arxiv.org/pdf/1707.03237.pdf)\n",
    "            # put foreground and background voxels in separate channels\n",
    "            input = torch.cat((input, 1 - input), dim=0)\n",
    "            target = torch.cat((target, 1 - target), dim=0)\n",
    "\n",
    "        # GDL weighting: the contribution of each label is corrected by the inverse of its volume\n",
    "        w_l = target.sum(-1)\n",
    "        w_l = 1 / (w_l * w_l).clamp(min=self.epsilon)\n",
    "        w_l.requires_grad = False\n",
    "\n",
    "        intersect = (input * target).sum(-1)\n",
    "        intersect = intersect * w_l\n",
    "\n",
    "        denominator = (input + target).sum(-1)\n",
    "        denominator = (denominator * w_l).clamp(min=self.epsilon)\n",
    "\n",
    "        return 2 * (intersect.sum() / denominator.sum())\n",
    "    \n",
    "criterion_dice = GeneralizedDiceLoss().dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a72b1-62d1-4611-bc7d-b21cb1039596",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_dice(torch.tensor(np.ones_like(a)-0.5), torch.tensor(np.ones_like(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d3da5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nib.load(data_meta['training'][0]['label']).get_fdata()[:, :, :20]\n",
    "b = nib.load(data_meta['training'][1]['label']).get_fdata()[:, :, :20]\n",
    "\n",
    "criterion_dice(torch.tensor(a), torch.tensor(b)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19fbb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:\t\t5242880\n",
      "\n",
      "\t\t0.000000\n",
      "\t\t1.000000\n",
      "\t\t0.000000\n",
      "\n",
      "\t\t0.000000\n",
      "\t\t1.000000\n",
      "\t\t0.000000\n",
      "\n",
      "count:\t5242880\n",
      "5242880\n",
      "0\n",
      "this\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\AppData\\Local\\Temp/ipykernel_16020/1074060611.py:22: RuntimeWarning: overflow encountered in long_scalars\n",
      "  count = count * count\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'current_weight' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16020/395086293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgeneralized_dice_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16020/1074060611.py\u001b[0m in \u001b[0;36mgeneralized_dice_loss\u001b[1;34m(im_real, im_pred, eps)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;31m# if current_weight == np.inf:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m#     current_weight = 1e-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'current_weight:\\t{current_weight}\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'current_weight' referenced before assignment"
     ]
    }
   ],
   "source": [
    "generalized_dice_loss(torch.tensor(np.ones_like(a)), torch.tensor(np.ones_like(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "54bf312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(tensor):\n",
    "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
    "    The shapes are transformed as follows:\n",
    "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
    "    \"\"\"\n",
    "    # number of channels\n",
    "    C = tensor.size(1)\n",
    "    # new axis order\n",
    "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
    "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
    "    transposed = tensor.permute(axis_order)\n",
    "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
    "    return transposed.contiguous().view(C, -1)\n",
    "\n",
    "class GeneralizedDiceLoss():\n",
    "    \"\"\"Computes Generalized Dice Loss (GDL) as described in https://arxiv.org/pdf/1707.03237.pdf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalization='sigmoid', epsilon=1e-6):\n",
    "        # super().__init__(weight=None, normalization=normalization)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def dice(self, input, target):\n",
    "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "\n",
    "        input = flatten(input)\n",
    "        target = flatten(target)\n",
    "        target = target.float()\n",
    "\n",
    "        if input.size(0) == 1:\n",
    "            # for GDL to make sense we need at least 2 channels (see https://arxiv.org/pdf/1707.03237.pdf)\n",
    "            # put foreground and background voxels in separate channels\n",
    "            input = torch.cat((input, 1 - input), dim=0)\n",
    "            target = torch.cat((target, 1 - target), dim=0)\n",
    "\n",
    "        # GDL weighting: the contribution of each label is corrected by the inverse of its volume\n",
    "        w_l = target.sum(-1)\n",
    "        w_l = 1 / (w_l * w_l).clamp(min=self.epsilon)\n",
    "        w_l.requires_grad = False\n",
    "\n",
    "        intersect = (input * target).sum(-1)\n",
    "        intersect = intersect * w_l\n",
    "\n",
    "        denominator = (input + target).sum(-1)\n",
    "        denominator = (denominator * w_l).clamp(min=self.epsilon)\n",
    "\n",
    "        return 2 * (intersect.sum() / denominator.sum())\n",
    "    \n",
    "criterion_dice = GeneralizedDiceLoss().dice\n",
    "\n",
    "criterion_dice(torch.tensor(a), torch.tensor(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = torch.tensor(a).unsqueeze(0)\n",
    "# batch_size, height, width, depth = images.shape\n",
    "# print(images.shape)\n",
    "\n",
    "# patch_size_normal = 25\n",
    "# patch_size_low = 19\n",
    "# patch_size_out = 9\n",
    "# patch_low_factor = 3\n",
    "# patch_size_low_up = patch_size_low * patch_low_factor\n",
    "\n",
    "# padding_amount = (patch_size_low_up - 1) // 2\n",
    "\n",
    "# height_new = height+patch_size_low_up+paddint_amount+1\n",
    "# width_new = width+patch_size_low_up+paddint_amount+1\n",
    "# depth_new = depth+patch_size_low_up+paddint_amount+1\n",
    "\n",
    "# images_expanded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32)\n",
    "# print(images_expanded.shape)\n",
    "# print()\n",
    "# images_reconstructed = torch.zeros_like(images)\n",
    "\n",
    "# for index_h in range(0)\n",
    "\n",
    "\n",
    "# height_start_orig = 0\n",
    "# height_end_orig = patch_size_out\n",
    "# for index_h in range(0, height+patch_size_out*4, patch_size_out):\n",
    "    \n",
    "#     height_start = index_h\n",
    "#     height_end = index_h+patch_size_low_up+1\n",
    "    \n",
    "#     print(f'{height_start} - {height_end}', end='\\t\\t')\n",
    "#     print(f'{height_start_orig} - {height_end_orig}')\n",
    "    \n",
    "#     height_start_orig = height_start_orig + patch_size_out + 1\n",
    "#     height_end_orig = height_end_orig + patch_size_out + 1\n",
    "    \n",
    "    \n",
    "# #     for index_w in range(paddint_amount, width+patch_size_low_up, patch_size_low_up):\n",
    "# #         width_start = index_w\n",
    "# #         width_end = index_w+patch_size_low_up+1\n",
    "# #         print(f'\\t{index_w} - {width_end}')\n",
    "        \n",
    "# #         for index_d in range(paddint_amount, depth+patch_size_low_up, patch_size_low_up):\n",
    "# #             depth_start = index_d\n",
    "# #             depth_end = index_d+patch_size_low_up+1\n",
    "# #             print(f'\\t\\t{index_d} - {depth_end}')\n",
    "            \n",
    "# #             images_reconstructed[:, height_start:height_end]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "aeeacce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512, 20])\n",
      "torch.Size([1, 569, 569, 77])\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import cv2\n",
    "\n",
    "# images = torch.tensor(a).unsqueeze(0)\n",
    "\n",
    "images = torch.tensor(a).unsqueeze(0)\n",
    "\n",
    "batch_size, height, width, depth = images.shape\n",
    "print(images.shape)\n",
    "\n",
    "patch_size_normal = 25\n",
    "patch_size_low = 19\n",
    "patch_size_out = 9\n",
    "patch_low_factor = 3\n",
    "patch_size_low_up = patch_size_low * patch_low_factor\n",
    "\n",
    "patch_half_normal = (patch_size_normal - 1) // 2\n",
    "patch_half_low_up = (patch_size_low_up - 1) // 2\n",
    "patch_half_out = (patch_size_out - 1) // 2\n",
    "\n",
    "height_new = height + patch_size_low_up\n",
    "width_new = width + patch_size_low_up\n",
    "depth_new = depth + patch_size_low_up\n",
    "\n",
    "# create a placeholder for the padded image\n",
    "images_expanded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32)\n",
    "\n",
    "# copy the original image to the placeholder\n",
    "images_expanded[:,\n",
    "                patch_half_low_up: height+patch_half_low_up, \n",
    "                patch_half_low_up: width+patch_half_low_up, \n",
    "                patch_half_low_up: depth+patch_half_low_up\n",
    "               ] = copy.deepcopy(images)\n",
    "\n",
    "print(images_expanded.shape)\n",
    "print()\n",
    "\n",
    "images_reconstructed = torch.zeros_like(images)\n",
    "\n",
    "# indices of the original image\n",
    "h_start_orig = 0\n",
    "h_end_orig = h_start_orig + patch_size_out\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "loss_total = 0\n",
    "\n",
    "for index_h in range(patch_half_low_up+patch_half_out, height_new - patch_half_out, patch_size_out):\n",
    "    \n",
    "    h_start_normal = index_h - patch_half_normal\n",
    "    h_end_normal = index_h + patch_half_normal + 1\n",
    "    \n",
    "    h_start_low_up = index_h - patch_half_low_up\n",
    "    h_end_low_up = index_h + patch_half_low_up + 1\n",
    "    \n",
    "    h_start_out = index_h - patch_half_out\n",
    "    h_end_out = index_h + patch_half_out + 1\n",
    "    \n",
    "    if h_end_out > height_new:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "    print(i)\n",
    "#     print(f'h_low_up:\\t{h_start_low_up}\\t-\\t{h_end_low_up}')\n",
    "#     print(f'\\th_normal:\\t{h_start_normal}\\t-\\t{h_end_normal}')    \n",
    "#     print(f'\\t\\th_out:\\t{h_start_out}\\t-\\t{h_end_out}')\n",
    "\n",
    "    w_start_orig = 0\n",
    "    w_end_orig = w_start_orig + patch_size_out\n",
    "\n",
    "    for index_w in range(patch_half_low_up+patch_half_out, width_new - patch_half_out, patch_size_out):\n",
    "\n",
    "        w_start_normal = index_w - patch_half_normal\n",
    "        w_end_normal = index_w + patch_half_normal + 1\n",
    "\n",
    "        w_start_low_up = index_w - patch_half_low_up\n",
    "        w_end_low_up = index_w + patch_half_low_up + 1\n",
    "\n",
    "        w_start_out = index_w - patch_half_out\n",
    "        w_end_out = index_w + patch_half_out + 1\n",
    "\n",
    "        if w_end_out > width_new:\n",
    "            break\n",
    "\n",
    "        # print(f'w_low_up:\\t{w_start_low_up}\\t-\\t{w_end_low_up}')\n",
    "        # print(f'\\tw_normal:\\t{w_start_normal}\\t-\\t{w_end_normal}')    \n",
    "#         print(f'\\t\\tw_out:\\t{w_start_out}\\t-\\t{w_end_out}')\n",
    "        \n",
    "        d_start_orig = 0\n",
    "        d_end_orig = d_start_orig + patch_size_out\n",
    "\n",
    "        for index_d in range(patch_half_low_up+patch_half_out, depth_new - patch_half_out, patch_size_out):\n",
    "\n",
    "            d_start_normal = index_d - patch_half_normal\n",
    "            d_end_normal = index_d + patch_half_normal + 1\n",
    "\n",
    "            d_start_low_up = index_d - patch_half_low_up\n",
    "            d_end_low_up = index_d + patch_half_low_up + 1\n",
    "\n",
    "            d_start_out = index_d - patch_half_out\n",
    "            d_end_out = index_d + patch_half_out + 1\n",
    "\n",
    "            if d_end_out > depth_new:\n",
    "                break\n",
    "\n",
    "            # print(f'd_low_up:\\t{d_start_low_up}\\t-\\t{d_end_low_up}')\n",
    "            # print(f'\\td_normal:\\t{d_start_normal}\\t-\\t{d_end_normal}')    \n",
    "            # print(f'\\t\\td_out:\\t{d_start_out}\\t-\\t{d_end_out}')\n",
    "            \n",
    "            # extract the current patch of the original image\n",
    "            patch_original = images[:, h_start_orig: h_end_orig, w_start_orig: w_end_orig, d_start_orig: d_end_orig]\n",
    "            \n",
    "            # extract the current patch of the expanded image\n",
    "            patch_out = images_expanded[:, h_start_out: h_end_out, w_start_out: w_end_out, d_start_out: d_end_out]\n",
    "            \n",
    "                \n",
    "#             print(patch_original.shape)\n",
    "#             print(patch_out.shape)\n",
    "            \n",
    "            # clip extra patrs            \n",
    "            if patch_original.shape[1] < patch_size_out:\n",
    "                patch_out = patch_out[:, :patch_original.shape[1], :, :]\n",
    "            \n",
    "            if patch_original.shape[2] < patch_size_out:\n",
    "                patch_out = patch_out[:, :, :patch_original.shape[2], :]\n",
    "                \n",
    "            if patch_original.shape[3] < patch_size_out:\n",
    "                patch_out = patch_out[:, :, :, :patch_original.shape[3]]\n",
    "            \n",
    "            # remove any dimensions with 0 elements\n",
    "            if (patch_out.shape[1] == 0) or (patch_out.shape[2] == 0) or (patch_out.shape[3] == 0) or (patch_original.shape[1] == 0) or (patch_original.shape[2] == 0) or (patch_original.shape[3] == 0):\n",
    "                break\n",
    "            \n",
    "            \n",
    "            # recreate the original image\n",
    "            images_reconstructed[\n",
    "                :, \n",
    "                h_start_orig: h_end_orig, \n",
    "                w_start_orig: w_end_orig, \n",
    "                d_start_orig: d_end_orig\n",
    "            ] = copy.deepcopy(patch_out)\n",
    "            \n",
    "            \n",
    "            # print(patch_out.shape)\n",
    "            \n",
    "            loss = torch.mean((patch_original-patch_out))**2\n",
    "            if loss > 0.0:\n",
    "                print('here')\n",
    "                print(loss)\n",
    "                print(patch_original.shape)\n",
    "                print(patch_out.shape)\n",
    "            \n",
    "#             print(loss.item())\n",
    "            loss_total += loss\n",
    "            \n",
    "            d_start_orig = d_start_orig + patch_size_out\n",
    "            d_end_orig = d_end_orig + patch_size_out\n",
    "        \n",
    "        w_start_orig = w_start_orig + patch_size_out\n",
    "        w_end_orig = w_end_orig + patch_size_out\n",
    "#         print(loss.item())\n",
    "        \n",
    "    h_start_orig = h_start_orig + patch_size_out\n",
    "    h_end_orig = h_end_orig + patch_size_out\n",
    "#     print(loss.item())\n",
    "    \n",
    "\n",
    "print(loss_total)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "bb53c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((images - images_reconstructed)**2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "af0607ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((images_expanded[:,\n",
    "                patch_half_low_up: height+patch_half_low_up, \n",
    "                patch_half_low_up: width+patch_half_low_up, \n",
    "                patch_half_low_up: depth+patch_half_low_up\n",
    "               ]+0.25 - images)**2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041145f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((images_expanded[:,\n",
    "                patch_half_low_up: height+patch_half_low_up, \n",
    "                patch_half_low_up: width+patch_half_low_up, \n",
    "                patch_half_low_up: depth+patch_half_low_up\n",
    "               ]+0.25 - images)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "path_meta = 'dataset.json'\n",
    "\n",
    "file_meta = open(path_meta)\n",
    "data_meta = json.loads(file_meta.read())\n",
    "file_meta.close()\n",
    "\n",
    "\n",
    "# images = torch.tensor(a).unsqueeze(0)\n",
    "a = nib.load(data_meta['training'][0]['label']).get_fdata()\n",
    "\n",
    "# images = torch.tensor(a).unsqueeze(0)\n",
    "images = torch.tensor(a).unsqueeze(0)[:, 200:256, 200:250]\n",
    "\n",
    "def stride_depth_and_inference(model, optimizer, criterion, images_real, patch_size_normal=25, patch_size_low=19, patch_size_out=9, patch_low_factor=3):\n",
    "\n",
    "    batch_size, height, width, depth = images_real.shape\n",
    "\n",
    "    # --------- loop through the whole image volume\n",
    "    patch_size_low_up = patch_size_low * patch_low_factor\n",
    "\n",
    "    patch_half_normal = (patch_size_normal - 1) // 2\n",
    "    patch_half_low_up = (patch_size_low_up - 1) // 2\n",
    "    patch_half_out = (patch_size_out - 1) // 2\n",
    "\n",
    "    height_new = height + patch_size_low_up\n",
    "    width_new = width + patch_size_low_up\n",
    "    depth_new = depth + patch_size_low_up\n",
    "\n",
    "    # create a placeholder for the padded image\n",
    "    images_padded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32)\n",
    "\n",
    "    # copy the original image to the placeholder\n",
    "    images_padded[\n",
    "        :,\n",
    "        patch_half_low_up: height + patch_half_low_up,\n",
    "        patch_half_low_up: width + patch_half_low_up,\n",
    "        patch_half_low_up: depth + patch_half_low_up\n",
    "    ] = copy.deepcopy(images_real)\n",
    "\n",
    "    # placeholder to store the inferred/reconstructed image labels\n",
    "    labels_pred = torch.zeros_like(images_real)\n",
    "\n",
    "    # indices of the original image\n",
    "    h_start_orig = 0\n",
    "    h_end_orig = h_start_orig + patch_size_out\n",
    "\n",
    "    for index_h in range(patch_half_low_up + patch_half_out, height_new - patch_half_out, patch_size_out):\n",
    "\n",
    "        h_start_normal = index_h - patch_half_normal\n",
    "        h_end_normal = index_h + patch_half_normal + 1\n",
    "\n",
    "        h_start_low_up = index_h - patch_half_low_up\n",
    "        h_end_low_up = index_h + patch_half_low_up + 1\n",
    "\n",
    "        h_start_out = index_h - patch_half_out\n",
    "        h_end_out = index_h + patch_half_out + 1\n",
    "\n",
    "        if h_end_out > height_new:\n",
    "            break\n",
    "\n",
    "        w_start_orig = 0\n",
    "        w_end_orig = w_start_orig + patch_size_out\n",
    "\n",
    "        for index_w in range(patch_half_low_up + patch_half_out, width_new - patch_half_out, patch_size_out):\n",
    "\n",
    "            w_start_normal = index_w - patch_half_normal\n",
    "            w_end_normal = index_w + patch_half_normal + 1\n",
    "\n",
    "            w_start_low_up = index_w - patch_half_low_up\n",
    "            w_end_low_up = index_w + patch_half_low_up + 1\n",
    "\n",
    "            w_start_out = index_w - patch_half_out\n",
    "            w_end_out = index_w + patch_half_out + 1\n",
    "\n",
    "            if w_end_out > width_new:\n",
    "                break\n",
    "\n",
    "            d_start_orig = 0\n",
    "            d_end_orig = d_start_orig + patch_size_out\n",
    "\n",
    "            for index_d in range(patch_half_low_up + patch_half_out, depth_new - patch_half_out,\n",
    "                                 patch_size_out):\n",
    "\n",
    "                d_start_normal = index_d - patch_half_normal\n",
    "                d_end_normal = index_d + patch_half_normal + 1\n",
    "\n",
    "                d_start_low_up = index_d - patch_half_low_up\n",
    "                d_end_low_up = index_d + patch_half_low_up + 1\n",
    "\n",
    "                d_start_out = index_d - patch_half_out\n",
    "                d_end_out = index_d + patch_half_out + 1\n",
    "\n",
    "                if d_end_out > depth_new:\n",
    "                    break\n",
    "\n",
    "                # extract the current patch of the original image\n",
    "                patch_original = images_real[:, h_start_orig: h_end_orig, w_start_orig: w_end_orig,\n",
    "                                 d_start_orig: d_end_orig]\n",
    "\n",
    "                # extract the current patch of the expanded image\n",
    "                patch_out = images_padded[:, h_start_out: h_end_out, w_start_out: w_end_out,\n",
    "                            d_start_out: d_end_out]\n",
    "\n",
    "                # clip extra patrs\n",
    "                if patch_original.shape[1] < patch_size_out:\n",
    "                    patch_out = patch_out[:, :patch_original.shape[1], :, :]\n",
    "\n",
    "                if patch_original.shape[2] < patch_size_out:\n",
    "                    patch_out = patch_out[:, :, :patch_original.shape[2], :]\n",
    "\n",
    "                if patch_original.shape[3] < patch_size_out:\n",
    "                    patch_out = patch_out[:, :, :, :patch_original.shape[3]]\n",
    "\n",
    "                # remove any dimensions with 0 elements\n",
    "                if (patch_out.shape[1] == 0) or (patch_out.shape[2] == 0) or (patch_out.shape[3] == 0) or (\n",
    "                        patch_original.shape[1] == 0) or (patch_original.shape[2] == 0) or (\n",
    "                        patch_original.shape[3] == 0):\n",
    "                    break\n",
    "\n",
    "                labels_pred[\n",
    "                    :,\n",
    "                    h_start_orig: h_end_orig,\n",
    "                    w_start_orig: w_end_orig,\n",
    "                    d_start_orig: d_end_orig\n",
    "                ] = copy.deepcopy(patch_out)\n",
    "\n",
    "                d_start_orig = d_start_orig + patch_size_out\n",
    "                d_end_orig = d_end_orig + patch_size_out\n",
    "\n",
    "            w_start_orig = w_start_orig + patch_size_out\n",
    "            w_end_orig = w_end_orig + patch_size_out\n",
    "\n",
    "        h_start_orig = h_start_orig + patch_size_out\n",
    "        h_end_orig = h_end_orig + patch_size_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "e54540c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 57, 57, 57])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "low_up = torch.rand((1, 1, 57, 57, 57))\n",
    "F.interpolate(low_up, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3d9e83d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 19, 19, 19])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.AvgPool3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f7f4a03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "e0da9db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242880,)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.reshape(-1) == 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "90e3ea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242880,)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "fd9139a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.reshape(-1) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ed548028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3701878], dtype=int64)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.where((a.reshape(-1) == 1) == 1)[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "13de2453",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unravel_index() missing required argument 'shape' (pos 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10460/3686208773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munravel_index\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unravel_index() missing required argument 'shape' (pos 2)"
     ]
    }
   ],
   "source": [
    "np.unravel_index(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a176f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375 245   9]\t1.0\n",
      "[345 259  19]\t1.0\n",
      "[341 329  19]\t1.0\n",
      "[364 272  10]\t1.0\n",
      "[370 233  12]\t1.0\n",
      "[355 270  12]\t1.0\n",
      "[361 249  18]\t1.0\n",
      "[375 255  16]\t1.0\n",
      "[349 276  14]\t1.0\n",
      "[367 234  16]\t1.0\n",
      "[361 263  17]\t1.0\n",
      "[350 269  15]\t1.0\n",
      "[368 236  15]\t1.0\n",
      "[368 234  15]\t1.0\n",
      "[365 277  13]\t1.0\n",
      "[371 263  19]\t1.0\n",
      "[339 327  19]\t1.0\n",
      "[373 249  10]\t1.0\n",
      "[345 333  15]\t1.0\n",
      "[343 330  16]\t1.0\n",
      "[352 317  17]\t1.0\n",
      "[350 264  17]\t1.0\n",
      "[354 268  13]\t1.0\n",
      "[364 251  16]\t1.0\n",
      "[344 259  18]\t1.0\n",
      "[361 263  17]\t1.0\n",
      "[362 267  16]\t1.0\n",
      "[351 273  14]\t1.0\n",
      "[363 270  17]\t1.0\n",
      "[366 281  12]\t1.0\n",
      "[355 271  18]\t1.0\n",
      "[354 274  19]\t1.0\n",
      "[375 265   9]\t1.0\n",
      "[368 236  15]\t1.0\n",
      "[372 258  18]\t1.0\n",
      "[363 250  18]\t1.0\n",
      "[349 267  15]\t1.0\n",
      "[360 249  19]\t1.0\n",
      "[363 252  18]\t1.0\n",
      "[343 332  16]\t1.0\n",
      "[341 329  18]\t1.0\n",
      "[367 249  15]\t1.0\n",
      "[361 286   8]\t1.0\n",
      "[371 250  12]\t1.0\n",
      "[351 264  16]\t1.0\n",
      "[363 268  16]\t1.0\n",
      "[360 286   8]\t1.0\n",
      "[354 269  19]\t1.0\n",
      "[362 266  17]\t1.0\n",
      "[371 221  16]\t1.0\n",
      "[349 276  14]\t1.0\n",
      "[375 232  10]\t1.0\n",
      "[370 264  18]\t1.0\n",
      "[364 271  17]\t1.0\n",
      "[375 255  18]\t1.0\n",
      "[349 277  13]\t1.0\n",
      "[355 298  17]\t1.0\n",
      "[367 265  19]\t1.0\n",
      "[365 281  12]\t1.0\n",
      "[354 269  19]\t1.0\n",
      "[356 272  11]\t1.0\n",
      "[366 233  15]\t1.0\n",
      "[364 232  16]\t1.0\n",
      "[371 261  18]\t1.0\n",
      "[360 251  19]\t1.0\n",
      "[362 265  17]\t1.0\n",
      "[370 226  18]\t1.0\n",
      "[367 228  18]\t1.0\n",
      "[355 296  19]\t1.0\n",
      "[355 270  13]\t1.0\n",
      "[360 253  19]\t1.0\n",
      "[362 284   8]\t1.0\n",
      "[344 260  19]\t1.0\n",
      "[372 222  16]\t1.0\n",
      "[353 268  14]\t1.0\n",
      "[354 271  19]\t1.0\n",
      "[365 280  12]\t1.0\n",
      "[362 251  19]\t1.0\n",
      "[362 249  18]\t1.0\n",
      "[357 299  18]\t1.0\n",
      "[369 221  17]\t1.0\n",
      "[367 232  16]\t1.0\n",
      "[370 253  13]\t1.0\n",
      "[369 226  18]\t1.0\n",
      "[353 273  18]\t1.0\n",
      "[367 229  18]\t1.0\n",
      "[347 261  18]\t1.0\n",
      "[374 243   9]\t1.0\n",
      "[370 235  13]\t1.0\n",
      "[376 269   8]\t1.0\n",
      "[355 268  12]\t1.0\n",
      "[374 248  11]\t1.0\n",
      "[347 257  18]\t1.0\n",
      "[363 252  18]\t1.0\n",
      "[367 228  18]\t1.0\n",
      "[364 231  18]\t1.0\n",
      "[355 269  13]\t1.0\n",
      "[319 332  19]\t1.0\n",
      "[342 330  17]\t1.0\n",
      "[365 234  18]\t1.0\n",
      "[361 251  18]\t1.0\n",
      "[357 296  18]\t1.0\n",
      "[358 251  19]\t1.0\n",
      "[370 265  18]\t1.0\n",
      "[361 264  17]\t1.0\n",
      "[354 268  13]\t1.0\n",
      "[354 267  19]\t1.0\n",
      "[357 299  18]\t1.0\n",
      "[347 265  17]\t1.0\n",
      "[372 261  18]\t1.0\n",
      "[356 268  12]\t1.0\n",
      "[352 270  15]\t1.0\n",
      "[351 276  14]\t1.0\n",
      "[362 233  19]\t1.0\n",
      "[353 270  14]\t1.0\n",
      "[358 253  19]\t1.0\n",
      "[352 317  17]\t1.0\n",
      "[363 270  15]\t1.0\n",
      "[347 255  17]\t1.0\n",
      "[369 251  15]\t1.0\n",
      "[368 230  18]\t1.0\n",
      "[355 270  13]\t1.0\n",
      "[376 254  16]\t1.0\n",
      "[340 327  19]\t1.0\n",
      "[366 249  16]\t1.0\n",
      "[362 269  15]\t1.0\n",
      "[344 333  16]\t1.0\n",
      "[352 267  15]\t1.0\n",
      "[348 275  14]\t1.0\n",
      "[351 276  14]\t1.0\n",
      "[349 267  15]\t1.0\n",
      "[357 300  16]\t1.0\n",
      "[357 252  19]\t1.0\n",
      "[364 268  16]\t1.0\n",
      "[375 255  18]\t1.0\n",
      "[356 297  18]\t1.0\n",
      "[369 254  12]\t1.0\n",
      "[347 256  18]\t1.0\n",
      "[368 226  18]\t1.0\n",
      "[365 250  16]\t1.0\n",
      "[367 249  16]\t1.0\n",
      "[369 253  14]\t1.0\n",
      "[374 247  11]\t1.0\n",
      "[370 234  14]\t1.0\n",
      "[349 264  17]\t1.0\n",
      "[355 298  17]\t1.0\n",
      "[364 272   9]\t1.0\n",
      "[359 303  13]\t1.0\n",
      "[350 268  15]\t1.0\n",
      "[370 263  18]\t1.0\n",
      "[374 222  16]\t1.0\n",
      "[370 234  14]\t1.0\n",
      "[363 270  15]\t1.0\n",
      "[361 254  19]\t1.0\n",
      "[361 259  18]\t1.0\n",
      "[357 301  15]\t1.0\n",
      "[364 271  17]\t1.0\n",
      "[349 271  14]\t1.0\n",
      "[365 251  16]\t1.0\n",
      "[366 250  15]\t1.0\n",
      "[363 250  19]\t1.0\n",
      "[360 262  18]\t1.0\n",
      "[343 256  19]\t1.0\n",
      "[360 264  17]\t1.0\n",
      "[344 259  19]\t1.0\n",
      "[374 254  18]\t1.0\n",
      "[366 252  16]\t1.0\n",
      "[357 251  19]\t1.0\n",
      "[364 251  16]\t1.0\n",
      "[359 305  12]\t1.0\n",
      "[346 255  18]\t1.0\n",
      "[365 232  17]\t1.0\n",
      "[369 267  17]\t1.0\n",
      "[363 273  10]\t1.0\n",
      "[352 267  14]\t1.0\n",
      "[342 328  17]\t1.0\n",
      "[365 252  16]\t1.0\n",
      "[356 297  17]\t1.0\n",
      "[369 253  14]\t1.0\n",
      "[371 262  18]\t1.0\n",
      "[350 270  14]\t1.0\n",
      "[350 263  17]\t1.0\n",
      "[368 267  19]\t1.0\n",
      "[370 234  12]\t1.0\n",
      "[370 221  15]\t1.0\n",
      "[346 259  18]\t1.0\n",
      "[365 250  16]\t1.0\n",
      "[366 233  15]\t1.0\n",
      "[367 252  16]\t1.0\n",
      "[350 270  15]\t1.0\n",
      "[352 268  14]\t1.0\n",
      "[372 236  12]\t1.0\n",
      "[364 233  18]\t1.0\n",
      "[363 268  16]\t1.0\n",
      "[357 263  19]\t1.0\n",
      "[361 263  17]\t1.0\n",
      "[361 264  17]\t1.0\n",
      "[340 327  19]\t1.0\n",
      "[339 328  19]\t1.0\n",
      "[346 262  19]\t1.0\n",
      "[363 270  10]\t1.0\n",
      "[366 250  17]\t1.0\n",
      "[359 306  12]\t1.0\n",
      "[364 282  11]\t1.0\n",
      "[370 227  18]\t1.0\n",
      "[368 249  15]\t1.0\n",
      "[357 268  12]\t1.0\n",
      "[371 226  18]\t1.0\n",
      "[361 269  11]\t1.0\n",
      "[368 235  16]\t1.0\n",
      "[352 269  15]\t1.0\n",
      "[369 234  14]\t1.0\n",
      "[348 265  16]\t1.0\n",
      "[364 234  19]\t1.0\n",
      "[362 265  17]\t1.0\n",
      "[363 284   9]\t1.0\n",
      "[375 254  17]\t1.0\n",
      "[355 250  18]\t1.0\n",
      "[368 265  19]\t1.0\n",
      "[360 270  11]\t1.0\n",
      "[351 275  14]\t1.0\n",
      "[349 268  16]\t1.0\n",
      "[367 266  19]\t1.0\n",
      "[354 268  19]\t1.0\n",
      "[346 257  19]\t1.0\n",
      "[370 264  19]\t1.0\n",
      "[356 296  19]\t1.0\n",
      "[373 247  11]\t1.0\n",
      "[365 277  13]\t1.0\n",
      "[346 332  15]\t1.0\n",
      "[363 273  10]\t1.0\n",
      "[354 269  18]\t1.0\n",
      "[354 268  13]\t1.0\n",
      "[374 261  10]\t1.0\n",
      "[370 263  19]\t1.0\n",
      "[356 270  12]\t1.0\n",
      "[361 249  18]\t1.0\n",
      "[369 263  18]\t1.0\n",
      "[347 262  17]\t1.0\n",
      "[372 224  18]\t1.0\n",
      "[368 265  19]\t1.0\n",
      "[361 284   8]\t1.0\n",
      "[359 305  12]\t1.0\n",
      "[353 269  19]\t1.0\n",
      "[376 268   8]\t1.0\n",
      "[357 262  19]\t1.0\n",
      "[370 251  12]\t1.0\n",
      "[366 229  18]\t1.0\n",
      "[373 233  11]\t1.0\n",
      "[348 264  17]\t1.0\n",
      "[362 269  10]\t1.0\n",
      "[372 220  15]\t1.0\n",
      "[355 251  18]\t1.0\n",
      "[356 298  18]\t1.0\n",
      "[351 265  16]\t1.0\n",
      "[345 255  18]\t1.0\n",
      "[349 271  14]\t1.0\n",
      "[350 268  15]\t1.0\n",
      "[372 221  16]\t1.0\n",
      "[369 229  18]\t1.0\n",
      "[347 255  18]\t1.0\n",
      "[354 268  13]\t1.0\n",
      "[364 234  15]\t1.0\n",
      "[369 263  18]\t1.0\n",
      "[358 260  19]\t1.0\n",
      "[361 265  17]\t1.0\n",
      "[357 250  19]\t1.0\n",
      "[353 293  19]\t1.0\n",
      "[372 236  12]\t1.0\n",
      "[354 270  18]\t1.0\n",
      "[371 250  12]\t1.0\n",
      "[364 252  17]\t1.0\n",
      "[370 266  19]\t1.0\n",
      "[366 252  16]\t1.0\n",
      "[366 250  15]\t1.0\n",
      "[370 265  18]\t1.0\n",
      "[352 273  14]\t1.0\n",
      "[345 260  19]\t1.0\n",
      "[358 252  19]\t1.0\n",
      "[353 252  18]\t1.0\n",
      "[365 232  18]\t1.0\n",
      "[356 295  18]\t1.0\n",
      "[375 255  16]\t1.0\n",
      "[353 268  13]\t1.0\n",
      "[355 298  17]\t1.0\n",
      "[361 262  18]\t1.0\n",
      "[375 243   8]\t1.0\n",
      "[375 265   9]\t1.0\n",
      "[362 251  18]\t1.0\n",
      "[350 277  13]\t1.0\n",
      "[355 266  19]\t1.0\n",
      "[349 278  14]\t1.0\n",
      "[368 264  19]\t1.0\n",
      "[369 254  12]\t1.0\n",
      "[345 258  19]\t1.0\n",
      "[364 249  16]\t1.0\n",
      "[366 232  16]\t1.0\n",
      "[351 272  14]\t1.0\n",
      "[350 270  15]\t1.0\n",
      "[360 249  19]\t1.0\n",
      "[357 251  19]\t1.0\n",
      "[343 257  19]\t1.0\n",
      "[349 262  17]\t1.0\n",
      "[371 228  18]\t1.0\n",
      "[376 269   8]\t1.0\n",
      "[350 278  14]\t1.0\n",
      "[372 221  16]\t1.0\n",
      "[361 270  15]\t1.0\n",
      "[362 249  19]\t1.0\n",
      "[364 234  18]\t1.0\n",
      "[366 234  17]\t1.0\n",
      "[349 278  13]\t1.0\n",
      "[365 230  18]\t1.0\n",
      "[356 271  11]\t1.0\n",
      "[374 244   8]\t1.0\n",
      "[349 262  17]\t1.0\n",
      "[369 251  13]\t1.0\n",
      "[360 284   8]\t1.0\n",
      "[355 295  18]\t1.0\n",
      "[350 275  14]\t1.0\n",
      "[351 267  16]\t1.0\n",
      "[343 329  17]\t1.0\n",
      "[354 268  19]\t1.0\n",
      "[367 266  19]\t1.0\n",
      "[354 271  19]\t1.0\n",
      "[369 265  18]\t1.0\n",
      "[370 235  13]\t1.0\n",
      "[353 294  19]\t1.0\n",
      "[365 270  17]\t1.0\n",
      "[365 250  17]\t1.0\n",
      "[372 223  17]\t1.0\n",
      "[371 253  12]\t1.0\n",
      "[353 293  19]\t1.0\n",
      "[348 266  17]\t1.0\n",
      "[362 265  17]\t1.0\n",
      "[345 262  18]\t1.0\n",
      "[368 234  16]\t1.0\n",
      "[363 252  17]\t1.0\n",
      "[348 266  16]\t1.0\n",
      "[363 284   7]\t1.0\n",
      "[345 260  19]\t1.0\n",
      "[373 222  16]\t1.0\n",
      "[359 302  14]\t1.0\n",
      "[372 249  11]\t1.0\n",
      "[350 316  19]\t1.0\n",
      "[375 243   8]\t1.0\n",
      "[374 261  10]\t1.0\n",
      "[366 251  17]\t1.0\n",
      "[345 258  19]\t1.0\n",
      "[365 231  19]\t1.0\n",
      "[347 261  18]\t1.0\n",
      "[370 252  12]\t1.0\n",
      "[344 253  18]\t1.0\n",
      "[362 251  18]\t1.0\n",
      "[363 270  15]\t1.0\n",
      "[365 250  17]\t1.0\n",
      "[357 260  19]\t1.0\n",
      "[371 222  17]\t1.0\n",
      "[371 251  13]\t1.0\n",
      "[344 254  18]\t1.0\n",
      "[366 236  15]\t1.0\n",
      "[349 277  14]\t1.0\n",
      "[362 264  17]\t1.0\n",
      "[347 256  18]\t1.0\n",
      "[372 260  18]\t1.0\n",
      "[365 236  15]\t1.0\n",
      "[357 260  19]\t1.0\n",
      "[353 317  17]\t1.0\n",
      "[349 267  16]\t1.0\n",
      "[360 259  18]\t1.0\n",
      "[363 270  17]\t1.0\n",
      "[360 261  19]\t1.0\n",
      "[365 251  16]\t1.0\n",
      "[377 270   8]\t1.0\n",
      "[364 234  18]\t1.0\n",
      "[365 281  12]\t1.0\n",
      "[365 236  15]\t1.0\n",
      "[358 269  11]\t1.0\n",
      "[365 234  15]\t1.0\n",
      "[362 284   7]\t1.0\n",
      "[358 271  11]\t1.0\n",
      "[343 258  19]\t1.0\n",
      "[363 232  18]\t1.0\n",
      "[344 258  18]\t1.0\n",
      "[359 271  11]\t1.0\n",
      "[352 253  18]\t1.0\n",
      "[351 267  16]\t1.0\n",
      "[354 275  19]\t1.0\n",
      "[368 235  15]\t1.0\n",
      "[364 235  15]\t1.0\n",
      "[356 251  18]\t1.0\n",
      "[373 222  16]\t1.0\n",
      "[364 251  18]\t1.0\n",
      "[361 261  18]\t1.0\n",
      "[365 270  17]\t1.0\n",
      "[366 235  15]\t1.0\n",
      "[357 250  19]\t1.0\n",
      "[357 270  11]\t1.0\n",
      "[351 272  14]\t1.0\n",
      "[361 257  19]\t1.0\n",
      "[361 252  18]\t1.0\n",
      "[370 265  18]\t1.0\n",
      "[355 270  18]\t1.0\n",
      "[374 262  10]\t1.0\n",
      "[359 303  13]\t1.0\n",
      "[348 274  14]\t1.0\n",
      "[359 305  12]\t1.0\n",
      "[366 250  15]\t1.0\n",
      "[362 284   7]\t1.0\n",
      "[348 262  17]\t1.0\n",
      "[371 221  14]\t1.0\n",
      "[347 263  18]\t1.0\n",
      "[359 249  19]\t1.0\n",
      "[344 333  16]\t1.0\n",
      "[346 263  18]\t1.0\n",
      "[373 222  15]\t1.0\n",
      "[360 253  19]\t1.0\n",
      "[371 226  18]\t1.0\n",
      "[346 262  18]\t1.0\n",
      "[373 249  10]\t1.0\n",
      "[357 296  18]\t1.0\n",
      "[371 225  18]\t1.0\n",
      "[354 295  19]\t1.0\n",
      "[359 255  19]\t1.0\n",
      "[357 271  11]\t1.0\n",
      "[353 269  13]\t1.0\n",
      "[370 233  12]\t1.0\n",
      "[373 247  11]\t1.0\n",
      "[356 267  19]\t1.0\n",
      "[350 277  14]\t1.0\n",
      "[350 275  14]\t1.0\n",
      "[370 227  18]\t1.0\n",
      "[355 264  19]\t1.0\n",
      "[367 251  16]\t1.0\n",
      "[357 269  12]\t1.0\n",
      "[369 234  16]\t1.0\n",
      "[360 260  19]\t1.0\n",
      "[364 272  10]\t1.0\n",
      "[374 254  18]\t1.0\n",
      "[362 271  10]\t1.0\n",
      "[374 222  16]\t1.0\n",
      "[375 233  11]\t1.0\n",
      "[351 275  14]\t1.0\n",
      "[368 235  16]\t1.0\n",
      "[352 269  14]\t1.0\n",
      "[364 271  10]\t1.0\n",
      "[364 271  10]\t1.0\n",
      "[349 266  17]\t1.0\n",
      "[358 260  19]\t1.0\n",
      "[365 271   9]\t1.0\n",
      "[349 275  14]\t1.0\n",
      "[348 262  18]\t1.0\n",
      "[372 227  18]\t1.0\n",
      "[371 221  15]\t1.0\n",
      "[368 252  14]\t1.0\n",
      "[348 264  17]\t1.0\n",
      "[355 269  19]\t1.0\n",
      "[356 297  17]\t1.0\n",
      "[349 268  16]\t1.0\n",
      "[360 253  19]\t1.0\n",
      "[348 254  18]\t1.0\n",
      "[365 251  17]\t1.0\n",
      "[353 269  19]\t1.0\n",
      "[366 235  16]\t1.0\n",
      "[359 253  19]\t1.0\n",
      "[360 260  19]\t1.0\n",
      "[375 261  10]\t1.0\n",
      "[350 316  19]\t1.0\n",
      "[372 260  18]\t1.0\n",
      "[347 255  18]\t1.0\n",
      "[371 251  12]\t1.0\n",
      "[353 268  13]\t1.0\n",
      "[360 255  19]\t1.0\n",
      "[350 268  15]\t1.0\n",
      "[370 253  13]\t1.0\n",
      "[370 234  12]\t1.0\n",
      "[351 271  14]\t1.0\n",
      "[346 262  18]\t1.0\n",
      "[373 256  18]\t1.0\n",
      "[373 257  18]\t1.0\n",
      "[358 261  19]\t1.0\n",
      "[357 300  16]\t1.0\n",
      "[357 251  19]\t1.0\n",
      "[346 259  18]\t1.0\n",
      "[356 298  18]\t1.0\n",
      "[370 262  18]\t1.0\n",
      "[343 254  18]\t1.0\n",
      "[366 232  17]\t1.0\n",
      "[353 318  17]\t1.0\n",
      "[369 250  15]\t1.0\n",
      "[371 225  18]\t1.0\n",
      "[349 253  18]\t1.0\n",
      "[369 250  13]\t1.0\n",
      "[347 262  18]\t1.0\n",
      "[345 261  19]\t1.0\n",
      "[349 264  16]\t1.0\n",
      "[374 262  10]\t1.0\n",
      "[352 268  14]\t1.0\n",
      "[357 271  12]\t1.0\n",
      "[366 236  15]\t1.0\n",
      "[355 251  18]\t1.0\n",
      "[373 243   9]\t1.0\n",
      "[354 268  19]\t1.0\n",
      "[356 263  19]\t1.0\n",
      "[344 259  18]\t1.0\n",
      "[352 268  15]\t1.0\n",
      "[343 330  16]\t1.0\n",
      "[345 259  19]\t1.0\n",
      "[363 249  18]\t1.0\n",
      "[364 233  18]\t1.0\n",
      "[366 233  15]\t1.0\n",
      "[364 272  10]\t1.0\n",
      "[371 233  12]\t1.0\n",
      "[359 304  12]\t1.0\n",
      "[356 295  18]\t1.0\n",
      "[362 269  16]\t1.0\n",
      "[352 266  15]\t1.0\n",
      "[344 332  15]\t1.0\n",
      "[365 271   9]\t1.0\n",
      "[345 256  18]\t1.0\n",
      "[354 271  18]\t1.0\n",
      "[359 261  18]\t1.0\n",
      "[357 301  15]\t1.0\n",
      "[356 298  17]\t1.0\n",
      "[349 267  16]\t1.0\n",
      "[350 270  15]\t1.0\n",
      "[374 242   9]\t1.0\n",
      "[354 275  19]\t1.0\n",
      "[358 298  18]\t1.0\n",
      "[358 270  12]\t1.0\n",
      "[374 255  17]\t1.0\n",
      "[351 253  18]\t1.0\n",
      "[351 268  16]\t1.0\n",
      "[358 269  11]\t1.0\n",
      "[350 253  18]\t1.0\n",
      "[376 244   9]\t1.0\n",
      "[370 234  13]\t1.0\n",
      "[365 271   9]\t1.0\n",
      "[348 275  14]\t1.0\n",
      "[357 250  19]\t1.0\n",
      "[372 222  17]\t1.0\n",
      "[355 299  16]\t1.0\n",
      "[364 233  16]\t1.0\n",
      "[361 270  15]\t1.0\n",
      "[375 266   8]\t1.0\n",
      "[363 252  17]\t1.0\n",
      "[339 328  19]\t1.0\n",
      "[355 265  19]\t1.0\n",
      "[362 250  19]\t1.0\n",
      "[366 230  18]\t1.0\n",
      "[349 263  17]\t1.0\n",
      "[362 249  18]\t1.0\n",
      "[364 271  17]\t1.0\n",
      "[364 283  11]\t1.0\n",
      "[361 256  19]\t1.0\n",
      "[361 259  18]\t1.0\n",
      "[352 274  14]\t1.0\n",
      "[372 235  12]\t1.0\n",
      "[370 265  19]\t1.0\n",
      "[370 256  12]\t1.0\n",
      "[350 316  19]\t1.0\n",
      "[356 266  19]\t1.0\n",
      "[348 261  18]\t1.0\n",
      "[368 251  14]\t1.0\n",
      "[375 255  16]\t1.0\n",
      "[372 261  18]\t1.0\n",
      "[349 264  17]\t1.0\n",
      "[345 262  18]\t1.0\n",
      "[363 251  19]\t1.0\n",
      "[354 296  19]\t1.0\n",
      "[348 265  17]\t1.0\n",
      "[370 252  13]\t1.0\n",
      "[344 259  19]\t1.0\n",
      "[347 264  17]\t1.0\n",
      "[374 261  10]\t1.0\n",
      "[347 256  18]\t1.0\n",
      "[363 233  19]\t1.0\n",
      "[362 249  19]\t1.0\n",
      "[351 277  14]\t1.0\n",
      "[345 254  18]\t1.0\n",
      "[344 257  18]\t1.0\n",
      "[369 254  12]\t1.0\n",
      "[343 258  19]\t1.0\n",
      "[352 267  15]\t1.0\n",
      "[359 306  12]\t1.0\n",
      "[373 260  18]\t1.0\n",
      "[365 234  18]\t1.0\n",
      "[345 261  18]\t1.0\n",
      "[365 232  16]\t1.0\n",
      "[365 252  16]\t1.0\n",
      "[362 266  17]\t1.0\n",
      "[371 253  12]\t1.0\n",
      "[372 222  15]\t1.0\n",
      "[369 228  18]\t1.0\n",
      "[363 250  17]\t1.0\n",
      "[366 232  18]\t1.0\n",
      "[350 315  19]\t1.0\n",
      "[366 233  18]\t1.0\n",
      "[353 268  14]\t1.0\n",
      "[358 269  12]\t1.0\n",
      "[355 298  17]\t1.0\n",
      "[350 266  16]\t1.0\n",
      "[346 253  18]\t1.0\n",
      "[362 251  17]\t1.0\n",
      "[348 260  18]\t1.0\n",
      "[367 227  18]\t1.0\n",
      "[369 228  18]\t1.0\n",
      "[370 252  14]\t1.0\n",
      "[353 268  13]\t1.0\n",
      "[370 264  19]\t1.0\n",
      "[359 271  11]\t1.0\n",
      "[367 252  16]\t1.0\n",
      "[350 269  14]\t1.0\n",
      "[364 231  18]\t1.0\n",
      "[355 269  12]\t1.0\n",
      "[347 260  18]\t1.0\n",
      "[370 267  17]\t1.0\n",
      "[374 256  18]\t1.0\n",
      "[361 250  18]\t1.0\n",
      "[359 259  18]\t1.0\n",
      "[371 221  14]\t1.0\n",
      "[357 302  14]\t1.0\n",
      "[373 256  18]\t1.0\n",
      "[345 331  15]\t1.0\n",
      "[361 252  18]\t1.0\n",
      "[350 264  16]\t1.0\n",
      "[345 332  16]\t1.0\n",
      "[354 251  18]\t1.0\n",
      "[356 267  19]\t1.0\n",
      "[365 233  18]\t1.0\n",
      "[363 284   7]\t1.0\n",
      "[367 236  15]\t1.0\n",
      "[357 302  14]\t1.0\n",
      "[364 251  17]\t1.0\n",
      "[354 270  13]\t1.0\n",
      "[349 279  13]\t1.0\n",
      "[362 284   9]\t1.0\n",
      "[374 261  10]\t1.0\n",
      "[370 221  15]\t1.0\n",
      "[358 261  19]\t1.0\n",
      "[345 260  18]\t1.0\n",
      "[375 244   8]\t1.0\n",
      "[359 305  12]\t1.0\n",
      "[364 234  19]\t1.0\n",
      "[354 271  18]\t1.0\n",
      "[349 263  17]\t1.0\n",
      "[361 260  18]\t1.0\n",
      "[358 270  12]\t1.0\n",
      "[359 260  19]\t1.0\n",
      "[358 263  19]\t1.0\n",
      "[358 297  18]\t1.0\n",
      "[347 257  18]\t1.0\n",
      "[367 229  18]\t1.0\n",
      "[367 249  15]\t1.0\n",
      "[366 251  17]\t1.0\n",
      "[344 253  18]\t1.0\n",
      "[347 259  18]\t1.0\n",
      "[357 269  12]\t1.0\n",
      "[362 269  15]\t1.0\n",
      "[350 270  15]\t1.0\n",
      "[351 269  14]\t1.0\n",
      "[350 270  15]\t1.0\n",
      "[356 297  17]\t1.0\n",
      "[371 222  16]\t1.0\n",
      "[363 249  17]\t1.0\n",
      "[363 250  16]\t1.0\n",
      "[352 318  17]\t1.0\n",
      "[355 269  12]\t1.0\n",
      "[341 329  18]\t1.0\n",
      "[345 258  18]\t1.0\n",
      "[373 258  11]\t1.0\n",
      "[372 234  12]\t1.0\n",
      "[353 267  14]\t1.0\n",
      "[345 261  19]\t1.0\n",
      "[349 272  14]\t1.0\n",
      "[346 258  19]\t1.0\n",
      "[371 222  15]\t1.0\n",
      "[371 227  18]\t1.0\n",
      "[354 273  18]\t1.0\n",
      "[370 234  12]\t1.0\n",
      "[363 250  18]\t1.0\n",
      "[349 275  14]\t1.0\n",
      "[360 271  11]\t1.0\n",
      "[372 235  12]\t1.0\n",
      "[365 252  16]\t1.0\n",
      "[376 254  16]\t1.0\n",
      "[346 259  18]\t1.0\n",
      "[374 255  18]\t1.0\n",
      "[368 233  15]\t1.0\n",
      "[370 252  13]\t1.0\n",
      "[361 255  19]\t1.0\n",
      "[372 222  15]\t1.0\n",
      "[370 234  13]\t1.0\n",
      "[364 231  18]\t1.0\n",
      "[366 235  15]\t1.0\n",
      "[361 265  17]\t1.0\n",
      "[366 230  18]\t1.0\n",
      "[374 243   8]\t1.0\n",
      "[369 267  17]\t1.0\n",
      "[372 227  18]\t1.0\n",
      "[369 252  14]\t1.0\n",
      "[364 232  19]\t1.0\n",
      "[357 296  18]\t1.0\n",
      "[350 267  16]\t1.0\n",
      "[355 268  13]\t1.0\n",
      "[363 248  18]\t1.0\n",
      "[360 270  10]\t1.0\n",
      "[360 305  12]\t1.0\n",
      "[373 256  18]\t1.0\n",
      "[345 262  19]\t1.0\n",
      "[363 284  10]\t1.0\n",
      "[354 275  19]\t1.0\n",
      "[363 284   9]\t1.0\n",
      "[372 235  12]\t1.0\n",
      "[354 268  19]\t1.0\n",
      "[349 271  14]\t1.0\n",
      "[365 236  15]\t1.0\n",
      "[370 265  18]\t1.0\n",
      "[350 266  15]\t1.0\n",
      "[352 274  18]\t1.0\n",
      "[354 293  19]\t1.0\n",
      "[367 234  17]\t1.0\n",
      "[355 297  17]\t1.0\n",
      "[368 251  15]\t1.0\n",
      "[347 261  19]\t1.0\n",
      "[367 234  17]\t1.0\n",
      "[368 252  14]\t1.0\n",
      "[370 264  19]\t1.0\n",
      "[359 260  19]\t1.0\n",
      "[363 270  17]\t1.0\n",
      "[371 234  12]\t1.0\n",
      "[368 265  19]\t1.0\n",
      "[346 256  18]\t1.0\n",
      "[360 271  11]\t1.0\n",
      "[352 270  14]\t1.0\n",
      "[367 249  15]\t1.0\n",
      "[353 295  19]\t1.0\n",
      "[369 252  13]\t1.0\n",
      "[348 265  16]\t1.0\n",
      "[361 266  17]\t1.0\n",
      "[357 260  19]\t1.0\n",
      "[353 273  18]\t1.0\n",
      "[344 259  18]\t1.0\n",
      "[363 270  10]\t1.0\n",
      "[365 233  17]\t1.0\n",
      "[365 270  17]\t1.0\n",
      "[364 272   9]\t1.0\n",
      "[375 255  17]\t1.0\n",
      "[351 277  17]\t1.0\n",
      "[366 252  16]\t1.0\n",
      "[374 233  11]\t1.0\n",
      "[360 285   8]\t1.0\n",
      "[370 221  15]\t1.0\n",
      "[357 296  18]\t1.0\n",
      "[357 260  19]\t1.0\n",
      "[365 232  18]\t1.0\n",
      "[374 223  17]\t1.0\n",
      "[373 222  16]\t1.0\n",
      "[357 270  12]\t1.0\n",
      "[358 286   8]\t1.0\n",
      "[359 304  13]\t1.0\n",
      "[371 235  13]\t1.0\n",
      "[372 222  15]\t1.0\n",
      "[370 267  17]\t1.0\n",
      "[349 278  13]\t1.0\n",
      "[372 249  12]\t1.0\n",
      "[358 257  19]\t1.0\n",
      "[349 276  14]\t1.0\n",
      "[377 268   8]\t1.0\n",
      "[370 221  16]\t1.0\n",
      "[370 265  18]\t1.0\n",
      "[346 257  19]\t1.0\n",
      "[348 262  18]\t1.0\n",
      "[349 276  14]\t1.0\n",
      "[368 249  15]\t1.0\n",
      "[371 233  12]\t1.0\n",
      "[365 232  16]\t1.0\n",
      "[349 264  17]\t1.0\n",
      "[373 258  18]\t1.0\n",
      "[339 328  19]\t1.0\n",
      "[359 305  12]\t1.0\n",
      "[369 264  18]\t1.0\n",
      "[356 266  19]\t1.0\n",
      "[358 269  12]\t1.0\n",
      "[366 251  17]\t1.0\n",
      "[369 253  12]\t1.0\n",
      "[360 259  18]\t1.0\n",
      "[350 278  14]\t1.0\n",
      "[353 269  19]\t1.0\n",
      "[371 234  13]\t1.0\n",
      "[365 233  19]\t1.0\n",
      "[356 264  19]\t1.0\n",
      "[370 250  13]\t1.0\n",
      "[346 255  18]\t1.0\n",
      "[373 260  11]\t1.0\n",
      "[374 256  17]\t1.0\n",
      "[356 251  18]\t1.0\n",
      "[360 258  18]\t1.0\n",
      "[376 266   8]\t1.0\n",
      "[347 264  17]\t1.0\n",
      "[360 305  12]\t1.0\n",
      "[359 250  19]\t1.0\n",
      "[348 263  18]\t1.0\n",
      "[351 272  14]\t1.0\n",
      "[349 266  16]\t1.0\n",
      "[370 234  12]\t1.0\n",
      "[370 252  12]\t1.0\n",
      "[353 271  14]\t1.0\n",
      "[366 251  16]\t1.0\n",
      "[355 268  13]\t1.0\n",
      "[367 235  16]\t1.0\n",
      "[373 221  15]\t1.0\n",
      "[351 273  14]\t1.0\n",
      "[346 258  18]\t1.0\n",
      "[354 269  13]\t1.0\n",
      "[356 266  19]\t1.0\n",
      "[375 257  18]\t1.0\n",
      "[364 232  18]\t1.0\n",
      "[355 252  18]\t1.0\n",
      "[373 222  17]\t1.0\n",
      "[350 274  14]\t1.0\n",
      "[372 249  11]\t1.0\n",
      "[346 261  18]\t1.0\n",
      "[364 232  16]\t1.0\n",
      "[343 256  19]\t1.0\n",
      "[368 229  18]\t1.0\n",
      "[374 258  18]\t1.0\n",
      "[354 268  19]\t1.0\n",
      "[357 261  19]\t1.0\n",
      "[367 251  16]\t1.0\n",
      "[319 332  19]\t1.0\n",
      "[345 258  19]\t1.0\n",
      "[370 250  13]\t1.0\n",
      "[365 233  16]\t1.0\n",
      "[374 257  18]\t1.0\n",
      "[364 232  19]\t1.0\n",
      "[371 235  13]\t1.0\n",
      "[348 265  16]\t1.0\n",
      "[362 267  16]\t1.0\n",
      "[348 265  17]\t1.0\n",
      "[350 264  17]\t1.0\n",
      "[352 265  16]\t1.0\n",
      "[358 260  19]\t1.0\n",
      "[352 266  15]\t1.0\n",
      "[361 268  16]\t1.0\n",
      "[354 270  13]\t1.0\n",
      "[375 255  18]\t1.0\n",
      "[355 268  13]\t1.0\n",
      "[364 250  16]\t1.0\n",
      "[359 261  19]\t1.0\n",
      "[351 277  14]\t1.0\n",
      "[362 252  19]\t1.0\n",
      "[375 243   9]\t1.0\n",
      "[350 268  15]\t1.0\n",
      "[366 233  16]\t1.0\n",
      "[354 269  14]\t1.0\n",
      "[368 251  14]\t1.0\n",
      "[365 249  17]\t1.0\n",
      "[357 302  15]\t1.0\n",
      "[372 220  15]\t1.0\n",
      "[372 222  17]\t1.0\n",
      "[364 232  16]\t1.0\n",
      "[361 264  17]\t1.0\n",
      "[356 298  17]\t1.0\n",
      "[363 270  17]\t1.0\n",
      "[350 276  14]\t1.0\n",
      "[362 284   7]\t1.0\n",
      "[354 271  18]\t1.0\n",
      "[343 258  19]\t1.0\n",
      "[362 264  17]\t1.0\n",
      "[369 233  15]\t1.0\n",
      "[369 226  18]\t1.0\n",
      "[360 260  19]\t1.0\n",
      "[362 249  19]\t1.0\n",
      "[345 261  19]\t1.0\n",
      "[371 228  18]\t1.0\n",
      "[343 254  19]\t1.0\n",
      "[344 259  19]\t1.0\n",
      "[366 229  18]\t1.0\n",
      "[361 284   8]\t1.0\n",
      "[370 251  14]\t1.0\n",
      "[370 221  15]\t1.0\n",
      "[375 257  18]\t1.0\n",
      "[372 256  12]\t1.0\n",
      "[359 269  11]\t1.0\n",
      "[354 269  14]\t1.0\n",
      "[364 251  18]\t1.0\n",
      "[360 251  18]\t1.0\n",
      "[345 262  18]\t1.0\n",
      "[350 265  17]\t1.0\n",
      "[354 274  19]\t1.0\n",
      "[366 249  16]\t1.0\n",
      "[371 233  12]\t1.0\n",
      "[373 250  11]\t1.0\n",
      "[372 221  16]\t1.0\n",
      "[355 269  13]\t1.0\n",
      "[354 267  19]\t1.0\n",
      "[366 234  16]\t1.0\n",
      "[373 259  18]\t1.0\n",
      "[350 274  14]\t1.0\n",
      "[357 270  11]\t1.0\n",
      "[368 264  19]\t1.0\n",
      "[375 262  10]\t1.0\n",
      "[370 264  19]\t1.0\n",
      "[355 294  19]\t1.0\n",
      "[363 249  17]\t1.0\n",
      "[349 266  16]\t1.0\n",
      "[361 250  18]\t1.0\n",
      "[361 250  18]\t1.0\n",
      "[364 234  16]\t1.0\n",
      "[352 253  18]\t1.0\n",
      "[365 270  17]\t1.0\n",
      "[362 233  19]\t1.0\n",
      "[374 262  10]\t1.0\n",
      "[356 271  12]\t1.0\n",
      "[367 229  18]\t1.0\n",
      "[372 222  15]\t1.0\n",
      "[365 232  17]\t1.0\n",
      "[360 258  18]\t1.0\n",
      "[369 250  15]\t1.0\n",
      "[373 222  16]\t1.0\n",
      "[344 257  19]\t1.0\n",
      "[343 329  17]\t1.0\n",
      "[347 256  18]\t1.0\n",
      "[366 229  18]\t1.0\n",
      "[370 264  19]\t1.0\n",
      "[372 256  12]\t1.0\n",
      "[358 297  18]\t1.0\n",
      "[356 298  17]\t1.0\n",
      "[371 225  18]\t1.0\n",
      "[351 267  16]\t1.0\n",
      "[355 297  18]\t1.0\n",
      "[354 267  19]\t1.0\n",
      "[356 269  12]\t1.0\n",
      "[364 250  18]\t1.0\n",
      "[364 271  17]\t1.0\n",
      "[369 265  18]\t1.0\n",
      "[344 257  19]\t1.0\n",
      "[371 236  12]\t1.0\n",
      "[375 256  17]\t1.0\n",
      "[361 286   8]\t1.0\n",
      "[345 257  18]\t1.0\n",
      "[358 262  19]\t1.0\n",
      "[364 250  18]\t1.0\n",
      "[367 233  17]\t1.0\n",
      "[372 260  11]\t1.0\n",
      "[347 264  17]\t1.0\n",
      "[360 250  19]\t1.0\n",
      "[367 234  15]\t1.0\n",
      "[371 253  13]\t1.0\n",
      "[347 261  18]\t1.0\n",
      "[349 267  15]\t1.0\n",
      "[363 273  10]\t1.0\n",
      "[355 296  18]\t1.0\n",
      "[361 249  19]\t1.0\n",
      "[340 329  19]\t1.0\n",
      "[374 243   9]\t1.0\n",
      "[354 268  14]\t1.0\n",
      "[359 269  11]\t1.0\n",
      "[355 269  12]\t1.0\n",
      "[352 273  18]\t1.0\n",
      "[372 220  15]\t1.0\n",
      "[374 243   8]\t1.0\n",
      "[349 269  15]\t1.0\n",
      "[367 251  15]\t1.0\n",
      "[369 235  15]\t1.0\n",
      "[352 274  14]\t1.0\n",
      "[370 227  18]\t1.0\n",
      "[356 298  16]\t1.0\n",
      "[374 242   9]\t1.0\n",
      "[365 277  13]\t1.0\n",
      "[351 267  14]\t1.0\n",
      "[365 272   9]\t1.0\n",
      "[348 265  16]\t1.0\n",
      "[374 232  11]\t1.0\n",
      "[347 264  17]\t1.0\n",
      "[373 222  17]\t1.0\n",
      "[349 272  14]\t1.0\n",
      "[341 328  18]\t1.0\n",
      "[370 234  14]\t1.0\n",
      "[357 299  18]\t1.0\n",
      "[360 271  11]\t1.0\n",
      "[361 262  17]\t1.0\n",
      "[370 233  12]\t1.0\n",
      "[374 223  17]\t1.0\n",
      "[364 234  15]\t1.0\n",
      "[369 250  13]\t1.0\n",
      "[366 251  16]\t1.0\n",
      "[365 271   9]\t1.0\n",
      "[353 269  18]\t1.0\n",
      "[377 269   8]\t1.0\n",
      "[366 249  16]\t1.0\n",
      "[357 263  19]\t1.0\n",
      "[364 231  19]\t1.0\n",
      "[348 265  17]\t1.0\n",
      "[351 269  14]\t1.0\n",
      "[345 262  19]\t1.0\n",
      "[363 233  19]\t1.0\n",
      "[361 272  10]\t1.0\n",
      "[361 270  15]\t1.0\n"
     ]
    }
   ],
   "source": [
    "current_label = 1\n",
    "indices_all = np.array(np.where(my_array==current_label))\n",
    "for i in range(1000):\n",
    "    selected_index_w = np.random.randint(indices_all.shape[1])\n",
    "    selected_index = indices_all[:, selected_index_w]\n",
    "    print(f'{selected_index}\\t{a[selected_index[0], selected_index[1], selected_index[2]]}')\n",
    "# a[selected_index[0], selected_index[1], selected_index[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2abb666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 913)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "82a9dc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "82ecc546",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10460/3816909202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mselected_index_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mselected_index_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mselected_index_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# selected_index = indices_all[:, selected_index_w]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "selected_index_h = np.random.randint(indices_all.shape[0])\n",
    "selected_index_w = np.random.randint(indices_all.shape[1])\n",
    "selected_index_d = np.random.randint(indices_all.shape[2])\n",
    "# selected_index = indices_all[:, selected_index_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "38f64f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 913)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2d7b22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a8cb20c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method 'timestamp' of 'datetime.datetime' objects>"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "2ee62a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10460/1378459625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'timestamp'"
     ]
    }
   ],
   "source": [
    "datetime.timestamp(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "cf3be0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29-03-2022__06-02-53'"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%m-%Y__%H-%M-%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc0ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
