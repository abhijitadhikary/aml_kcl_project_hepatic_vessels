{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cb790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# %matplotlib inline\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from imp import reload\n",
    "import json\n",
    "import logging\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f2dcd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instructions #\n",
    "\n",
    "Major part of the code is implemented using Classes to avoid duplication of code. The first few blocks of the notebook defines the various components i.e. model structure, training pipeline, dataloaders, loss functions etc. In each of the marked sections afterwards, the required functions are called with the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e009bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducability\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6529904",
   "metadata": {},
   "source": [
    "### Dataset and Dataloaders ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc7e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTorchTensor:\n",
    "    '''\n",
    "        Transforms a numpy ndarray to a torch tensor of the supplied datatype\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dtype=torch.float32):\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return torch.tensor(input, dtype=self.dtype)\n",
    "\n",
    "class DatasetHepatic(Dataset):\n",
    "    '''\n",
    "        min = 24\n",
    "        max = 181\n",
    "        median = 49\n",
    "        mean = 69\n",
    "    '''\n",
    "\n",
    "    def __init__(self, run_mode='train',\n",
    "                 transform_image=None,\n",
    "                 transform_label=None,\n",
    "                 patch_size_normal=25,\n",
    "                 patch_size_low=19,\n",
    "                 patch_size_out=9,\n",
    "                 patch_low_factor=3,\n",
    "                 label_percentage=0.1,\n",
    "                 batch_size_inner=100,\n",
    "                 use_probabilistic=False,\n",
    "                 create_numpy_dataset=False,\n",
    "                 dataset_variant='nib',\n",
    "                 train_percentage=0.8,\n",
    "                 use_elastic_deformation=False,\n",
    "                 user_affine_transformation=False,\n",
    "                 num_controlpoints=20, sigma=5, rotation=10, scale=(0.90, 1.10), shear=(0.01, 0.02)\n",
    "                 ):\n",
    "\n",
    "        self.run_mode = run_mode\n",
    "        self.create_numpy_dataset_cond = create_numpy_dataset\n",
    "        self.dataset_variant = dataset_variant\n",
    "        self.patch_size_normal = patch_size_normal\n",
    "        self.patch_size_low = patch_size_low\n",
    "        self.patch_size_out = patch_size_out\n",
    "        self.patch_low_factor = patch_low_factor\n",
    "        self.batch_size_inner = batch_size_inner\n",
    "        self.train_percentage = train_percentage\n",
    "        self.patch_size_low_up = self.patch_size_low * self.patch_low_factor\n",
    "\n",
    "        self.label_percentage = label_percentage\n",
    "        self.use_probabilistic = use_probabilistic\n",
    "        self.fetch_filenames()\n",
    "        self.create_numpy_dataset()\n",
    "        self.use_elastic_deformation = use_elastic_deformation\n",
    "        self.use_affine_transformation = user_affine_transformation\n",
    "        self.elastic_deformation = ElasticDeformation(num_controlpoints=num_controlpoints, sigma=sigma)\n",
    "        self.affine_transformation = AffineTransformation(rotation=rotation, scale=scale, shear=shear)\n",
    "\n",
    "        if transform_image is None:\n",
    "            self.transform_image = transforms.Compose([\n",
    "                ToTorchTensor(dtype=torch.float32),\n",
    "                transforms.Normalize(mean=0.5, std=0.5)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform_image = transform_image\n",
    "\n",
    "        if transform_label is None:\n",
    "            self.transform_label = transforms.Compose([\n",
    "                ToTorchTensor(torch.int64)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform_label = transform_label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset_variant == 'nib':\n",
    "            image = self.read_file_nib(self.filenames_image_nib[index])\n",
    "            label = self.read_file_nib(self.filenames_label_nib[index])\n",
    "        elif self.dataset_variant == 'npy':\n",
    "            image = self.read_file_npy(self.filenames_image_npy[index])\n",
    "            label = self.read_file_npy(self.filenames_label_npy[index])\n",
    "\n",
    "        image = self.transform_image(image)\n",
    "        label = self.transform_label(label)\n",
    "        if self.use_elastic_deformation:\n",
    "            image, label = self.elastic_deformation(image, label)\n",
    "        if self.use_affine_transformation:\n",
    "            image, label, _, _ = self.affine_transformation(image, label)\n",
    "\n",
    "        image = image.detach().numpy()\n",
    "        label = label.detach().numpy()\n",
    "\n",
    "        # index of the original filenames as in the dataset folders\n",
    "        index_filename = self.filenames_image_npy[index][25:28]\n",
    "\n",
    "        if self.run_mode in ['train', 'val']:\n",
    "            if self.batch_size_inner > 1:\n",
    "                image_patch_normal_stack = torch.zeros(\n",
    "                    (self.batch_size_inner, self.patch_size_normal, self.patch_size_normal, self.patch_size_normal),\n",
    "                    dtype=torch.float32)\n",
    "                image_patch_low_up_stack = torch.zeros(\n",
    "                    (self.batch_size_inner, self.patch_size_low_up, self.patch_size_low_up, self.patch_size_low_up),\n",
    "                    dtype=torch.float32)\n",
    "                label_patch_out_stack = torch.zeros(\n",
    "                    (self.batch_size_inner, self.patch_size_out, self.patch_size_out, self.patch_size_out),\n",
    "                    dtype=torch.int64)\n",
    "\n",
    "                for index_inner in range(self.batch_size_inner):\n",
    "                    # extract the three different patches of labels\n",
    "                    label_patch_normal, label_patch_low_up, label_patch_out = self.get_random_patch(label)\n",
    "\n",
    "                    # extract the three different patches of images\n",
    "                    image_patch_normal = self.get_3D_crop(image, self.coordinate_center, self.patch_size_normal)\n",
    "                    image_patch_low_up = self.get_3D_crop(image, self.coordinate_center, self.patch_size_low_up)\n",
    "                    image_patch_out = self.get_3D_crop(image, self.coordinate_center, self.patch_size_out)\n",
    "\n",
    "                    image_patch_normal_stack[index_inner] = torch.tensor(image_patch_normal, dtype=torch.float32).unsqueeze(0)\n",
    "                    image_patch_low_up_stack[index_inner] = torch.tensor(image_patch_low_up, dtype=torch.float32).unsqueeze(0)\n",
    "                    label_patch_out_stack[index_inner] = torch.tensor(label_patch_out, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "                return image_patch_normal_stack.unsqueeze(1), image_patch_low_up_stack.unsqueeze(1), label_patch_out_stack.unsqueeze(1)\n",
    "            else:\n",
    "                # extract the three different patches of labels\n",
    "                label_patch_normal, label_patch_low_up, label_patch_out = self.get_random_patch(label)\n",
    "\n",
    "                # extract the three different patches of images\n",
    "                image_patch_normal = self.get_3D_crop(image, self.coordinate_center, self.patch_size_normal)\n",
    "                image_patch_low_up = self.get_3D_crop(image, self.coordinate_center, self.patch_size_low_up)\n",
    "                image_patch_out = self.get_3D_crop(image, self.coordinate_center, self.patch_size_out)\n",
    "\n",
    "                return torch.tensor(image_patch_normal, dtype=torch.float32).unsqueeze(0), \\\n",
    "                       torch.tensor(image_patch_low_up, dtype=torch.float32).unsqueeze(0), \\\n",
    "                       torch.tensor(label_patch_out, dtype=torch.int64).unsqueeze(0)\n",
    "\n",
    "        elif self.run_mode == 'inference':\n",
    "            # TODO fix uneven dimensions, otherwise run with batch size = 1\n",
    "            image = self.transform_image(image)\n",
    "            return image, label, index_filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def create_numpy_dataset(self):\n",
    "        '''\n",
    "            Converts the dataset to numpy format to increase i/o operations\n",
    "        '''\n",
    "        def convert_to_numpy_from_nib(target_dir, filenames):\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "            for filename in tqdm(filenames, leave=False):\n",
    "                data_np = nib.load(filename).get_fdata()\n",
    "\n",
    "                filename_new = f'{filename[11:-7]}.npy'\n",
    "                save_path = os.path.join(target_dir, filename_new)\n",
    "                np.save(save_path, data_np)\n",
    "\n",
    "        save_dir_train_im = 'imagesTrNP'\n",
    "        train_filenames_im = self.filenames_image_nib\n",
    "\n",
    "        save_dir_train_labels = 'labelsTrNP'\n",
    "        train_filenames_labels = self.filenames_label_nib\n",
    "\n",
    "        if self.create_numpy_dataset_cond:\n",
    "            convert_to_numpy_from_nib(target_dir=save_dir_train_im, filenames=train_filenames_im)\n",
    "            convert_to_numpy_from_nib(target_dir=save_dir_train_labels, filenames=train_filenames_labels)\n",
    "\n",
    "    def get_label_percentage(self, input, label):\n",
    "        '''\n",
    "            Returns the percentage of supplied label in the voxel\n",
    "        '''\n",
    "        eps = 1e-9\n",
    "        denominator = input.shape[0] * input.shape[1] * input.shape[2]\n",
    "        numerator = np.sum(np.where(input == label, 1, 0))\n",
    "\n",
    "        return numerator / (denominator + eps)\n",
    "\n",
    "    def get_rand_index_3D(self, input, height=512, width=512, depth=20, patch_size=57):\n",
    "        '''\n",
    "            Returns a random starting index (top-left) of a valid 3D volume\n",
    "        '''\n",
    "        patch_size_half = patch_size // 2\n",
    "\n",
    "        if self.use_probabilistic:\n",
    "            # nearby currently selected label\n",
    "            loop_condition = True\n",
    "            background_count = 0\n",
    "            while loop_condition:\n",
    "                # crop the image so that the patch does not go outside the area of the image\n",
    "                input_cropped = input[patch_size_half:height - patch_size_half, patch_size_half:width - patch_size_half,\n",
    "                                patch_size_half:depth - patch_size_half]\n",
    "                # all indices of the cropped image equal to the current selected label category\n",
    "                indices_all = np.array(np.where(input_cropped == self.current_selected_label))\n",
    "                # print(indices_all.shape[1])\n",
    "                if indices_all.shape[1] >= 1:\n",
    "                    selected_index_w = np.random.randint(indices_all.shape[1])\n",
    "                    selected_index = indices_all[:, selected_index_w]\n",
    "\n",
    "                    index_h, index_w, index_d = (\n",
    "                        selected_index[0] + patch_size_half, selected_index[1] + patch_size_half,\n",
    "                        selected_index[2] + patch_size_half)\n",
    "                    # index_h, index_w, index_d = selected_index\n",
    "                    loop_condition = False\n",
    "                else:\n",
    "                    # print('here')\n",
    "                    if background_count > 0:\n",
    "                        # if none of the other two labels are present in the image, randomly pick a coordinate\n",
    "                        index_h = np.random.randint(patch_size_half, height - patch_size_half)\n",
    "                        index_w = np.random.randint(patch_size_half, width - patch_size_half)\n",
    "                        index_d = np.random.randint(patch_size_half, depth - patch_size_half)\n",
    "                        loop_condition = False\n",
    "\n",
    "                    else:\n",
    "                        if self.current_selected_label == 1:\n",
    "                            self.current_selected_label = 2\n",
    "                            background_count += 1\n",
    "                        elif self.current_selected_label == 2:\n",
    "                            self.current_selected_label = 1\n",
    "                            background_count += 1\n",
    "                        loop_condition = True\n",
    "        else:\n",
    "            #  complete random\n",
    "            index_h = np.random.randint(patch_size_half, height - patch_size_half)\n",
    "            index_w = np.random.randint(patch_size_half, width - patch_size_half)\n",
    "            index_d = np.random.randint(patch_size_half, depth - patch_size_half)\n",
    "\n",
    "        return (index_h, index_w, index_d)\n",
    "\n",
    "    def get_3D_crop(self, input, coordinate, patch_size):\n",
    "        '''\n",
    "            Returns a 3D patch of an input 3D image given a valid top-left coordinate\n",
    "        '''\n",
    "        assert patch_size % 2 == 1, 'Patch size should be an odd number'\n",
    "        patch_size_half = patch_size // 2\n",
    "\n",
    "        if len(input.shape) == 3:\n",
    "            height, width, depth = input.shape\n",
    "\n",
    "        if depth <= self.patch_size_low * self.patch_low_factor:\n",
    "            temp_array = np.zeros((height, width, self.patch_size_low * self.patch_low_factor))\n",
    "            temp_array[:, :, :depth] = input\n",
    "            input = temp_array\n",
    "            depth = temp_array.shape[2]\n",
    "\n",
    "        return input[\n",
    "               coordinate[0] - patch_size_half: coordinate[0] + patch_size_half + 1,\n",
    "               coordinate[1] - patch_size_half: coordinate[1] + patch_size_half + 1,\n",
    "               coordinate[2] - patch_size_half: coordinate[2] + patch_size_half + 1,\n",
    "               ]\n",
    "\n",
    "    def set_probabilistic_label(self):\n",
    "        '''\n",
    "            Randomly with equal probability select one of the three labels to be the current label\n",
    "        '''\n",
    "        label_probability = np.random.rand()\n",
    "        mode = 'major'  # equal, biased\n",
    "        if mode == 'biased':\n",
    "            if label_probability > 0.5:\n",
    "                self.current_selected_label = 1\n",
    "            else:\n",
    "                self.current_selected_label = 2\n",
    "        elif mode == 'equal':\n",
    "            if label_probability > 0.66:\n",
    "                self.current_selected_label = 2\n",
    "            elif label_probability < 0.33:\n",
    "                self.current_selected_label = 1\n",
    "            else:\n",
    "                self.current_selected_label = 0\n",
    "        elif mode == 'major':\n",
    "            if label_probability > 0.45:\n",
    "                self.current_selected_label = 2\n",
    "            elif label_probability < 0.45:\n",
    "                self.current_selected_label = 1\n",
    "            else:\n",
    "                self.current_selected_label = 0\n",
    "\n",
    "    def get_random_patch(self, input):\n",
    "        '''\n",
    "            Returns a valid cubic sub-volume with edge lenth = patch_size from a supplied 3D input volume image_input\n",
    "        '''\n",
    "        # a = copy.deepcopy(input)\n",
    "        if len(input.shape) == 3:\n",
    "            height, width, depth = input.shape\n",
    "\n",
    "        if depth <= self.patch_size_low * self.patch_low_factor:\n",
    "            temp_array = np.zeros((height, width, self.patch_size_low * self.patch_low_factor))\n",
    "            temp_array[:, :, :depth] = input\n",
    "            input = temp_array\n",
    "            depth = temp_array.shape[2]\n",
    "\n",
    "        loop_condition = True\n",
    "        if self.use_probabilistic:\n",
    "            self.set_probabilistic_label()\n",
    "\n",
    "        # keep sampling a new patch until the current label meets the desired overall percentage\n",
    "        while loop_condition:\n",
    "            # get a valid coordinate and extract the patch\n",
    "            self.coordinate_center = self.get_rand_index_3D(input, height, width, depth, self.patch_size_low_up)\n",
    "\n",
    "            patch_normal = self.get_3D_crop(input, self.coordinate_center, self.patch_size_normal)\n",
    "            patch_low_up = self.get_3D_crop(input, self.coordinate_center, self.patch_size_low_up)\n",
    "            patch_out = self.get_3D_crop(input, self.coordinate_center, self.patch_size_out)\n",
    "\n",
    "            loop_condition = False\n",
    "\n",
    "        return patch_normal, patch_low_up, patch_out\n",
    "\n",
    "    def read_file_nib(self, filename):\n",
    "        '''\n",
    "            Reads a nibabel file and returns it in numpy ndarray format\n",
    "        '''\n",
    "        try:\n",
    "            data_nib = nib.load(filename).get_fdata()\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error reading file: {filename}')\n",
    "\n",
    "        return data_nib\n",
    "\n",
    "    def read_file_npy(self, filename):\n",
    "        '''\n",
    "            Reads a npy file and returns it in numpy ndarray format\n",
    "        '''\n",
    "        try:\n",
    "            data_npy = np.load(filename)\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error reading file: {filename}')\n",
    "\n",
    "        return data_npy\n",
    "\n",
    "    def fetch_filenames(self, path_meta='dataset.json'):\n",
    "        '''\n",
    "            Reads the dataset.json file and extracts the training and test image and/or labels\n",
    "        :return:\n",
    "        '''\n",
    "        try:\n",
    "            with open(path_meta) as file_meta:\n",
    "                data_meta = json.loads(file_meta.read())\n",
    "        except FileNotFoundError:\n",
    "            print(f'Meta file: {self.path_meta} not found')\n",
    "\n",
    "        num_samples = len(data_meta['training'])\n",
    "\n",
    "        if self.run_mode == 'train':\n",
    "            num_samples = int(np.floor(self.train_percentage * num_samples))\n",
    "\n",
    "            self.filenames_image_nib = [current_sample['image'] for current_sample in data_meta['training']][\n",
    "                                       :num_samples]\n",
    "            self.filenames_label_nib = [current_sample['label'] for current_sample in data_meta['training']][\n",
    "                                       :num_samples]\n",
    "\n",
    "            self.filenames_image_npy = [os.path.join('.', 'imagesTrNP', f'{filename[11:-7]}.npy') for filename in\n",
    "                                        self.filenames_image_nib]\n",
    "            self.filenames_label_npy = [os.path.join('.', 'labelsTrNP', f'{filename[11:-7]}.npy') for filename in\n",
    "                                        self.filenames_label_nib]\n",
    "            self.num_samples = num_samples\n",
    "        else:\n",
    "            num_train = int(np.floor(self.train_percentage * num_samples))\n",
    "\n",
    "            self.filenames_image_nib = [current_sample['image'] for current_sample in data_meta['training']][\n",
    "                                       num_train:]\n",
    "            self.filenames_label_nib = [current_sample['label'] for current_sample in data_meta['training']][\n",
    "                                       num_train:]\n",
    "\n",
    "            self.filenames_image_npy = [os.path.join('.', 'imagesTrNP', f'{filename[11:-7]}.npy') for filename in\n",
    "                                        self.filenames_image_nib]\n",
    "            self.filenames_label_npy = [os.path.join('.', 'labelsTrNP', f'{filename[11:-7]}.npy') for filename in\n",
    "                                        self.filenames_label_nib]\n",
    "            # self.num_samples = int(np.ceil((1 - self.train_percentage) * num_samples))\n",
    "            self.num_samples = len(self.filenames_image_nib)\n",
    "        if (not len(self.filenames_image_nib) == len(self.filenames_label_nib)):\n",
    "            raise Exception('Inconsistent training image/label combination')\n",
    "        if len(self.filenames_image_nib) == 0:\n",
    "            raise Exception(f'Error reading {self.run_mode} images')\n",
    "        if len(self.filenames_label_nib) == 0:\n",
    "            raise Exception(f'Error reading {self.run_mode} labels')\n",
    "\n",
    "        elif self.run_mode == 'test':\n",
    "            # 'TODO' correct the train and test and inference variants\n",
    "            self.filenames_image_nib = [current_sample for current_sample in data_meta['test']]\n",
    "            if len(self.filenames_image_nib) == 0:\n",
    "                raise Exception(f'Error reading {self.run_mode} images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7474ee",
   "metadata": {},
   "source": [
    "### DeepMedic Model ###\n",
    "#### Adapted from: https://github.com/pykao/BraTS2018-tumor-segmentation/blob/master/models/deepmedic.py ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63be558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    '''\n",
    "        Adapted from: https://github.com/pykao/BraTS2018-tumor-segmentation/blob/master/models/deepmedic.py\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inplanes, planes):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, 3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.bn1(self.conv1(x)))\n",
    "        y = self.bn2(self.conv2(y))\n",
    "        x = x[:, :, 2:-2, 2:-2, 2:-2]\n",
    "        y[:, :self.inplanes] += x\n",
    "        y = self.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "def conv3x3(inplanes, planes, ksize=3):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(inplanes, planes, ksize, bias=False),\n",
    "        nn.BatchNorm3d(planes),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "def repeat(x, n=3):\n",
    "    # nc333\n",
    "    b, c, h, w, t = x.shape\n",
    "    x = x.unsqueeze(5).unsqueeze(4).unsqueeze(3)\n",
    "    x = x.repeat(1, 1, 1, n, 1, n, 1, n)\n",
    "    return x.view(b, c, n * h, n * w, n * t)\n",
    "\n",
    "\n",
    "class DeepMedic(nn.Module):\n",
    "    '''\n",
    "        Adapted from: https://github.com/pykao/BraTS2018-tumor-segmentation/blob/master/models/deepmedic.py\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_channels=1, n1=30, n2=40, n3=50, m=150, up=True):\n",
    "        super(DeepMedic, self).__init__()\n",
    "        # n1, n2, n3 = 30, 40, 50\n",
    "        num_classes = 3\n",
    "        n = 2 * n3\n",
    "        self.branch1 = nn.Sequential(\n",
    "            conv3x3(input_channels, n1),\n",
    "            conv3x3(n1, n1),\n",
    "            ResBlock(n1, n2),\n",
    "            ResBlock(n2, n2),\n",
    "            ResBlock(n2, n3))\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv3x3(input_channels, n1),\n",
    "            conv3x3(n1, n1),\n",
    "            conv3x3(n1, n2),\n",
    "            conv3x3(n2, n2),\n",
    "            conv3x3(n2, n2),\n",
    "            conv3x3(n2, n2),\n",
    "            conv3x3(n2, n3),\n",
    "            conv3x3(n3, n3))\n",
    "\n",
    "        self.up3 = nn.Upsample(scale_factor=3, mode='trilinear', align_corners=False) if up else repeat\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            conv3x3(n, m, 1),\n",
    "            conv3x3(m, m, 1),\n",
    "            nn.Conv3d(m, num_classes, 1)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x1, x2 = inputs\n",
    "        x1 = self.branch1(x1)\n",
    "        x2 = self.branch2(x2)\n",
    "        x2 = self.up3(x2)\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af41f8f",
   "metadata": {},
   "source": [
    "### Generalized Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1fe8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralizedDiceLoss(nn.Module):\n",
    "    '''\n",
    "        Following the equation from https://arxiv.org/abs/1707.03237 page 3\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GeneralizedDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, im_pred, im_real):\n",
    "        if len(im_pred.shape) == 4:\n",
    "            im_pred = im_pred.unsqueeze(0)\n",
    "\n",
    "        if len(im_real.shape) == 4:\n",
    "            im_real = im_real.unsqueeze(0)\n",
    "\n",
    "        im_real = im_real.permute((1, 0, 2, 3, 4))\n",
    "        im_pred = im_pred.permute((1, 0, 2, 3, 4))\n",
    "\n",
    "        eps = 1e-12\n",
    "        sum_1 = torch.sum(im_real[0])\n",
    "        sum_2 = torch.sum(im_real[1])\n",
    "        sum_3 = torch.sum(im_real[2])\n",
    "\n",
    "        weight_1 = 1 / (sum_1 ** 2 + eps) if sum_1 > 0 else 1\n",
    "        weight_2 = 1 / (sum_2 ** 2 + eps) if sum_2 > 0 else 1\n",
    "        weight_3 = 1 / (sum_3 ** 2 + eps) if sum_3 > 0 else 1\n",
    "\n",
    "        numerator_1 = torch.sum(im_real[0] * im_pred[0]) * weight_1\n",
    "        numerator_2 = torch.sum(im_real[1] * im_pred[1]) * weight_2\n",
    "        numerator_3 = torch.sum(im_real[2] * im_pred[2]) * weight_3\n",
    "\n",
    "        numerator = numerator_1 + numerator_2 + numerator_3\n",
    "\n",
    "        denominator_1 = (torch.sum(im_real[0]) + torch.sum(im_pred[0])) * weight_1\n",
    "        denominator_2 = (torch.sum(im_real[1]) + torch.sum(im_pred[1])) * weight_2\n",
    "        denominator_3 = (torch.sum(im_real[2]) + torch.sum(im_pred[2])) * weight_3\n",
    "\n",
    "        denominator = denominator_1 + denominator_2 + denominator_3\n",
    "\n",
    "        dice_loss = 1 - ((2 * numerator) / (denominator + eps))\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e78f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Elastic Deformation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfc1ce1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ElasticDeformation:\n",
    "    \"\"\"\n",
    "        Classs containing Elastic Deformation Transformation\n",
    "        Adapted from week 3 AML tutorial materials\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_controlpoints=None, sigma=None):\n",
    "\n",
    "        self.num_controlpoints = num_controlpoints\n",
    "        self.sigma = sigma\n",
    "\n",
    "        # Random parameters if not defined\n",
    "        if self.sigma == None:\n",
    "            self.sigma = np.random.uniform(low=1, high=5)\n",
    "\n",
    "        if self.num_controlpoints == None:\n",
    "            self.num_controlpoints = int(np.random.uniform(low=1, high=6))\n",
    "\n",
    "    def create_elastic_deformation(self, image):\n",
    "        \"\"\"\n",
    "            We need to parameterise our b-spline transform\n",
    "            The transform will depend on such variables as image size and sigma\n",
    "            Sigma modulates the strength of the transformation\n",
    "            The number of control points controls the granularity of our transform\n",
    "        \"\"\"\n",
    "        # Create an instance of a SimpleITK image of the same size as our image\n",
    "        itkimg = sitk.GetImageFromArray(np.zeros(image.shape))\n",
    "\n",
    "        # This parameter is just a list with the number of control points per image dimensions\n",
    "        trans_from_domain_mesh_size = [self.num_controlpoints] * itkimg.GetDimension()\n",
    "\n",
    "        # We initialise the transform here: Passing the image size and the control point specifications\n",
    "        bspline_transformation = sitk.BSplineTransformInitializer(itkimg, trans_from_domain_mesh_size)\n",
    "\n",
    "        # Isolate the transform parameters: They will be all zero at this stage\n",
    "        params = np.asarray(bspline_transformation.GetParameters(), dtype=float)\n",
    "\n",
    "        # Let's initialise the transform by randomly initialising each parameter according to sigma\n",
    "        params = params + np.random.randn(params.shape[0]) * self.sigma\n",
    "\n",
    "        # Let's initialise the transform by randomly displacing each control point by a random distance (magnitude sigma)\n",
    "        bspline_transformation.SetParameters(tuple(params))\n",
    "\n",
    "        return bspline_transformation\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        # We need to choose an interpolation method for our transformed image, let's just go with b-spline\n",
    "        resampler = sitk.ResampleImageFilter()\n",
    "        resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "        # Let's convert our image to an sitk image\n",
    "        sitk_image = sitk.GetImageFromArray(image)\n",
    "\n",
    "        # Specify the image to be transformed: This is the reference image\n",
    "        resampler.SetReferenceImage(sitk_image)\n",
    "        resampler.SetDefaultPixelValue(0)\n",
    "\n",
    "        # Initialise the transform\n",
    "        bspline_transform = self.create_elastic_deformation(image)\n",
    "\n",
    "        # Set the transform in the initialiser\n",
    "        resampler.SetTransform(bspline_transform)\n",
    "\n",
    "        # Carry out the resampling according to the transform and the resampling method\n",
    "        out_img_sitk = resampler.Execute(sitk_image)\n",
    "\n",
    "        # Convert the image back into a python array\n",
    "        out_img = sitk.GetArrayFromImage(out_img_sitk)\n",
    "\n",
    "        # We need to choose an interpolation method for our transformed image, let's just go with b-spline\n",
    "        resampler_label = sitk.ResampleImageFilter()\n",
    "        resampler_label.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "        # Let's convert our image to an sitk image\n",
    "        sitk_label = sitk.GetImageFromArray(label)\n",
    "\n",
    "        # Specify the image to be transformed: This is the reference image\n",
    "        resampler_label.SetReferenceImage(sitk_label)\n",
    "        resampler_label.SetDefaultPixelValue(0)\n",
    "\n",
    "        # Initialise the transform\n",
    "        bspline_transform = self.create_elastic_deformation(label)\n",
    "\n",
    "        # Set the transform in the initialiser\n",
    "        resampler_label.SetTransform(bspline_transform)\n",
    "\n",
    "        # Carry out the resampling according to the transform and the resampling method\n",
    "        out_label_sitk = resampler_label.Execute(sitk_label)\n",
    "\n",
    "        # Convert the image back into a python array\n",
    "        out_label = sitk.GetArrayFromImage(out_label_sitk)\n",
    "\n",
    "        return torch.tensor(out_img.reshape(image.shape), dtype=torch.float32), torch.tensor(out_label.reshape(image.shape), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b39cb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Affine Transformation Class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33a9627",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AffineTransformation:\n",
    "    \"\"\"\n",
    "        Classs containing Elastic Deformation Transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rotation=5, scale=(0.95, 1.05), shear=(0.01, 0.02), return_inverse=False, inverse_matrix=None):\n",
    "        self.rotation = rotation\n",
    "        self.scale = scale\n",
    "        self.shear = shear\n",
    "        self.return_inverse = return_inverse\n",
    "        self.inverse_matrix = inverse_matrix\n",
    "\n",
    "    def get_transformation_matrix(self):\n",
    "        # apply rotation on the z-axis\n",
    "        degree_rotation = torch.tensor(1, dtype=torch.float32).uniform_(-self.rotation, self.rotation)\n",
    "        degree_rotation = (degree_rotation * torch.pi) / 180\n",
    "\n",
    "        matrix_rotation = torch.zeros((1, 4, 4), dtype=torch.float32)\n",
    "        matrix_rotation[0, 0, 0] = torch.cos(degree_rotation)\n",
    "        matrix_rotation[0, 0, 1] = torch.sin(degree_rotation)\n",
    "        matrix_rotation[0, 1, 0] = -torch.sin(degree_rotation)\n",
    "        matrix_rotation[0, 1, 1] = torch.cos(degree_rotation)\n",
    "        matrix_rotation[0, 2, 2] = 1\n",
    "        matrix_rotation[0, 3, 3] = 1\n",
    "\n",
    "        # apply scaling on each dimension\n",
    "        matrix_scale = torch.zeros((1, 4, 4), dtype=torch.float32)\n",
    "        matrix_scale[0, 0, 0] = torch.tensor(1, dtype=torch.float32).uniform_(self.scale[0], self.scale[1])\n",
    "        matrix_scale[0, 1, 1] = torch.tensor(1, dtype=torch.float32).uniform_(self.scale[0], self.scale[1])\n",
    "        matrix_scale[0, 2, 2] = torch.tensor(1, dtype=torch.float32).uniform_(self.scale[0], self.scale[1])\n",
    "        matrix_scale[0, 3, 3] = 1\n",
    "        # print(matrix_scale.shape)\n",
    "\n",
    "        # shear\n",
    "        degree_shear = torch.tensor((\n",
    "            torch.tensor(1, dtype=torch.float32).uniform_(self.shear[0], self.shear[1]),\n",
    "            torch.tensor(1, dtype=torch.float32).uniform_(self.shear[0], self.shear[1])\n",
    "        ))\n",
    "\n",
    "        matrix_shear = torch.zeros((1, 4, 4), dtype=torch.float32)\n",
    "        matrix_shear[0, 0, 0] = 1\n",
    "        matrix_shear[0, 0, 1] = degree_shear[0]\n",
    "        matrix_shear[0, 1, 0] = degree_shear[1]\n",
    "        matrix_shear[0, 1, 1] = 1\n",
    "        matrix_shear[0, 2, 2] = 1\n",
    "        matrix_shear[0, 3, 3] = 1\n",
    "\n",
    "        # generate the combined affine transformation matrix\n",
    "        self.matrix_affine = torch.matmul(matrix_shear, torch.matmul(matrix_rotation, matrix_scale))\n",
    "\n",
    "        # generate the inverse transformation matrix\n",
    "        self.matrix_affine_inv = torch.inverse(self.matrix_affine)\n",
    "\n",
    "        # return to original coordinates\n",
    "        self.matrix_affine = self.matrix_affine[:, 0:3, :]\n",
    "        self.matrix_affine_inv = self.matrix_affine_inv[:, 0:3, :]\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.unsqueeze(0).unsqueeze(0)\n",
    "        if len(label.shape) == 3:\n",
    "            label = label.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # obtain transformation matrix\n",
    "        self.get_transformation_matrix()\n",
    "\n",
    "        # define the affine grid and apply transformation on images and labels\n",
    "        if self.return_inverse:\n",
    "            grid_affine = F.affine_grid(self.matrix_affine_inv, image.shape, align_corners=False)\n",
    "            image_at = F.grid_sample(image.float(), grid_affine, padding_mode=\"border\", align_corners=False)\n",
    "            label_at = F.grid_sample(label.float(), grid_affine, mode='nearest', padding_mode=\"zeros\",\n",
    "                                        align_corners=False)\n",
    "        else:\n",
    "            grid_affine = F.affine_grid(self.matrix_affine, image.shape, align_corners=False)\n",
    "            image_at = F.grid_sample(image.float(), grid_affine, padding_mode=\"border\", align_corners=False)\n",
    "            label_at = F.grid_sample(label.float(), grid_affine, mode='nearest', padding_mode=\"zeros\",\n",
    "                                        align_corners=False)\n",
    "\n",
    "        return image_at.squeeze(0).squeeze(0), label_at.squeeze(0).squeeze(0), self.matrix_affine, self.matrix_affine_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50481ab",
   "metadata": {},
   "source": [
    "### Container class for TRAIN/VAL/EVALUATE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3572a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConainer():\n",
    "    def __init__(self, params_model):\n",
    "        self.params_model = params_model\n",
    "\n",
    "    def __init_train_params(self):\n",
    "        self.run_mode = 'train'\n",
    "\n",
    "        self.loss_dict_train = {\n",
    "            'total': [],\n",
    "            'dice': [],\n",
    "            'mse': [],\n",
    "            'ce': [],\n",
    "            'dice_n_mse': [],\n",
    "            'dice_n_mse_n_ce': []\n",
    "        }\n",
    "\n",
    "        self.loss_dict_val = {\n",
    "            'total': [],\n",
    "            'dice': [],\n",
    "            'mse': [],\n",
    "            'ce': [],\n",
    "            'dice_n_mse': [],\n",
    "            'dice_n_mse_n_ce': []\n",
    "        }\n",
    "\n",
    "        self.loss_best_train = {\n",
    "            'total': np.inf,\n",
    "            'dice': np.inf,\n",
    "            'mse': np.inf,\n",
    "            'ce': np.inf,\n",
    "            'dice_n_mse': np.inf,\n",
    "            'dice_n_mse_n_ce': np.inf\n",
    "        }\n",
    "\n",
    "        self.loss_best_val = {\n",
    "            'total': np.inf,\n",
    "            'dice': np.inf,\n",
    "            'mse': np.inf,\n",
    "            'ce': np.inf,\n",
    "            'dice_n_mse': np.inf,\n",
    "            'dice_n_mse_n_ce': np.inf\n",
    "        }\n",
    "\n",
    "    def __init_inference_params(self):\n",
    "        self.run_mode = 'inference'\n",
    "\n",
    "    def __setup_logger(self):\n",
    "\n",
    "        if not self.params_train['resume_condition']:\n",
    "            reload(logging)\n",
    "\n",
    "        logging.basicConfig(filename=self.params_train['path_logger_full'], encoding='utf-8', level=logging.DEBUG)\n",
    "\n",
    "    def __create_params_file(self):\n",
    "        params_dict = {\n",
    "            'params_model': self.params_model,\n",
    "            'params_train': self.params_train\n",
    "        }\n",
    "\n",
    "        params_dict = json.dumps(params_dict, indent=4, sort_keys=False)\n",
    "\n",
    "        with open(self.params_train['path_params_full'], 'w') as outfile:\n",
    "            outfile.write(params_dict)\n",
    "\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "        self.__print('\\t\\tTraining starting with params:')\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "        self.__print(f'{params_dict}')\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "\n",
    "    def __create_checkpoint_dir(self):\n",
    "        if self.params_train['resume_condition']:\n",
    "            self.params_train['dirname_checkpoint'] = self.params_train['resume_dir'][:11]\n",
    "            self.params_train['path_checkpoint_full'] = self.params_train['resume_dir']\n",
    "        else:\n",
    "            self.params_train['dirname_checkpoint'] = f'{self.params_model[\"experiment_name\"]}__' \\\n",
    "                                                      f'{self.params_model[\"init_timestamp\"]}__' \\\n",
    "                                                      f'{self.params_model[\"model_name\"]}__' \\\n",
    "                                                      f'{self.params_train[\"loss_name\"]}__' \\\n",
    "                                                      f'{self.params_train[\"optimizer_name\"]}__' \\\n",
    "                                                      f'lr_{self.params_train[\"learning_rate\"]}__' \\\n",
    "                                                      f'ep_{self.params_train[\"num_epochs\"]}'\n",
    "\n",
    "            self.params_train['path_checkpoint_full'] = os.path.join(self.params_train['path_checkpoint'],\n",
    "                                                                     self.params_train['dirname_checkpoint'])\n",
    "\n",
    "        self.params_train['path_params_full'] = os.path.join(self.params_train['path_checkpoint_full'],\n",
    "                                                             self.params_train['filename_params'])\n",
    "        self.params_train['path_logger_full'] = os.path.join(self.params_train['path_checkpoint_full'],\n",
    "                                                             self.params_train['filename_logger'])\n",
    "        os.makedirs(self.params_train['path_checkpoint_full'], exist_ok=True)\n",
    "\n",
    "    def train(self, params_train, transform_train=None):\n",
    "        self.params_train = params_train\n",
    "        self.transform_train = transform_train\n",
    "        self.__init_train_params()\n",
    "        self.__create_checkpoint_dir()\n",
    "        self.__create_params_file()\n",
    "        self.__setup_logger()\n",
    "        self.__fit_model()\n",
    "\n",
    "    def inference(self, params_inference):\n",
    "\n",
    "        self.params_inference = params_inference\n",
    "\n",
    "        self.__init_inference_params()\n",
    "        self.__run_inference()\n",
    "\n",
    "    def __set_device(self):\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    def __get_dataloaders(self, run_mode):\n",
    "        if run_mode == 'train':\n",
    "            self.dataset_train = DatasetHepatic(\n",
    "                run_mode='train',\n",
    "                transform_image=self.transform_train,\n",
    "                label_percentage=0.0001,\n",
    "                use_probabilistic=True,\n",
    "                patch_size_normal=self.params_model['patch_size_normal'],\n",
    "                patch_size_low=self.params_model['patch_size_low'],\n",
    "                patch_size_out=self.params_model['patch_size_out'],\n",
    "                patch_low_factor=self.params_model['patch_low_factor'],\n",
    "                create_numpy_dataset=self.params_model['create_numpy_dataset'],\n",
    "                dataset_variant=self.params_model['dataset_variant'],\n",
    "                batch_size_inner=self.params_train['batch_size_inner'],\n",
    "                train_percentage=self.params_train['train_percentage'],\n",
    "                use_elastic_deformation=self.params_train['use_elastic_deformation'],\n",
    "                user_affine_transformation=self.params_train['user_affine_transformation'],\n",
    "                num_controlpoints=self.params_train['num_controlpoints'],\n",
    "                sigma=self.params_train['sigma'],\n",
    "                rotation=self.params_train['rotation'],\n",
    "                scale=self.params_train['scale'],\n",
    "                shear=self.params_train['shear']\n",
    "            )\n",
    "\n",
    "            self.dataset_val = DatasetHepatic(\n",
    "                run_mode='val',\n",
    "                label_percentage=0.0001,\n",
    "                transform_image=None,\n",
    "                use_probabilistic=True,\n",
    "                patch_size_normal=self.params_model['patch_size_normal'],\n",
    "                patch_size_low=self.params_model['patch_size_low'],\n",
    "                patch_size_out=self.params_model['patch_size_out'],\n",
    "                patch_low_factor=self.params_model['patch_low_factor'],\n",
    "                create_numpy_dataset=self.params_model['create_numpy_dataset'],\n",
    "                dataset_variant=self.params_model['dataset_variant'],\n",
    "                batch_size_inner=self.params_train['batch_size_inner'],\n",
    "                train_percentage=self.params_train['train_percentage']\n",
    "            )\n",
    "\n",
    "            self.dataloader_train = DataLoader(\n",
    "                self.dataset_train,\n",
    "                batch_size=self.params_train['batch_size'],\n",
    "                shuffle=True,\n",
    "                num_workers=self.params_train['num_workers'],\n",
    "                pin_memory=self.params_train['pin_memory'],\n",
    "                prefetch_factor=self.params_train['prefetch_factor'],\n",
    "                persistent_workers=self.params_train['persistent_workers']\n",
    "            )\n",
    "\n",
    "            self.dataloader_val = DataLoader(\n",
    "                self.dataset_val,\n",
    "                batch_size=self.params_train['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=self.params_train['num_workers'],\n",
    "                pin_memory=self.params_train['pin_memory'],\n",
    "                prefetch_factor=self.params_train['prefetch_factor'],\n",
    "                persistent_workers=self.params_train['persistent_workers']\n",
    "            )\n",
    "\n",
    "        elif run_mode == 'inference':\n",
    "            self.dataset_inference = DatasetHepatic(\n",
    "                run_mode='inference',\n",
    "                transform_image=None,\n",
    "                label_percentage=0.0001,\n",
    "                use_probabilistic=True,\n",
    "                patch_size_normal=self.params_model['patch_size_normal'],\n",
    "                patch_size_low=self.params_model['patch_size_low'],\n",
    "                patch_size_out=self.params_model['patch_size_out'],\n",
    "                patch_low_factor=self.params_model['patch_low_factor'],\n",
    "                create_numpy_dataset=self.params_model['create_numpy_dataset'],\n",
    "                dataset_variant=self.params_model['dataset_variant']\n",
    "            )\n",
    "\n",
    "            self.dataloader_inference = DataLoader(\n",
    "                self.dataset_inference,\n",
    "                batch_size=self.params_inference['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=self.params_inference['num_workers'],\n",
    "                pin_memory=self.params_inference['pin_memory'],\n",
    "                prefetch_factor=self.params_inference['prefetch_factor'],\n",
    "                persistent_workers=self.params_inference['persistent_workers']\n",
    "            )\n",
    "\n",
    "    def __define_model(self):\n",
    "        if self.params_model['model_name'] == 'deep_medic':\n",
    "            self.model = DeepMedic().to(self.device)\n",
    "\n",
    "    def __define_criterions(self):\n",
    "        self.criterion_mse = nn.MSELoss()\n",
    "        self.criterion_dice = GeneralizedDiceLoss()\n",
    "        self.criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def __define_optimizr(self):\n",
    "        if self.params_train['optimizer_name'] == 'adam':\n",
    "            self.optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.params_train['learning_rate'],\n",
    "                betas=(self.params_train['beta_1'], self.params_train['beta_2']),\n",
    "                amsgrad=self.params_train['use_amsgrad']\n",
    "            )\n",
    "\n",
    "        elif self.params_train['optimizer_name'] == 'sgd_w_momentum':\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.params_train['learning_rate'],\n",
    "                momentum=self.params_train['momentum']\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(f'Invalid choice of optimizer:\\t{self.params_train[\"optimizer_name\"]}')\n",
    "\n",
    "    def __define_lr_scheduler(self):\n",
    "        if self.params_train['lr_scheduler_name'] == 'plateau':\n",
    "            self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                patience=self.params_train['patience_lr_scheduler'],\n",
    "                factor=self.params_train['factor_lr_scheduler'],\n",
    "                verbose=True)\n",
    "\n",
    "    def __put_to_device(self, device, tensors):\n",
    "        for index, tensor in enumerate(tensors):\n",
    "            tensors[index] = tensor.to(device)\n",
    "        return tensors\n",
    "\n",
    "    def __get_one_hot_labels(self, input, labels, squeeze_dim=None):\n",
    "        output = torch.zeros((input.shape[0], len(labels), input.shape[2], input.shape[3], input.shape[4]),\n",
    "                             dtype=input.dtype).to(input.device)\n",
    "\n",
    "        if not squeeze_dim is None:\n",
    "            for index, label in enumerate(labels):\n",
    "                output[:, index] = torch.where(input == label, 1, 0).squeeze(squeeze_dim)\n",
    "        else:\n",
    "            for index, label in enumerate(labels):\n",
    "                output[:, label] = torch.where(input == label, 1, 0)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __criterion_generalized_dice(self, im_real, im_pred):\n",
    "        '''\n",
    "            Following the equation from https://arxiv.org/abs/1707.03237 page 3\n",
    "        '''\n",
    "        weights = torch.autograd.Variable(3, dtype=torch.float64, requires_grad=True)\n",
    "        for index in range(3):\n",
    "            count = torch.tensor(torch.sum(torch.where(im_real == index, 1, 0)), dtype=torch.double, requires_grad=True)\n",
    "            # if none of the voxels are of the current category, set weight to 1\n",
    "            if count == 0:\n",
    "                weights[index] = torch.tensor(1, dtype=torch.double, requires_grad=True)\n",
    "            else:\n",
    "                weights[index] = 1 / count ** 2\n",
    "\n",
    "        numerator = torch.zeros(3, dtype=torch.double, requires_grad=True)\n",
    "        denominator = torch.zeros(3, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "        for index in range(3):\n",
    "            r_l_n = torch.where(im_real == index, 1, 0)\n",
    "            p_l_n = torch.where(im_pred == index, 1, 0)\n",
    "\n",
    "            # numerator\n",
    "            mult = r_l_n * p_l_n\n",
    "            numerator[index] = weights[index] * torch.sum(mult)\n",
    "\n",
    "            current_denominator = weights[index] * (torch.sum(r_l_n) + torch.sum(p_l_n))\n",
    "            denominator[index] = current_denominator\n",
    "\n",
    "        dice_loss = 1 - (2 * torch.sum(numerator) / torch.sum(denominator))\n",
    "\n",
    "        return dice_loss\n",
    "\n",
    "    def __save_model(self):\n",
    "        '''\n",
    "            Saves the model, best and the latest\n",
    "        '''\n",
    "        if self.params_train['save_condition']:\n",
    "\n",
    "            save_dict = {\n",
    "                'index_epoch': self.index_epoch + 1,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': self.lr_scheduler.state_dict(),\n",
    "                'params_model': self.params_model,\n",
    "                'params_train': self.params_train,\n",
    "                'loss_dict_train': self.loss_dict_train,\n",
    "                'loss_dict_val': self.loss_dict_val,\n",
    "                'loss_best_train': self.loss_best_train,\n",
    "                'loss_best_val': self.loss_best_val\n",
    "            }\n",
    "\n",
    "            # save models at each epoch\n",
    "            if self.params_train['save_every_epoch']:\n",
    "                save_path = os.path.join(self.params_train['path_checkpoint_full'], f'{self.index_epoch + 1}.pth')\n",
    "                torch.save(save_dict, save_path)\n",
    "\n",
    "            # save the latest model\n",
    "            save_path = os.path.join(self.params_train['path_checkpoint_full'], f'latest.pth')\n",
    "            torch.save(save_dict, save_path)\n",
    "\n",
    "            if self.loss_dict_val['total'][-1] <= min(self.loss_dict_val['total']):\n",
    "                save_path = os.path.join(self.params_train['path_checkpoint_full'], f'best.pth')\n",
    "                torch.save(save_dict, save_path)\n",
    "                self.__print(f'{\"*\" * 10}\\tNew best model saved at:\\t{self.index_epoch + 1}\\t{\"*\" * 10}')\n",
    "\n",
    "    def __load_model(self):\n",
    "        '''\n",
    "            Loads the model\n",
    "        '''\n",
    "        if self.run_mode == 'train':\n",
    "            if self.params_train['resume_condition']:\n",
    "                filename_checkpoint = f'{self.params_train[\"resume_epoch\"]}.pth'\n",
    "                load_path = os.path.join(self.params_train['path_checkpoint'],\n",
    "                                         self.params_train['resume_dir'],\n",
    "                                         filename_checkpoint)\n",
    "\n",
    "                if not os.path.exists(load_path):\n",
    "                    raise FileNotFoundError(f'File {load_path} doesn\\'t exist')\n",
    "\n",
    "                checkpoint = torch.load(load_path)\n",
    "\n",
    "                self.index_epoch = checkpoint['index_epoch']\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                self.lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "                self.params_model = checkpoint['params_model']\n",
    "                self.params_train = checkpoint['params_train']\n",
    "                self.loss_dict_train = checkpoint['loss_dict_train']\n",
    "                self.loss_dict_val = checkpoint['loss_dict_val']\n",
    "                self.loss_best_train = checkpoint['loss_best_train']\n",
    "                self.loss_best_val = checkpoint['loss_best_val']\n",
    "\n",
    "                self.__print(f'Model loaded from epoch:\\t{self.index_epoch}')\n",
    "                self.index_epoch += 1\n",
    "                self.start_epoch = self.index_epoch\n",
    "                self.__print(f'Resuming training from epoch:\\t{self.index_epoch}')\n",
    "\n",
    "        elif self.run_mode == 'inference':\n",
    "            filename_checkpoint = f'{self.params_inference[\"resume_epoch\"]}.pth'\n",
    "            load_path = os.path.join(self.params_inference['path_checkpoint'],\n",
    "                                     self.params_inference['resume_dir'],\n",
    "                                     filename_checkpoint)\n",
    "\n",
    "            if not os.path.exists(load_path):\n",
    "                raise FileNotFoundError(f'File {load_path} doesn\\'t exist')\n",
    "\n",
    "            checkpoint = torch.load(load_path)\n",
    "            self.index_epoch = checkpoint['index_epoch']\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.params_model = checkpoint['params_model']\n",
    "            self.index_epoch += 1\n",
    "            self.__print(f'Model loaded from epoch:\\t{self.index_epoch}')\n",
    "\n",
    "    def __early_stop(self):\n",
    "        '''\n",
    "            If early stopping condition meets, break training\n",
    "        '''\n",
    "        # train for at least self.params_train['min_epochs_to_train'] epochs\n",
    "        if self.index_epoch > self.params_train['min_epochs_to_train']:\n",
    "\n",
    "            # if the latest loss is lower than the best, continue training,\n",
    "            # otherwise check the last x losses loss_dict_val\n",
    "            # if self.loss_best_val['total'][-1] < min(self.loss_best_val['total']):\n",
    "            if self.loss_dict_val['total'][-1] < min(self.loss_dict_val['total']):\n",
    "                self.break_training_condition = False\n",
    "            else:\n",
    "                index_start = len(self.loss_dict_val['total']) - 1\n",
    "                index_stop = len(self.loss_dict_val['total']) - 1 - self.params_train['patience_early_stop']\n",
    "\n",
    "                # if any of the last x losses are greater than the best loss, increase counter\n",
    "                counter = 0\n",
    "                for index in range(index_start, index_stop, -1):\n",
    "                    if self.loss_dict_val['total'][index] > min(self.loss_dict_val['total']):\n",
    "                        counter += 1\n",
    "\n",
    "                # if counter equals the patience, break training\n",
    "                if counter >= self.params_train['patience_early_stop']:\n",
    "                    self.__print(f'Early stopping at epoch:\\t{self.index_epoch + 1}')\n",
    "                    self.break_training_condition = True\n",
    "\n",
    "    def __run_epoch(self, dataloader, run_mode):\n",
    "        '''\n",
    "            Runs one epoch of training and validation loops\n",
    "        '''\n",
    "        loss_list_total = []\n",
    "        loss_list_dice = []\n",
    "        loss_list_ce = []\n",
    "        loss_list_mse = []\n",
    "        loss_list_dice_n_mse = []\n",
    "        loss_list_dice_n_mse_n_ce = []\n",
    "\n",
    "        loss_total, loss_dice, loss_mse, loss_ce, loss_dice_n_mse, loss_dice_n_mse_n_ce = np.Inf, np.Inf, np.Inf, np.Inf, np.Inf, np.inf\n",
    "\n",
    "        for index_batch, batch in tqdm(enumerate(dataloader), leave=False, total=len(dataloader)):\n",
    "            if run_mode == 'train':\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "            else:\n",
    "                self.model.eval()\n",
    "\n",
    "            (image_patch_normal, image_patch_low_up, label_patch_out_real) = self.__put_to_device(self.device, batch)\n",
    "\n",
    "            if self.params_train['batch_size_inner'] > 1:\n",
    "                if len(image_patch_normal.shape) == 6:\n",
    "                    batch_size_stacked = image_patch_normal.shape[0] * image_patch_normal.shape[1]\n",
    "\n",
    "                    image_patch_normal = image_patch_normal.reshape(batch_size_stacked, image_patch_normal.shape[2],\n",
    "                                                                    image_patch_normal.shape[3],\n",
    "                                                                    image_patch_normal.shape[4],\n",
    "                                                                    image_patch_normal.shape[5])\n",
    "                    image_patch_low_up = image_patch_low_up.reshape(batch_size_stacked, image_patch_low_up.shape[2],\n",
    "                                                                    image_patch_low_up.shape[3],\n",
    "                                                                    image_patch_low_up.shape[4],\n",
    "                                                                    image_patch_low_up.shape[5])\n",
    "                    label_patch_out_real = label_patch_out_real.reshape(batch_size_stacked,\n",
    "                                                                        label_patch_out_real.shape[2],\n",
    "                                                                        label_patch_out_real.shape[3],\n",
    "                                                                        label_patch_out_real.shape[4],\n",
    "                                                                        label_patch_out_real.shape[5])\n",
    "\n",
    "                    image_patch_low = torch.zeros((image_patch_low_up.shape[0],\n",
    "                                                   self.params_model['patch_size_low'],\n",
    "                                                   self.params_model['patch_size_low'],\n",
    "                                                   self.params_model['patch_size_low'])).to(self.device)\n",
    "\n",
    "                else:\n",
    "                    image_patch_normal, image_patch_low_up, label_patch_out_real = image_patch_normal.squeeze(\n",
    "                        0), image_patch_low_up.squeeze(0), label_patch_out_real.squeeze(0)\n",
    "\n",
    "                image_patch_low = torch.zeros((image_patch_low_up.shape[0],\n",
    "                                               image_patch_low_up.shape[1],\n",
    "                                               self.params_model['patch_size_low'],\n",
    "                                               self.params_model['patch_size_low'],\n",
    "                                               self.params_model['patch_size_low'])).to(self.device)\n",
    "\n",
    "                for index, current_low_up in enumerate(image_patch_low_up):\n",
    "                    current_low = F.avg_pool3d(input=current_low_up, kernel_size=3, stride=None)\n",
    "                    image_patch_low[index] = copy.deepcopy(current_low.detach())\n",
    "\n",
    "            # forward pass\n",
    "            label_patch_out_pred = self.model.forward((image_patch_normal, image_patch_low))\n",
    "\n",
    "            # convert label_patch_out_real to one hot\n",
    "            label_patch_out_real_one_hot = self.__get_one_hot_labels(label_patch_out_real, labels=[0, 1, 2],\n",
    "                                                                     squeeze_dim=1)\n",
    "\n",
    "            # generalized dice loss_total # dice, mse, dice_n_mse\n",
    "            if self.params_train['loss_name'] == 'dice':\n",
    "                loss_dice = self.criterion_dice(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                                label_patch_out_real_one_hot.float())\n",
    "                loss_list_dice.append(loss_dice.item())\n",
    "                # print(f'loss_dice:\\t{loss_dice.item():.5f}')\n",
    "                loss_total = loss_dice\n",
    "            elif self.params_train['loss_name'] == 'mse':\n",
    "                loss_mse = self.criterion_mse(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                              label_patch_out_real_one_hot.float())\n",
    "                loss_list_mse.append(loss_mse.item())\n",
    "                loss_total = loss_mse\n",
    "            elif self.params_train['loss_name'] == 'ce':\n",
    "                loss_ce = self.criterion_ce(label_patch_out_pred.float(), label_patch_out_real.squeeze(1).long())\n",
    "                loss_list_ce.append(loss_ce.item())\n",
    "                loss_total = loss_ce\n",
    "            elif self.params_train['loss_name'] == 'dice_n_mse':\n",
    "                loss_dice = self.criterion_dice(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                                label_patch_out_real_one_hot.float())\n",
    "                loss_mse = self.criterion_mse(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                              label_patch_out_real_one_hot.float())\n",
    "                loss_dice_n_mse = loss_dice + loss_mse\n",
    "                loss_total = loss_dice_n_mse\n",
    "                loss_list_dice.append(loss_dice.item())\n",
    "                loss_list_mse.append(loss_mse.item())\n",
    "                loss_list_dice_n_mse.append(loss_dice_n_mse.item())\n",
    "            elif self.params_train['loss_name'] == 'dice_n_mse_n_ce':\n",
    "                loss_dice = self.criterion_dice(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                                label_patch_out_real_one_hot.float())\n",
    "                loss_mse = self.criterion_mse(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                              label_patch_out_real_one_hot.float())\n",
    "                loss_ce = self.criterion_ce(label_patch_out_pred.float(), label_patch_out_real.squeeze(1).long())\n",
    "\n",
    "                loss_dice_n_mse_n_ce = loss_dice + loss_mse + loss_ce\n",
    "\n",
    "                loss_total = loss_dice_n_mse_n_ce\n",
    "                loss_list_dice.append(loss_dice.item())\n",
    "                loss_list_mse.append(loss_mse.item())\n",
    "                loss_list_ce.append(loss_ce.item())\n",
    "                loss_list_dice_n_mse_n_ce.append(loss_dice_n_mse_n_ce.item())\n",
    "            else:\n",
    "                raise NotImplementedError(f'Invalid criterion selected:\\t{self.params_train[\"loss_name\"]}')\n",
    "\n",
    "            loss_list_total.append(loss_total)\n",
    "\n",
    "            if run_mode == 'train':\n",
    "                # calculate gradients and update weights\n",
    "                loss_total.backward()\n",
    "                self.optimizer.step()\n",
    "            sep = '\\t' if run_mode == 'train' else '\\t\\t'\n",
    "            # self.__print(f'\\tBatch:\\t[{index_batch + 1} / {len(dataloader)}]'\n",
    "            #                f'\\n\\t\\t{str(run_mode).upper()}{sep}-->\\t\\tLoss ({self.params_train[\"loss_name\"]}):\\t\\t{loss_total.item():.5f}')\n",
    "\n",
    "            # ###############################\n",
    "            # loss_mse = self.criterion_mse(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "            #                               label_patch_out_real_one_hot.float())\n",
    "            # loss_list_mse.append(loss_mse.item())\n",
    "            #\n",
    "            # print(f'Loss ({self.params_train[\"loss_name\"]}):\\t{loss_total.item():.5f}\\t\\tMSE:\\t{loss_mse.item()}')\n",
    "            # ###############################\n",
    "\n",
    "            # print(loss_dice.item())\n",
    "            # print(loss_mse.item())\n",
    "            # print(loss_list_dice_n_mse.item())\n",
    "            # break\n",
    "\n",
    "        # loss_dice = sum(loss_list_dice) / len(loss_list_dice)\n",
    "        # loss_mse = 0\n",
    "        # loss_dice_n_mse = 0\n",
    "\n",
    "        if len(loss_list_total) > 0:\n",
    "            loss_total = sum(loss_list_total) / len(loss_list_total)\n",
    "        if len(loss_list_dice) > 0:\n",
    "            loss_dice = sum(loss_list_dice) / len(loss_list_dice)\n",
    "        if len(loss_list_mse) > 0:\n",
    "            loss_mse = sum(loss_list_mse) / len(loss_list_mse)\n",
    "        if len(loss_list_ce) > 0:\n",
    "            loss_ce = sum(loss_list_ce) / len(loss_list_ce)\n",
    "        if len(loss_list_dice_n_mse) > 0:\n",
    "            loss_dice_n_mse = sum(loss_list_dice_n_mse) / len(loss_list_dice_n_mse)\n",
    "        if len(loss_list_dice_n_mse_n_ce) > 0:\n",
    "            loss_dice_n_mse_n_ce = sum(loss_list_dice_n_mse_n_ce) / len(loss_list_dice_n_mse_n_ce)\n",
    "\n",
    "        if run_mode == 'train':\n",
    "            self.loss_dict_train['total'].append(loss_total.item())\n",
    "            self.loss_dict_train['dice'].append(loss_dice)\n",
    "            self.loss_dict_train['mse'].append(loss_mse)\n",
    "            self.loss_dict_train['ce'].append(loss_ce)\n",
    "            self.loss_dict_train['dice_n_mse'].append(loss_dice_n_mse)\n",
    "            self.loss_dict_train['dice_n_mse_n_ce'].append(loss_dice_n_mse_n_ce)\n",
    "\n",
    "        elif run_mode == 'val':\n",
    "            self.loss_dict_val['total'].append(loss_total.item())\n",
    "            self.loss_dict_val['dice'].append(loss_dice)\n",
    "            self.loss_dict_val['mse'].append(loss_mse)\n",
    "            self.loss_dict_val['ce'].append(loss_ce)\n",
    "            self.loss_dict_val['dice_n_mse'].append(loss_dice_n_mse)\n",
    "            self.loss_dict_val['dice_n_mse_n_ce'].append(loss_dice_n_mse_n_ce)\n",
    "\n",
    "    def __update_best_losses(self):\n",
    "        '''\n",
    "            Updates the best loss found so far\n",
    "        '''\n",
    "        self.found_best_loss_flag = False\n",
    "\n",
    "        for (key, value) in self.loss_dict_train.items():\n",
    "            if self.loss_dict_train[key][-1] < min(self.loss_dict_train[key]):\n",
    "                self.loss_best_train[key] = self.loss_dict_train[key][-1]\n",
    "                # if self.params_train['loss_name'] == key:\n",
    "                #     self.found_best_loss_flag = True\n",
    "\n",
    "        for (key, value) in self.loss_dict_val.items():\n",
    "            if self.loss_dict_val[key][-1] < min(self.loss_dict_val[key]):\n",
    "                self.loss_best_val[key] = self.loss_dict_val[key][-1]\n",
    "                if self.params_train['loss_name'] == key:\n",
    "                    self.found_best_loss_flag = True\n",
    "\n",
    "    def __print(self, message):\n",
    "        print(message)\n",
    "        logging.debug(message)\n",
    "        logging.debug('working')\n",
    "\n",
    "    def __fit_model(self):\n",
    "        '''\n",
    "            Trains and validates a model given hyperparameters, model and optimizer name, dataloaders, num_epochs\n",
    "        '''\n",
    "\n",
    "        # set up dataloaders, model, criterions, optimizers, schedulers\n",
    "        self.__set_device()\n",
    "        self.__get_dataloaders('train')\n",
    "        self.__define_model()\n",
    "        self.__define_criterions()\n",
    "        self.__define_optimizr()\n",
    "        self.__define_lr_scheduler()\n",
    "\n",
    "        # variables to keep track of training progress\n",
    "        self.start_epoch = 0\n",
    "        self.break_training_condition = False\n",
    "        self.end_epoch = self.params_train['num_epochs']\n",
    "\n",
    "        self.__load_model()\n",
    "\n",
    "        for index_epoch in range(self.start_epoch, self.end_epoch):\n",
    "            time_start = time.time()\n",
    "            self.index_epoch = index_epoch\n",
    "\n",
    "            # train\n",
    "            self.__run_epoch(\n",
    "                dataloader=self.dataloader_train,\n",
    "                run_mode='train'\n",
    "            )\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                self.__run_epoch(\n",
    "                    dataloader=self.dataloader_val,\n",
    "                    run_mode='val'\n",
    "                )\n",
    "\n",
    "            # choose which loss to put into the scheduler\n",
    "            self.lr_scheduler.step(self.loss_dict_val['total'][-1])\n",
    "\n",
    "            duration = time.time() - time_start\n",
    "\n",
    "            self.__print(f'\\n{\"-\" * 100}'\n",
    "                         f'\\nEpoch:\\t[{index_epoch + 1} / {self.end_epoch}]\\t\\t'\n",
    "                         f'Time:\\t{duration:.2f} s'\n",
    "                         f'\\n\\tTRAIN\\t\\t-->\\t\\tLoss Total:\\t\\t{self.loss_dict_train[\"total\"][-1]:.5f}'\n",
    "                         f'\\n\\tVAL\\t\\t\\t-->\\t\\tLoss Total:\\t\\t{self.loss_dict_val[\"total\"][-1]:.5f}'\n",
    "                         f'\\t\\tBest:\\t{min(self.loss_dict_val[\"total\"]):.5f}'\n",
    "                         f'\\n{\"-\" * 100}\\n')\n",
    "\n",
    "            self.__update_best_losses()\n",
    "            self.__save_model()\n",
    "            self.__early_stop()\n",
    "            # self.__early_stopper()\n",
    "\n",
    "            if self.break_training_condition:\n",
    "                break\n",
    "\n",
    "    def __run_inference(self):\n",
    "        '''\n",
    "            Run 3D inference on the validation set. Generates a 3D volume of predicted labels with same shape as the original one\n",
    "        '''\n",
    "        self.__set_device()\n",
    "        self.__get_dataloaders('inference')\n",
    "        self.__define_model()\n",
    "        self.__define_criterions()\n",
    "        self.__load_model()\n",
    "\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "        self.__print('\\t\\tInference starting with params:')\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "        params_dict = {\n",
    "            'params_model': self.params_model,\n",
    "            'params_inference': self.params_inference\n",
    "        }\n",
    "        params_dict = json.dumps(params_dict, indent=4, sort_keys=False)\n",
    "        self.__print(f'{params_dict}')\n",
    "        self.__print(f'{\"*\" * 100}')\n",
    "\n",
    "        for index_batch, batch in enumerate(self.dataloader_inference):\n",
    "            # save only the last 30 samples to match with other group members\n",
    "            if index_batch < 31:\n",
    "                continue\n",
    "            images, labels_real, index_filename = batch\n",
    "            (images, labels_real) = self.__put_to_device(self.device, [images, labels_real])\n",
    "\n",
    "            labels_pred, labels_pred_probabilistic, loss_dice, loss_mse = self.__stride_depth_and_inference(\n",
    "                images_real=images,\n",
    "                labels_real=labels_real\n",
    "            )\n",
    "            # assuming the batch size == 1\n",
    "            index_filename = index_filename[0]\n",
    "            self.__print(\n",
    "                f'{index_batch + 1}: \\t{index_batch}.npy\\tLoss DICE:\\t{loss_dice:.5f}\\tLoss MSE:\\t{loss_mse:.5f}')\n",
    "\n",
    "            labels_real, labels_pred, labels_pred_probabilistic = labels_real.cpu().detach().numpy(), labels_pred.cpu().detach().numpy(), labels_pred_probabilistic.cpu().detach().numpy()\n",
    "\n",
    "            predictions_path = os.path.join('.', 'Ensamble', 'Abhijit')\n",
    "            labels_path = os.path.join('.', 'labels_true')\n",
    "            os.makedirs(predictions_path, exist_ok=True)\n",
    "            os.makedirs(labels_path, exist_ok=True)\n",
    "            # saves the probabilistic outputs (bs x 3 x h x w x d)\n",
    "\n",
    "            # save predictions\n",
    "            np.save(os.path.join(predictions_path, f'{index_batch}.npy'), labels_pred_probabilistic,\n",
    "                    allow_pickle=True)\n",
    "\n",
    "            # save the actual labels\n",
    "            np.save(os.path.join(labels_path, f'{index_batch}.npy'), labels_real,\n",
    "                    allow_pickle=True)\n",
    "\n",
    "    def __stride_depth_and_inference(self, images_real, labels_real):\n",
    "        self.model.eval()\n",
    "        patch_size_normal = self.params_model['patch_size_normal']\n",
    "        patch_size_low = self.params_model['patch_size_low']\n",
    "        patch_size_out = self.params_model['patch_size_out']\n",
    "        patch_low_factor = self.params_model['patch_low_factor']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_list_dice = []\n",
    "            loss_list_mse = []\n",
    "\n",
    "            device = images_real.device\n",
    "            batch_size, height, width, depth = images_real.shape\n",
    "\n",
    "            # --------- loop through the whole image volume\n",
    "            patch_size_low_up = patch_size_low * patch_low_factor\n",
    "\n",
    "            patch_half_normal = (patch_size_normal - 1) // 2\n",
    "            patch_half_low = (patch_size_low - 1) // 2\n",
    "            patch_half_low_up = (patch_size_low_up - 1) // 2\n",
    "            patch_half_out = (patch_size_out - 1) // 2\n",
    "\n",
    "            height_new = height + patch_size_low_up\n",
    "            width_new = width + patch_size_low_up\n",
    "            depth_new = depth + patch_size_low_up\n",
    "\n",
    "            # create a placeholder for the padded image\n",
    "            images_padded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32).to(device)\n",
    "            labels_real_padded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32).to(\n",
    "                device)\n",
    "\n",
    "            # labels_padded = torch.zeros((batch_size, height_new, width_new, depth_new), dtype=torch.float32).to(device)\n",
    "            # print(f'images_real.shape:\\t{images_real.shape}')\n",
    "            # print(f'images_padded.shape:\\t{images_padded.shape}')\n",
    "\n",
    "            # copy the original image to the placeholder\n",
    "            images_padded[\n",
    "            :,\n",
    "            patch_half_low_up: height + patch_half_low_up,\n",
    "            patch_half_low_up: width + patch_half_low_up,\n",
    "            patch_half_low_up: depth + patch_half_low_up\n",
    "            ] = copy.deepcopy(images_real).to(device)\n",
    "\n",
    "            labels_real_padded[\n",
    "            :,\n",
    "            patch_half_low_up: height + patch_half_low_up,\n",
    "            patch_half_low_up: width + patch_half_low_up,\n",
    "            patch_half_low_up: depth + patch_half_low_up\n",
    "            ] = copy.deepcopy(labels_real).to(device)\n",
    "\n",
    "            # print(f'{patch_half_low_up} -> {height + patch_half_low_up}')\n",
    "            # print(f'{patch_half_low_up} -> {width + patch_half_low_up}')\n",
    "            # print(f'{patch_half_low_up} -> {depth + patch_half_low_up}')\n",
    "\n",
    "            # placeholder to store the inferred/reconstructed image labels\n",
    "            labels_pred_whole_image = torch.zeros_like(images_real).to(device)\n",
    "            labels_pred_whole_image_probabilistic = torch.zeros((batch_size, 3, height, width, depth),\n",
    "                                                                dtype=torch.float32).to(device)\n",
    "            # print(f'labels_pred_whole_image.shape:\\t{labels_pred_whole_image.shape}')\n",
    "\n",
    "            # indices of the original image\n",
    "            h_start_orig = 0\n",
    "            h_end_orig = h_start_orig + patch_size_out\n",
    "\n",
    "            for index_h in tqdm(range(patch_half_low_up, height_new - patch_half_low_up, patch_size_out),\n",
    "                                leave=False):\n",
    "                # print(index_h)\n",
    "                h_start_normal = index_h - patch_half_normal\n",
    "                h_end_normal = index_h + patch_half_normal + 1\n",
    "\n",
    "                h_start_low_up = index_h - patch_half_low_up\n",
    "                h_end_low_up = index_h + patch_half_low_up + 1\n",
    "\n",
    "                h_start_out = index_h - patch_half_out\n",
    "                h_end_out = index_h + patch_half_out + 1\n",
    "\n",
    "                # if the starting index of the out height > padded height; break\n",
    "                if h_end_out > height_new:\n",
    "                    break\n",
    "\n",
    "                w_start_orig = 0\n",
    "                w_end_orig = w_start_orig + patch_size_out\n",
    "\n",
    "                for index_w in range(patch_half_low_up, width_new - patch_half_low_up, patch_size_out):\n",
    "\n",
    "                    w_start_normal = index_w - patch_half_normal\n",
    "                    w_end_normal = index_w + patch_half_normal + 1\n",
    "\n",
    "                    w_start_low_up = index_w - patch_half_low_up\n",
    "                    w_end_low_up = index_w + patch_half_low_up + 1\n",
    "\n",
    "                    w_start_out = index_w - patch_half_out\n",
    "                    w_end_out = index_w + patch_half_out + 1\n",
    "\n",
    "                    if w_end_out > width_new:\n",
    "                        break\n",
    "\n",
    "                    d_start_orig = 0\n",
    "                    d_end_orig = d_start_orig + patch_size_out\n",
    "\n",
    "                    for index_d in range(patch_half_low_up, depth_new - patch_half_low_up, patch_size_out):\n",
    "\n",
    "                        d_start_normal = index_d - patch_half_normal\n",
    "                        d_end_normal = index_d + patch_half_normal + 1\n",
    "\n",
    "                        d_start_low_up = index_d - patch_half_low_up\n",
    "                        d_end_low_up = index_d + patch_half_low_up + 1\n",
    "\n",
    "                        d_start_out = index_d - patch_half_out\n",
    "                        d_end_out = index_d + patch_half_out + 1\n",
    "\n",
    "                        if d_end_out > depth_new:\n",
    "                            break\n",
    "\n",
    "                        # extract the current patch of the expanded image\n",
    "                        image_patch_normal = images_padded[\n",
    "                                             :,\n",
    "                                             h_start_normal: h_end_normal,\n",
    "                                             w_start_normal: w_end_normal,\n",
    "                                             d_start_normal: d_end_normal\n",
    "                                             ]\n",
    "                        # print('\\nNormal')\n",
    "                        # print(f'{h_start_normal} -> {h_end_normal}')\n",
    "                        # print(f'{w_start_normal} -> {w_end_normal}')\n",
    "                        # print(f'{d_start_normal} -> {d_end_normal}')\n",
    "\n",
    "                        image_patch_low_up = images_padded[\n",
    "                                             :,\n",
    "                                             h_start_low_up: h_end_low_up,\n",
    "                                             w_start_low_up: w_end_low_up,\n",
    "                                             d_start_low_up: d_end_low_up\n",
    "                                             ]\n",
    "\n",
    "                        # print('\\nlow_up')\n",
    "                        # print(f'{h_start_low_up} -> {h_end_low_up}')\n",
    "                        # print(f'{w_start_low_up} -> {w_end_low_up}')\n",
    "                        # print(f'{d_start_low_up} -> {d_end_low_up}')\n",
    "\n",
    "                        # extract the current output patch of the expanded label\n",
    "                        label_patch_out_real = labels_real_padded[\n",
    "                                               :,\n",
    "                                               h_start_out: h_end_out,\n",
    "                                               w_start_out: w_end_out,\n",
    "                                               d_start_out: d_end_out\n",
    "                                               ]\n",
    "                        # print('\\nout')\n",
    "                        # print(f'{h_start_out} -> {h_end_out}')\n",
    "                        # print(f'{w_start_out} -> {w_end_out}')\n",
    "                        # print(f'{d_start_out} -> {d_end_out}')\n",
    "\n",
    "                        # if d_start_out == 42:\n",
    "                        #     print('sssss')\n",
    "\n",
    "                        if not (label_patch_out_real.shape[1] * label_patch_out_real.shape[2] *\n",
    "                                label_patch_out_real.shape[3] > 0):\n",
    "                            # print('here')\n",
    "                            continue\n",
    "\n",
    "                        # pad uneven images (image patch normal)\n",
    "                        image_patch_normal_temp = torch.zeros(\n",
    "                            (batch_size, patch_size_normal, patch_size_normal, patch_size_normal)).to(device)\n",
    "                        image_patch_normal_temp[:, :image_patch_normal.shape[1], :image_patch_normal.shape[2],\n",
    "                        :image_patch_normal.shape[3]] = image_patch_normal\n",
    "                        image_patch_normal = image_patch_normal_temp\n",
    "\n",
    "                        # pad uneven images (image patch low_up)\n",
    "                        image_patch_low_up_temp = torch.zeros(\n",
    "                            (batch_size, patch_size_low_up, patch_size_low_up, patch_size_low_up)).to(device)\n",
    "                        image_patch_low_up_temp[:, :image_patch_low_up.shape[1], :image_patch_low_up.shape[2],\n",
    "                        :image_patch_low_up.shape[3]] = image_patch_low_up\n",
    "                        image_patch_low_up = image_patch_low_up_temp\n",
    "\n",
    "                        # resize (downsample) image_patch_low\n",
    "                        image_patch_low = F.avg_pool3d(input=image_patch_low_up, kernel_size=3, stride=None)\n",
    "\n",
    "                        # perform forward pass\n",
    "                        label_patch_out_pred = self.model.forward(\n",
    "                            (image_patch_normal.unsqueeze(0), image_patch_low.unsqueeze(0)))\n",
    "\n",
    "                        # print(label_patch_out_real.shape)\n",
    "                        # clip extra parts\n",
    "                        if label_patch_out_real.shape[1] < patch_size_out:\n",
    "                            label_patch_out_pred = label_patch_out_pred[:, :, :label_patch_out_real.shape[1], :, :]\n",
    "\n",
    "                        if label_patch_out_real.shape[2] < patch_size_out:\n",
    "                            label_patch_out_pred = label_patch_out_pred[:, :, :, :label_patch_out_real.shape[2], :]\n",
    "\n",
    "                        if label_patch_out_real.shape[3] < patch_size_out:\n",
    "                            label_patch_out_pred = label_patch_out_pred[:, :, :, :, :label_patch_out_real.shape[3]]\n",
    "\n",
    "                        # # remove any dimensions with 0 elements\n",
    "                        # if (label_patch_out_pred.shape[2] == 0) or (label_patch_out_pred.shape[3] == 0) or (label_patch_out_pred.shape[4] == 0) or (\n",
    "                        #         label_patch_out_real.shape[2] == 0) or (label_patch_out_real.shape[3] == 0) or (\n",
    "                        #         label_patch_out_real.shape[4] == 0):\n",
    "                        #     break\n",
    "\n",
    "                        # print(label_patch_out_pred.shape)\n",
    "                        # convert label_patch_out_real to one hot\n",
    "                        label_patch_out_real_one_hot = torch.zeros_like(label_patch_out_pred).to(device)\n",
    "                        # print(label_patch_out_real_one_hot.shape)\n",
    "                        label_patch_out_real_one_hot[:, 0] = torch.where(label_patch_out_real == 0, 1, 0)\n",
    "                        label_patch_out_real_one_hot[:, 1] = torch.where(label_patch_out_real == 1, 1, 0)\n",
    "                        label_patch_out_real_one_hot[:, 2] = torch.where(label_patch_out_real == 2, 1, 0)\n",
    "\n",
    "                        # cross-entropy loss_dice\n",
    "                        loss_dice = self.criterion_dice(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                                        label_patch_out_real_one_hot.float())\n",
    "                        loss_mse = self.criterion_mse(F.softmax(label_patch_out_pred.float(), dim=1),\n",
    "                                                      label_patch_out_real_one_hot.float())\n",
    "                        # print(loss_mse.item())\n",
    "                        loss_list_dice.append(loss_dice)\n",
    "                        loss_list_mse.append(loss_mse)\n",
    "                        # print(loss_dice)\n",
    "\n",
    "                        label_patch_out_pred_double = torch.argmax(label_patch_out_pred.detach(), dim=1)\n",
    "                        label_patch_out_pred_double_temp = torch.zeros(batch_size, patch_size_out, patch_size_out,\n",
    "                                                                       patch_size_out).to(device)\n",
    "                        label_patch_out_pred_double_temp[:, :label_patch_out_pred_double.shape[1],\n",
    "                        :label_patch_out_pred_double.shape[2],\n",
    "                        :label_patch_out_pred_double.shape[3]] = label_patch_out_pred_double\n",
    "                        label_patch_out_pred_double = label_patch_out_pred_double_temp\n",
    "\n",
    "                        bs, h, w, d = labels_pred_whole_image[:, h_start_orig: h_end_orig,\n",
    "                                      w_start_orig: w_end_orig,\n",
    "                                      d_start_orig: d_end_orig].shape\n",
    "\n",
    "                        # save the pixel wise predictions\n",
    "                        labels_pred_whole_image[:, h_start_orig: h_end_orig, w_start_orig: w_end_orig,\n",
    "                        d_start_orig: d_end_orig] = label_patch_out_pred_double[:, :h, :w, :d].detach()\n",
    "\n",
    "                        # save the probabilistic predictions\n",
    "                        labels_pred_whole_image_probabilistic[:, :, h_start_orig: h_end_orig, w_start_orig: w_end_orig,\n",
    "                        d_start_orig: d_end_orig] = label_patch_out_pred[:, :, :h, :w, :d].detach()\n",
    "\n",
    "                        d_start_orig = d_start_orig + patch_size_out\n",
    "                        d_end_orig = d_end_orig + patch_size_out\n",
    "\n",
    "                    w_start_orig = w_start_orig + patch_size_out\n",
    "                    w_end_orig = w_end_orig + patch_size_out\n",
    "\n",
    "                h_start_orig = h_start_orig + patch_size_out\n",
    "                h_end_orig = h_end_orig + patch_size_out\n",
    "\n",
    "                loss_dice = sum(loss_list_dice) / (len(loss_list_dice) + 1e-9)\n",
    "                loss_mse = sum(loss_list_mse) / (len(loss_list_mse) + 1e-9)\n",
    "\n",
    "        return labels_pred_whole_image, labels_pred_whole_image_probabilistic, loss_dice, loss_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8207e",
   "metadata": {},
   "source": [
    "# STEP 1 #\n",
    "\n",
    "Write a segmentation algorithm pipeline. Train on the training set, defined as a proportion of the data in imagesTr, and validate the algorithm performance on the remaining images. Do not use any auwgmentation for now. Use any choice of optimiser.\n",
    "Describe how the algorithm was trained, and what were the final results using standard image segmentation validation metrics such as Dice Score or Hausdorff Distance.\n",
    "\n",
    "Answer Marks:\n",
    "\n",
    "[10] Working algorithmic implementation\n",
    "\n",
    "[ 3] Comments on the code\n",
    "\n",
    "[ 9] Description of the training process\n",
    "\n",
    "[ 8] Validation presentation and description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24156223",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "The for all training variants, the data was split `80/20` for training and validation. This resulted in `242` training images and `61` validation images. As I used the DeepMedic model, I extracted 3D patches from the whole volume and passed them through the network. As there are much more voxels representing the background class, I used a biased sampling strategy to extract the patches. First I randomly selected the center voxel with `40%` probability to be hepatic vessel or tumour classes each and `20%` for the background class. This voxel was determined as the center pixel and the three different crops of patches were extracted from here. I used a batch size of `8` with 16 random patches extracted from each sample. Additionally, to speed up the `i/o` operation, I converted the provided dataset to numpy ndarray format.\n",
    "\n",
    "To extract the three different crops of the image, the following parameters were used. `patch_size_normal`=`25` refers to original crop. `patch_size_low`=`19` and `patch_low_factor`=`3` refer to the additional large but downsampled crop. i.e. a `57x57x57` patch was downsampled by a factor of `3` to produce a patch of size `19x19x19`. `patch_size_out`=`9` refers to the output produced by the network.\n",
    "\n",
    "I used the Adam optimizer with `beta1=0.9` and `beta2=0.999` with an initial learning rate=`0.0002`. I also set `AMSGrad` to true for better convergence. Validation was performed after each epoch. The initial total number of epochs was set to `100`, while the model was trained using early stopping and learning rate decay. If the best validation loss did not improve (compared to the best found so far) for two consecutive epochs, the learning rate decreased by a factor of `10`. If the validation loss did not improve (compared to the best) for `5` consecutive epochs, the training was terminated. But regardless, the model was trained for at least `10`. The latest and best models were saved after each epoch.\n",
    "\n",
    "At inference time, I used a sliding window approach across the whole volume to obtain the final prediction. I first padded the whole image so that the `output` patch is flushed at the \"`top-left`\" corner while the largest `57x57x57` patch does not go out of bounds. Then I strided by the size of the `output` size (`9`) to make predictions for each patch. The predictions for each patch were saved to an empty 3D output array.\n",
    "\n",
    "At this step only the `Generalized DICE loss` was used, which is `1-DICE` Score (because we want to minimize).\n",
    "\n",
    "The following block runs the training and outputs the training and validation losses after each epoch, what is the best found validation loss so far, whether the learning rate was decreased and when the model training was stopped. The model was trained for `33` epochs before early stopping. The best validation loss of `0.21903` was obtained on epoch `28`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d077bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\t\tTraining starting with params:\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"params_model\": {\n",
      "        \"experiment_name\": \"step_1\",\n",
      "        \"model_name\": \"deep_medic\",\n",
      "        \"patch_size_normal\": 25,\n",
      "        \"patch_size_low\": 19,\n",
      "        \"patch_size_out\": 9,\n",
      "        \"patch_low_factor\": 3,\n",
      "        \"run_mode\": null,\n",
      "        \"dataset_variant\": \"npy\",\n",
      "        \"create_numpy_dataset\": false,\n",
      "        \"init_timestamp\": \"15-08-38__05-04-2022\"\n",
      "    },\n",
      "    \"params_train\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"loss_name\": \"dice\",\n",
      "        \"beta_1\": 0.9,\n",
      "        \"beta_2\": 0.999,\n",
      "        \"momentum\": 0.9,\n",
      "        \"use_amsgrad\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"lr_scheduler_name\": \"plateau\",\n",
      "        \"patience_lr_scheduler\": 2,\n",
      "        \"factor_lr_scheduler\": 0.1,\n",
      "        \"early_stop_condition\": true,\n",
      "        \"patience_early_stop\": 5,\n",
      "        \"early_stop_patience_counter\": 0,\n",
      "        \"min_epochs_to_train\": 10,\n",
      "        \"num_epochs\": 100,\n",
      "        \"save_every_epoch\": true,\n",
      "        \"save_condition\": true,\n",
      "        \"resume_condition\": false,\n",
      "        \"resume_dir\": \"14-10-08__01-04-2022__deep_medic__dice__adam__lr_0.0001__ep_50\",\n",
      "        \"resume_epoch\": \"latest\",\n",
      "        \"batch_size\": 8,\n",
      "        \"batch_size_inner\": 16,\n",
      "        \"train_percentage\": 0.8,\n",
      "        \"num_workers\": 8,\n",
      "        \"pin_memory\": true,\n",
      "        \"prefetch_factor\": 2,\n",
      "        \"persistent_workers\": true,\n",
      "        \"path_checkpoint\": \"./checkpoints\",\n",
      "        \"path_checkpoint_full\": \"./checkpoints/step_1__15-08-38__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"dirname_checkpoint\": \"step_1__15-08-38__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"filename_params\": \"params.json\",\n",
      "        \"filename_logger\": \"logger.txt\",\n",
      "        \"path_params_full\": \"./checkpoints/step_1__15-08-38__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/params.json\",\n",
      "        \"path_logger_full\": \"./checkpoints/step_1__15-08-38__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/logger.txt\",\n",
      "        \"use_elastic_deformation\": false,\n",
      "        \"user_affine_transformation\": false,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[1 / 100]\t\tTime:\t433.39 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.54777\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.43942\t\tBest:\t0.43942\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t1\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[2 / 100]\t\tTime:\t436.38 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.44131\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.37737\t\tBest:\t0.37737\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t2\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[3 / 100]\t\tTime:\t451.40 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.40754\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.40235\t\tBest:\t0.37737\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[4 / 100]\t\tTime:\t436.17 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.40538\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.35128\t\tBest:\t0.35128\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t4\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[5 / 100]\t\tTime:\t446.50 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.35426\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.33229\t\tBest:\t0.33229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t5\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[6 / 100]\t\tTime:\t442.12 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.38096\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.33042\t\tBest:\t0.33042\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t6\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[7 / 100]\t\tTime:\t463.92 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.34211\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30315\t\tBest:\t0.30315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t7\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[8 / 100]\t\tTime:\t434.22 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.33924\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.33920\t\tBest:\t0.30315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[9 / 100]\t\tTime:\t438.07 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.32699\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28170\t\tBest:\t0.28170\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t9\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[10 / 100]\t\tTime:\t476.14 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.32182\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.27461\t\tBest:\t0.27461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t10\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[11 / 100]\t\tTime:\t448.98 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.30836\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28935\t\tBest:\t0.27461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[12 / 100]\t\tTime:\t466.97 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.31678\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25937\t\tBest:\t0.25937\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t12\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[13 / 100]\t\tTime:\t458.61 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29453\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28866\t\tBest:\t0.25937\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[14 / 100]\t\tTime:\t445.32 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.32577\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25669\t\tBest:\t0.25669\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t14\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[15 / 100]\t\tTime:\t448.86 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.27631\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30026\t\tBest:\t0.25669\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[16 / 100]\t\tTime:\t444.38 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28012\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.27703\t\tBest:\t0.25669\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[17 / 100]\t\tTime:\t436.28 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29427\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24486\t\tBest:\t0.24486\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t17\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[18 / 100]\t\tTime:\t435.14 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28402\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.29928\t\tBest:\t0.24486\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[19 / 100]\t\tTime:\t484.84 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29069\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25004\t\tBest:\t0.24486\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[20 / 100]\t\tTime:\t460.05 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26589\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23152\t\tBest:\t0.23152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t20\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[21 / 100]\t\tTime:\t433.85 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25900\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25875\t\tBest:\t0.23152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[22 / 100]\t\tTime:\t438.11 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26296\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25247\t\tBest:\t0.23152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[23 / 100]\t\tTime:\t457.75 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26025\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23113\t\tBest:\t0.23113\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t23\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[24 / 100]\t\tTime:\t470.61 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25454\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23959\t\tBest:\t0.23113\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[25 / 100]\t\tTime:\t455.79 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.27519\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24448\t\tBest:\t0.23113\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: reducing learning rate of group 0 to 2.0000e-05.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[26 / 100]\t\tTime:\t486.99 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26176\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24437\t\tBest:\t0.23113\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[27 / 100]\t\tTime:\t428.83 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24735\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23922\t\tBest:\t0.23113\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[28 / 100]\t\tTime:\t453.69 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.23339\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21903\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t28\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[29 / 100]\t\tTime:\t440.86 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24715\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22200\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[30 / 100]\t\tTime:\t467.61 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25004\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22617\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: reducing learning rate of group 0 to 2.0000e-06.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[31 / 100]\t\tTime:\t435.11 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.22246\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23199\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[32 / 100]\t\tTime:\t477.63 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.23143\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23155\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[33 / 100]\t\tTime:\t471.26 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.21114\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22660\t\tBest:\t0.21903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Early stopping at epoch:\t33\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    'optimizer_name': 'adam',  # adam, sgd_w_momentum\n",
    "    'loss_name': 'dice',  # dice, mse, ce, dice_n_mse, dice_n_mse_n_ce\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'momentum': 0.9,\n",
    "    'use_amsgrad': True,\n",
    "    'learning_rate': 0.0002,  # 0.0002\n",
    "    'lr_scheduler_name': 'plateau',\n",
    "    'patience_lr_scheduler': 2,\n",
    "    'factor_lr_scheduler': 0.1,\n",
    "    'early_stop_condition': True,\n",
    "    'patience_early_stop': 5,\n",
    "    'early_stop_patience_counter': 0,\n",
    "    'min_epochs_to_train': 10,\n",
    "    'num_epochs': 100,\n",
    "    'save_every_epoch': True,\n",
    "\n",
    "    'save_condition': True,  # whether to save the model\n",
    "    'resume_condition': False,  # whether to resume training\n",
    "\n",
    "    'resume_dir': 'step_1__15-08-38__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'latest',\n",
    "\n",
    "    'batch_size': 8,  # 8\n",
    "    'batch_size_inner': 16,  # 16 (how many patches to generate per sample)\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 8,  # 8\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "    'filename_params': 'params.json',\n",
    "    'filename_logger': 'logger.txt',\n",
    "    'path_params_full': '',\n",
    "    'path_logger_full': '',\n",
    "\n",
    "    'use_elastic_deformation': False,\n",
    "    'user_affine_transformation': False,\n",
    "\n",
    "    'num_controlpoints': 20,\n",
    "    'sigma': 5,\n",
    "\n",
    "    'rotation': 10,\n",
    "    'scale': (0.90, 1.10),\n",
    "    'shear': (0.01, 0.02)\n",
    "}\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "params_model['experiment_name'] = 'step_1'\n",
    "model_container = ModelConainer(params_model)\n",
    "\n",
    "# train the model\n",
    "model_container.train(params_train=params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69395294",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 2: Now run the same training process but now using Affine transformations and Elastic Deformations as augmentation techniques. Describe what the augmentation is doing, what parameters were used and why, and what was the outcome of the training/testing process when augmentation was used. Did you observe a smaller train/test performance gap? [10]\n",
    "Answer Marks:\n",
    "[ 6] 3 points for each implementation of the augmentation\n",
    "[ 2] Description of the augmentation and parameters\n",
    "[ 2] Description of the performance gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe502182",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "Both `Elastic Deformation` and `Affine Transformation` are implemented as separate classes. The objects are instantiated from within the model container class. The model was instructed to use these transformations by setting the `use_elastic_deformation` and `use_affine_transformation` parameters of the `params_train` to `True`.\n",
    "\n",
    "For elastic deformation, I set the number of control points to `20` and the sigma to `5`. The number of control points define how fine grained the transformation is going to be, where more control points mean that there will be high-frequency transformations while sigma determines the sense of smoothing. As I am using b-spline interpolation, `sigma` refers to how many control points away from the center of a control point should influence. A larger number would result in a smoother image.\n",
    "\n",
    "For affine transformation, I randomly rotated the images by +/- `10` degrees (either clockwise or anti-clockwise) on the volume axis, which is meaningful because a person might not lie perfectly straight when taking the scan. +/- `10%` scaling was applied to the image while `0.01` and `0.02` shear in the height and width dimensions.\n",
    "\n",
    "The model was trained for `29` epochs before early stopping. The best validation loss (`DICE`) `0.21015` was found at epoch `24`. This loss was slightly better (`0.0008`) than the loss from the previous step (`0.21095`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cd95c88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\t\tTraining starting with params:\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"params_model\": {\n",
      "        \"experiment_name\": \"step_2\",\n",
      "        \"model_name\": \"deep_medic\",\n",
      "        \"patch_size_normal\": 25,\n",
      "        \"patch_size_low\": 19,\n",
      "        \"patch_size_out\": 9,\n",
      "        \"patch_low_factor\": 3,\n",
      "        \"run_mode\": null,\n",
      "        \"dataset_variant\": \"npy\",\n",
      "        \"create_numpy_dataset\": false,\n",
      "        \"init_timestamp\": \"19-32-16__05-04-2022\",\n",
      "        \"use_elastic_deformation\": true,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"user_affine_transformation\": true,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    },\n",
      "    \"params_train\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"loss_name\": \"dice\",\n",
      "        \"beta_1\": 0.9,\n",
      "        \"beta_2\": 0.999,\n",
      "        \"momentum\": 0.9,\n",
      "        \"use_amsgrad\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"lr_scheduler_name\": \"plateau\",\n",
      "        \"patience_lr_scheduler\": 2,\n",
      "        \"factor_lr_scheduler\": 0.1,\n",
      "        \"early_stop_condition\": true,\n",
      "        \"patience_early_stop\": 5,\n",
      "        \"early_stop_patience_counter\": 0,\n",
      "        \"min_epochs_to_train\": 10,\n",
      "        \"num_epochs\": 100,\n",
      "        \"save_every_epoch\": true,\n",
      "        \"save_condition\": true,\n",
      "        \"resume_condition\": false,\n",
      "        \"resume_dir\": \"14-10-08__01-04-2022__deep_medic__dice__adam__lr_0.0001__ep_50\",\n",
      "        \"resume_epoch\": \"latest\",\n",
      "        \"batch_size\": 8,\n",
      "        \"batch_size_inner\": 16,\n",
      "        \"train_percentage\": 0.8,\n",
      "        \"num_workers\": 8,\n",
      "        \"pin_memory\": true,\n",
      "        \"prefetch_factor\": 2,\n",
      "        \"persistent_workers\": true,\n",
      "        \"path_checkpoint\": \"./checkpoints\",\n",
      "        \"path_checkpoint_full\": \"./checkpoints/step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"dirname_checkpoint\": \"step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"filename_params\": \"params.json\",\n",
      "        \"filename_logger\": \"logger.txt\",\n",
      "        \"path_params_full\": \"./checkpoints/step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/params.json\",\n",
      "        \"path_logger_full\": \"./checkpoints/step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/logger.txt\",\n",
      "        \"use_elastic_deformation\": false,\n",
      "        \"user_affine_transformation\": false,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[1 / 100]\t\tTime:\t458.88 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.54768\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.44073\t\tBest:\t0.44073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t1\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[2 / 100]\t\tTime:\t470.35 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.44151\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.37718\t\tBest:\t0.37718\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t2\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[3 / 100]\t\tTime:\t471.91 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.40489\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.40777\t\tBest:\t0.37718\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[4 / 100]\t\tTime:\t452.36 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.40420\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.35287\t\tBest:\t0.35287\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t4\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[5 / 100]\t\tTime:\t555.81 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.35344\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.33996\t\tBest:\t0.33996\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t5\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[6 / 100]\t\tTime:\t519.59 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.38305\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30759\t\tBest:\t0.30759\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t6\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[7 / 100]\t\tTime:\t501.14 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.34097\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.35565\t\tBest:\t0.30759\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[8 / 100]\t\tTime:\t496.80 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.33303\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.39398\t\tBest:\t0.30759\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[9 / 100]\t\tTime:\t593.79 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.32447\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28083\t\tBest:\t0.28083\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t9\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[10 / 100]\t\tTime:\t601.48 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.31451\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.26961\t\tBest:\t0.26961\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t10\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[11 / 100]\t\tTime:\t660.61 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.30092\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.39474\t\tBest:\t0.26961\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[12 / 100]\t\tTime:\t647.37 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.31724\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.31914\t\tBest:\t0.26961\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[13 / 100]\t\tTime:\t630.68 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.30178\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25256\t\tBest:\t0.25256\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t13\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[14 / 100]\t\tTime:\t518.63 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.32304\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.31157\t\tBest:\t0.25256\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[15 / 100]\t\tTime:\t532.93 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28392\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24674\t\tBest:\t0.24674\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t15\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[16 / 100]\t\tTime:\t814.09 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28136\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.27104\t\tBest:\t0.24674\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[17 / 100]\t\tTime:\t617.02 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28540\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30630\t\tBest:\t0.24674\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: reducing learning rate of group 0 to 2.0000e-05.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[18 / 100]\t\tTime:\t926.29 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28499\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25281\t\tBest:\t0.24674\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[19 / 100]\t\tTime:\t951.48 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28139\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22692\t\tBest:\t0.22692\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t19\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[20 / 100]\t\tTime:\t975.75 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25543\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22926\t\tBest:\t0.22692\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[21 / 100]\t\tTime:\t790.55 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24044\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23426\t\tBest:\t0.22692\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022: reducing learning rate of group 0 to 2.0000e-06.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[22 / 100]\t\tTime:\t890.60 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24628\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22822\t\tBest:\t0.22692\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[23 / 100]\t\tTime:\t849.21 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.23753\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21492\t\tBest:\t0.21492\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t23\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[24 / 100]\t\tTime:\t905.11 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24468\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21015\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t24\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[25 / 100]\t\tTime:\t656.93 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26441\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22856\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[26 / 100]\t\tTime:\t887.41 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24436\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24515\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027: reducing learning rate of group 0 to 2.0000e-07.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[27 / 100]\t\tTime:\t673.95 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25809\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22876\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[28 / 100]\t\tTime:\t683.02 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24454\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22038\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[29 / 100]\t\tTime:\t766.25 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26121\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22527\t\tBest:\t0.21015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Early stopping at epoch:\t29\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    'optimizer_name': 'adam',  # adam, sgd_w_momentum\n",
    "    'loss_name': 'dice',  # dice, mse, ce, dice_n_mse, dice_n_mse_n_ce\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'momentum': 0.9,\n",
    "    'use_amsgrad': True,\n",
    "    'learning_rate': 0.0002,  # 0.0002\n",
    "    'lr_scheduler_name': 'plateau',\n",
    "    'patience_lr_scheduler': 2,\n",
    "    'factor_lr_scheduler': 0.1,\n",
    "    'early_stop_condition': True,\n",
    "    'patience_early_stop': 5,\n",
    "    'early_stop_patience_counter': 0,\n",
    "    'min_epochs_to_train': 10,\n",
    "    'num_epochs': 100,\n",
    "    'save_every_epoch': True,\n",
    "\n",
    "    'save_condition': True,  # whether to save the model\n",
    "    'resume_condition': False,  # whether to resume training\n",
    "\n",
    "    'resume_dir': 'step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'latest',\n",
    "\n",
    "    'batch_size': 8,  # 8\n",
    "    'batch_size_inner': 16,  # 16 (how many patches to generate per sample)\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 8,  # 8\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "    'filename_params': 'params.json',\n",
    "    'filename_logger': 'logger.txt',\n",
    "    'path_params_full': '',\n",
    "    'path_logger_full': '',\n",
    "\n",
    "    'use_elastic_deformation': False,\n",
    "    'user_affine_transformation': False,\n",
    "\n",
    "    'num_controlpoints': 20,\n",
    "    'sigma': 5,\n",
    "\n",
    "    'rotation': 10,\n",
    "    'scale': (0.90, 1.10),\n",
    "    'shear': (0.01, 0.02)\n",
    "}\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "params_model['experiment_name'] = 'step_2'\n",
    "\n",
    "# using elastic deformation\n",
    "params_model['use_elastic_deformation'] = True\n",
    "params_model['num_controlpoints'] = 20\n",
    "params_model['sigma'] = 5\n",
    "\n",
    "# using affine transformation\n",
    "params_model['user_affine_transformation'] = True\n",
    "params_model['rotation'] = 10\n",
    "params_model['scale'] = (0.90, 1.10)\n",
    "params_model['shear'] = (0.01, 0.02)\n",
    "\n",
    "model_container = ModelConainer(params_model)\n",
    "\n",
    "# train the model\n",
    "model_container.train(params_train=params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967e156",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 3: To obtain even better results, you will need to optimise the parameters of the loss function, the optimiser learning rate, or the network parameters. Report how these hyperparameters were optimised and what performance gains were observed. [10]\n",
    "Answer Marks:\n",
    "[ 6] 2 points for each parameter that was optimised\n",
    "[ 2] Description of the optimisation process\n",
    "[ 2] Description of the performance gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89efac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "Although I have the code implemented to perform grid search in the following block, I could not perform a very wide range of parameter search due to computational resource limitations, specially the slow i/o times to load the large files in the dataset. I was also limited by PyTorch's dataloader's bug, which does not allow me to run threaded operations on an windows environment, unless I run from inside the if `__name__=='__main__'` block, so I had to make alternative arrangements. As I used learning rate decay, extensive search of the learning rate parameter was avoided.\n",
    "\n",
    "Due to these limitations, I ran separate `.py` scripts on a separate machine, and was not able to attach the output of the results here. The semi-optimal parameters I found at this step were also used in the previous steps to maximize runtime and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2477ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    'optimizer_name': 'adam',  # adam, sgd_w_momentum\n",
    "    'loss_name': 'dice',  # dice, mse, ce, dice_n_mse, dice_n_mse_n_ce\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'momentum': 0.9,\n",
    "    'use_amsgrad': True,\n",
    "    'learning_rate': 0.0002,  # 0.0002\n",
    "    'lr_scheduler_name': 'plateau',\n",
    "    'patience_lr_scheduler': 2,\n",
    "    'factor_lr_scheduler': 0.1,\n",
    "    'early_stop_condition': True,\n",
    "    'patience_early_stop': 5,\n",
    "    'early_stop_patience_counter': 0,\n",
    "    'min_epochs_to_train': 10,\n",
    "    'num_epochs': 100,\n",
    "    'save_every_epoch': True,\n",
    "\n",
    "    'save_condition': True,  # whether to save the model\n",
    "    'resume_condition': False,  # whether to resume training\n",
    "\n",
    "    'resume_dir': 'step_3__09-08-25__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'latest',\n",
    "\n",
    "    'batch_size': 8,  # 8\n",
    "    'batch_size_inner': 16,  # 16 (how many patches to generate per sample)\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 8,  # 8\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "    'filename_params': 'params.json',\n",
    "    'filename_logger': 'logger.txt',\n",
    "    'path_params_full': '',\n",
    "    'path_logger_full': '',\n",
    "\n",
    "    'use_elastic_deformation': False,\n",
    "    'user_affine_transformation': False,\n",
    "\n",
    "    'num_controlpoints': 20,\n",
    "    'sigma': 5,\n",
    "\n",
    "    'rotation': 10,\n",
    "    'scale': (0.90, 1.10),\n",
    "    'shear': (0.01, 0.02)\n",
    "}\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "params_model['experiment_name'] = 'step_3'\n",
    "params_model['loss_name'] = 'dice'\n",
    "params_model['use_elastic_deformation'] = True\n",
    "params_model['user_affine_transformation'] = True\n",
    "\n",
    "list_lr = [0.0002, 0.001, 0.01]\n",
    "list_control_points = [10, 15, 20]\n",
    "list_sigma = [5, 10, 20]\n",
    "list_rotation = [5, 10]\n",
    "list_scale = [(0.90, 1.10), (0.95, 1.05)]\n",
    "list_shear = [(0.01, 0.02), (0.05, 0.10)]\n",
    "\n",
    "\n",
    "index = 0\n",
    "num_train_models = len(list_lr) * len(list_control_points) * len(list_sigma) * len(list_rotation) * len(list_scale) * len(list_shear)\n",
    "\n",
    "print(f'Starting grid search:\\n')\n",
    "\n",
    "for lr in list_lr:\n",
    "    for cp in list_control_points:\n",
    "        for sigma in list_sigma:\n",
    "            for rotation in list_rotation:\n",
    "                for scale in list_scale:\n",
    "                    for shear in list_shear: \n",
    "                        params_model['learning_rate'] = lr\n",
    "                        params_model['num_controlpoints'] = cp\n",
    "                        params_model['sigma'] = sigma\n",
    "\n",
    "\n",
    "                        params_model['rotation'] = rotation\n",
    "                        params_model['scale'] = scale\n",
    "                        params_model['shear'] = shear\n",
    "                        \n",
    "                        print(f'Training Model:\\t[{index+1}/{num_train_models}]')\n",
    "                        \n",
    "                        if index > 0:\n",
    "                            # to avoid memory leak, but does not solve the issue altogether\n",
    "                            del model_container\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        model_container = ModelConainer(params_model)\n",
    "\n",
    "                        # train the model\n",
    "                        model_container.train(params_train=params_train)\n",
    "                        index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c896e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 4: Vessels are small and thin. This commonly results in a disconnected vessel three. Predicting distance maps (e.g. https://arxiv.org/pdf/1908.05099.pdf) is a good auxiliary\n",
    "task to force a network to understand vessel geometry. Implement this auxiliary task and\n",
    "assess the performance with and without the auxiliary task. [20]\n",
    "Answer Marks:\n",
    "[13] Correct implementation of the task\n",
    "[ 2] Code comments\n",
    "[ 5] Description of the performance gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a77201",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "From the paper what I understood was that, in order to predict the distance maps, the Generalized Dice loss has to be optimized alongside the Mean Squared Loss (MSE). The performance gains from this is that, MSE helps the network localize and focus on the very small regions of the hepatic vessels and tumours (but does not handle class imbalance) while the Generalized Dice loss helps to tackle the class imbalance and segmentation performance.\n",
    "\n",
    "To implement the complete loss from the paper (segmentation + distance + contour) we can additionally optimize the Cross-Entropy loss alongside the previous two losses. The necessary code is implemented after the following block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c7200",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### DICE + MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfd998d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\t\tTraining starting with params:\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"params_model\": {\n",
      "        \"experiment_name\": \"step_4\",\n",
      "        \"model_name\": \"deep_medic\",\n",
      "        \"patch_size_normal\": 25,\n",
      "        \"patch_size_low\": 19,\n",
      "        \"patch_size_out\": 9,\n",
      "        \"patch_low_factor\": 3,\n",
      "        \"run_mode\": null,\n",
      "        \"dataset_variant\": \"npy\",\n",
      "        \"create_numpy_dataset\": false,\n",
      "        \"init_timestamp\": \"09-03-12__06-04-2022\",\n",
      "        \"loss_name\": \"dice_n_mse\",\n",
      "        \"use_elastic_deformation\": true,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"user_affine_transformation\": true,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    },\n",
      "    \"params_train\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"loss_name\": \"dice\",\n",
      "        \"beta_1\": 0.9,\n",
      "        \"beta_2\": 0.999,\n",
      "        \"momentum\": 0.9,\n",
      "        \"use_amsgrad\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"lr_scheduler_name\": \"plateau\",\n",
      "        \"patience_lr_scheduler\": 2,\n",
      "        \"factor_lr_scheduler\": 0.1,\n",
      "        \"early_stop_condition\": true,\n",
      "        \"patience_early_stop\": 5,\n",
      "        \"early_stop_patience_counter\": 0,\n",
      "        \"min_epochs_to_train\": 10,\n",
      "        \"num_epochs\": 100,\n",
      "        \"save_every_epoch\": true,\n",
      "        \"save_condition\": true,\n",
      "        \"resume_condition\": false,\n",
      "        \"resume_dir\": \"step_2__19-32-16__05-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"resume_epoch\": \"latest\",\n",
      "        \"batch_size\": 8,\n",
      "        \"batch_size_inner\": 16,\n",
      "        \"train_percentage\": 0.8,\n",
      "        \"num_workers\": 8,\n",
      "        \"pin_memory\": true,\n",
      "        \"prefetch_factor\": 2,\n",
      "        \"persistent_workers\": true,\n",
      "        \"path_checkpoint\": \"./checkpoints\",\n",
      "        \"path_checkpoint_full\": \"./checkpoints/step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"dirname_checkpoint\": \"step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"filename_params\": \"params.json\",\n",
      "        \"filename_logger\": \"logger.txt\",\n",
      "        \"path_params_full\": \"./checkpoints/step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/params.json\",\n",
      "        \"path_logger_full\": \"./checkpoints/step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100/logger.txt\",\n",
      "        \"use_elastic_deformation\": false,\n",
      "        \"user_affine_transformation\": false,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[1 / 100]\t\tTime:\t456.72 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.54791\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.43348\t\tBest:\t0.43348\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t1\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[2 / 100]\t\tTime:\t495.79 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.44145\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.37291\t\tBest:\t0.37291\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t2\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[3 / 100]\t\tTime:\t512.69 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.40581\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.40209\t\tBest:\t0.37291\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[4 / 100]\t\tTime:\t562.41 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.39930\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.34903\t\tBest:\t0.34903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t4\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[5 / 100]\t\tTime:\t626.50 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.34937\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30827\t\tBest:\t0.30827\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t5\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[6 / 100]\t\tTime:\t753.72 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.37694\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.29229\t\tBest:\t0.29229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t6\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[7 / 100]\t\tTime:\t705.96 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.34502\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.38347\t\tBest:\t0.29229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[8 / 100]\t\tTime:\t736.27 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.34238\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.33099\t\tBest:\t0.29229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[9 / 100]\t\tTime:\t758.10 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.31946\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.27836\t\tBest:\t0.27836\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t9\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[10 / 100]\t\tTime:\t948.15 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.31934\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28000\t\tBest:\t0.27836\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[11 / 100]\t\tTime:\t908.63 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.30784\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.29417\t\tBest:\t0.27836\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[12 / 100]\t\tTime:\t1211.46 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.30960\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25787\t\tBest:\t0.25787\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t12\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[13 / 100]\t\tTime:\t1028.96 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29819\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.30882\t\tBest:\t0.25787\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[14 / 100]\t\tTime:\t1026.18 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.33662\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.32230\t\tBest:\t0.25787\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[15 / 100]\t\tTime:\t949.85 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28269\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.24181\t\tBest:\t0.24181\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t15\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[16 / 100]\t\tTime:\t934.00 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.28256\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.34878\t\tBest:\t0.24181\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[17 / 100]\t\tTime:\t943.54 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29130\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23611\t\tBest:\t0.23611\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t17\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[18 / 100]\t\tTime:\t983.46 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.27954\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25617\t\tBest:\t0.23611\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[19 / 100]\t\tTime:\t934.92 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.29714\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25195\t\tBest:\t0.23611\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[20 / 100]\t\tTime:\t1177.66 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.26778\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23050\t\tBest:\t0.23050\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t20\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[21 / 100]\t\tTime:\t920.18 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25666\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.25889\t\tBest:\t0.23050\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[22 / 100]\t\tTime:\t952.53 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25525\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.28110\t\tBest:\t0.23050\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[23 / 100]\t\tTime:\t871.72 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25715\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22780\t\tBest:\t0.22780\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t23\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[24 / 100]\t\tTime:\t837.13 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25507\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23877\t\tBest:\t0.22780\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[25 / 100]\t\tTime:\t928.81 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.27627\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.26304\t\tBest:\t0.22780\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: reducing learning rate of group 0 to 2.0000e-05.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[26 / 100]\t\tTime:\t885.86 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25396\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23466\t\tBest:\t0.22780\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[27 / 100]\t\tTime:\t898.64 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.25077\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.23698\t\tBest:\t0.22780\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[28 / 100]\t\tTime:\t806.23 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.22900\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21811\t\tBest:\t0.21811\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t28\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[29 / 100]\t\tTime:\t847.17 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24899\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21365\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "**********\tNew best model saved at:\t29\t**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[30 / 100]\t\tTime:\t872.10 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.24870\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22354\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[31 / 100]\t\tTime:\t819.09 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.22305\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22730\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032: reducing learning rate of group 0 to 2.0000e-06.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[32 / 100]\t\tTime:\t792.36 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.23197\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22747\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[33 / 100]\t\tTime:\t755.72 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.20683\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.22076\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:\t[34 / 100]\t\tTime:\t766.89 s\n",
      "\tTRAIN\t\t-->\t\tLoss Total:\t\t0.22011\n",
      "\tVAL\t\t\t-->\t\tLoss Total:\t\t0.21798\t\tBest:\t0.21365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Early stopping at epoch:\t34\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    'optimizer_name': 'adam',  # adam, sgd_w_momentum\n",
    "    'loss_name': 'dice',  # dice, mse, ce, dice_n_mse, dice_n_mse_n_ce\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'momentum': 0.9,\n",
    "    'use_amsgrad': True,\n",
    "    'learning_rate': 0.0002,  # 0.0002\n",
    "    'lr_scheduler_name': 'plateau',\n",
    "    'patience_lr_scheduler': 2,\n",
    "    'factor_lr_scheduler': 0.1,\n",
    "    'early_stop_condition': True,\n",
    "    'patience_early_stop': 5,\n",
    "    'early_stop_patience_counter': 0,\n",
    "    'min_epochs_to_train': 10,\n",
    "    'num_epochs': 100,\n",
    "    'save_every_epoch': True,\n",
    "\n",
    "    'save_condition': True,  # whether to save the model\n",
    "    'resume_condition': False,  # whether to resume training\n",
    "\n",
    "    'resume_dir': 'step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'latest',\n",
    "\n",
    "    'batch_size': 8,  # 8\n",
    "    'batch_size_inner': 16,  # 16 (how many patches to generate per sample)\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 8,  # 8\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "    'filename_params': 'params.json',\n",
    "    'filename_logger': 'logger.txt',\n",
    "    'path_params_full': '',\n",
    "    'path_logger_full': '',\n",
    "\n",
    "    'use_elastic_deformation': False,\n",
    "    'user_affine_transformation': False,\n",
    "\n",
    "    'num_controlpoints': 20,\n",
    "    'sigma': 5,\n",
    "\n",
    "    'rotation': 10,\n",
    "    'scale': (0.90, 1.10),\n",
    "    'shear': (0.01, 0.02)\n",
    "}\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "params_model['experiment_name'] = 'step_4'\n",
    "params_model['loss_name'] = 'dice_n_mse'\n",
    "\n",
    "params_model['use_elastic_deformation'] = True\n",
    "params_model['num_controlpoints'] = 20\n",
    "params_model['sigma'] = 5\n",
    "\n",
    "params_model['user_affine_transformation'] = True\n",
    "params_model['rotation'] = 10\n",
    "params_model['scale'] = (0.90, 1.10)\n",
    "params_model['shear'] = (0.01, 0.02)\n",
    "\n",
    "model_container = ModelConainer(params_model)\n",
    "\n",
    "# train the model\n",
    "model_container.train(params_train=params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa082a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### DCIE + MSE + CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae252a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    'optimizer_name': 'adam',  # adam, sgd_w_momentum\n",
    "    'loss_name': 'dice',  # dice, mse, ce, dice_n_mse, dice_n_mse_n_ce\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'momentum': 0.9,\n",
    "    'use_amsgrad': True,\n",
    "    'learning_rate': 0.0002,  # 0.0002\n",
    "    'lr_scheduler_name': 'plateau',\n",
    "    'patience_lr_scheduler': 2,\n",
    "    'factor_lr_scheduler': 0.1,\n",
    "    'early_stop_condition': True,\n",
    "    'patience_early_stop': 5,\n",
    "    'early_stop_patience_counter': 0,\n",
    "    'min_epochs_to_train': 10,\n",
    "    'num_epochs': 100,\n",
    "    'save_every_epoch': True,\n",
    "\n",
    "    'save_condition': True,  # whether to save the model\n",
    "    'resume_condition': False,  # whether to resume training\n",
    "\n",
    "    'resume_dir': 'step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'latest',\n",
    "\n",
    "    'batch_size': 8,  # 8\n",
    "    'batch_size_inner': 16,  # 16 (how many patches to generate per sample)\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 8,  # 8\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "    'filename_params': 'params.json',\n",
    "    'filename_logger': 'logger.txt',\n",
    "    'path_params_full': '',\n",
    "    'path_logger_full': '',\n",
    "\n",
    "    'use_elastic_deformation': False,\n",
    "    'user_affine_transformation': False,\n",
    "\n",
    "    'num_controlpoints': 20,\n",
    "    'sigma': 5,\n",
    "\n",
    "    'rotation': 10,\n",
    "    'scale': (0.90, 1.10),\n",
    "    'shear': (0.01, 0.02)\n",
    "}\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "params_model['experiment_name'] = 'step_4'\n",
    "params_model['loss_name'] = 'dice_n_mse_n_ce'\n",
    "\n",
    "model_container = ModelConainer(params_model)\n",
    "\n",
    "# train the model\n",
    "model_container.train(params_train=params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1490914",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 5: The process of image segmentation is naturally uncertain. Because of this, we would like to estimate how uncertaint the models are when segmenting the target labels. To achieve this, please implement the Augmentation-based Aleatoric method, as decribed here (https://arxiv.org/pdf/1807.07356.pdf). Optimise any parameters the method might have. Visualise the uncertainty estimates. Are the areas of high uncertainty areas where errors are more likeley to be made? [10]\n",
    "Answer Marks:\n",
    "[ 5] Implementation of the uncertainty estimation method\n",
    "[ 2] Visualisation\n",
    "[ 3] Describe relationship between error and uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f2664",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 6: Ensemble all the models by averaging their probalility. You can achieve this by either sharing the models themselves among the team, or by sharing the probabilistic outputs of\n",
    "the models. Comment on the algorithmic performance of the ensemble compared to your own method. [10]\n",
    "Answer Marks:\n",
    "[ 5] Implementation of the average ensemble\n",
    "[ 5] Describe the differences in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698b32b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save the outputs from the inference: I am using the model from the trained mdoel from step 4, which uses DICE loss as well as the distance maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c389a54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from epoch:\t30\n",
      "****************************************************************************************************\n",
      "\t\tInference starting with params:\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"params_model\": {\n",
      "        \"experiment_name\": \"step_4\",\n",
      "        \"model_name\": \"deep_medic\",\n",
      "        \"patch_size_normal\": 25,\n",
      "        \"patch_size_low\": 19,\n",
      "        \"patch_size_out\": 9,\n",
      "        \"patch_low_factor\": 3,\n",
      "        \"run_mode\": null,\n",
      "        \"dataset_variant\": \"npy\",\n",
      "        \"create_numpy_dataset\": false,\n",
      "        \"init_timestamp\": \"09-03-12__06-04-2022\",\n",
      "        \"loss_name\": \"dice_n_mse\",\n",
      "        \"use_elastic_deformation\": true,\n",
      "        \"num_controlpoints\": 20,\n",
      "        \"sigma\": 5,\n",
      "        \"user_affine_transformation\": true,\n",
      "        \"rotation\": 10,\n",
      "        \"scale\": [\n",
      "            0.9,\n",
      "            1.1\n",
      "        ],\n",
      "        \"shear\": [\n",
      "            0.01,\n",
      "            0.02\n",
      "        ]\n",
      "    },\n",
      "    \"params_inference\": {\n",
      "        \"loss_name\": \"dice\",\n",
      "        \"batch_size\": 1,\n",
      "        \"train_percentage\": 0.8,\n",
      "        \"num_workers\": 0,\n",
      "        \"pin_memory\": false,\n",
      "        \"prefetch_factor\": 2,\n",
      "        \"persistent_workers\": false,\n",
      "        \"resume_dir\": \"step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100\",\n",
      "        \"resume_epoch\": \"best\",\n",
      "        \"path_checkpoint\": \".\\\\checkpoints\",\n",
      "        \"path_checkpoint_full\": \"\",\n",
      "        \"dirname_checkpoint\": \"\"\n",
      "    }\n",
      "}\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31: \t30.npy\tLoss DICE:\t0.39051\tLoss MSE:\t0.03766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: \t31.npy\tLoss DICE:\t0.38103\tLoss MSE:\t0.03800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33: \t32.npy\tLoss DICE:\t0.57124\tLoss MSE:\t0.03101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34: \t33.npy\tLoss DICE:\t0.35475\tLoss MSE:\t0.03918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35: \t34.npy\tLoss DICE:\t0.50300\tLoss MSE:\t0.03211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36: \t35.npy\tLoss DICE:\t0.40539\tLoss MSE:\t0.04297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37: \t36.npy\tLoss DICE:\t0.52183\tLoss MSE:\t0.03593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38: \t37.npy\tLoss DICE:\t0.51899\tLoss MSE:\t0.03090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39: \t38.npy\tLoss DICE:\t0.38306\tLoss MSE:\t0.03462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40: \t39.npy\tLoss DICE:\t0.58272\tLoss MSE:\t0.04245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41: \t40.npy\tLoss DICE:\t0.59060\tLoss MSE:\t0.04261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42: \t41.npy\tLoss DICE:\t0.45669\tLoss MSE:\t0.03946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43: \t42.npy\tLoss DICE:\t0.44385\tLoss MSE:\t0.02936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44: \t43.npy\tLoss DICE:\t0.21941\tLoss MSE:\t0.02203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45: \t44.npy\tLoss DICE:\t0.55297\tLoss MSE:\t0.03464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46: \t45.npy\tLoss DICE:\t0.50854\tLoss MSE:\t0.02983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47: \t46.npy\tLoss DICE:\t0.31312\tLoss MSE:\t0.02055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48: \t47.npy\tLoss DICE:\t0.53860\tLoss MSE:\t0.04269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49: \t48.npy\tLoss DICE:\t0.42796\tLoss MSE:\t0.02662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50: \t49.npy\tLoss DICE:\t0.51611\tLoss MSE:\t0.03639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51: \t50.npy\tLoss DICE:\t0.40107\tLoss MSE:\t0.02452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52: \t51.npy\tLoss DICE:\t0.37862\tLoss MSE:\t0.03711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53: \t52.npy\tLoss DICE:\t0.49972\tLoss MSE:\t0.04058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54: \t53.npy\tLoss DICE:\t0.44210\tLoss MSE:\t0.03262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55: \t54.npy\tLoss DICE:\t0.50054\tLoss MSE:\t0.03323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56: \t55.npy\tLoss DICE:\t0.43322\tLoss MSE:\t0.03024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57: \t56.npy\tLoss DICE:\t0.38116\tLoss MSE:\t0.02084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58: \t57.npy\tLoss DICE:\t0.54903\tLoss MSE:\t0.03079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59: \t58.npy\tLoss DICE:\t0.52512\tLoss MSE:\t0.03185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60: \t59.npy\tLoss DICE:\t0.34767\tLoss MSE:\t0.01777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61: \t60.npy\tLoss DICE:\t0.39607\tLoss MSE:\t0.03667\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'experiment_name': 'step_1',\n",
    "    'model_name': 'deep_medic',\n",
    "    'patch_size_normal': 25,\n",
    "    'patch_size_low': 19,\n",
    "    'patch_size_out': 9,\n",
    "    'patch_low_factor': 3,\n",
    "    'run_mode': None,\n",
    "    'dataset_variant': 'npy',  # npy, nib\n",
    "    'create_numpy_dataset': False,\n",
    "    'init_timestamp': datetime.now().strftime(\"%H-%M-%S__%d-%m-%Y\")\n",
    "}\n",
    "\n",
    "params_inference = {\n",
    "    'loss_name': 'dice',\n",
    "    'batch_size': 1,\n",
    "    'train_percentage': 0.8,\n",
    "    'num_workers': 0,  # 8\n",
    "    'pin_memory': False,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': False,\n",
    "\n",
    "    'resume_dir': 'step_4__09-03-12__06-04-2022__deep_medic__dice__adam__lr_0.0002__ep_100',\n",
    "    'resume_epoch': 'best',\n",
    "    'path_checkpoint': os.path.join('.', 'checkpoints'),\n",
    "    'path_checkpoint_full': '',\n",
    "    'dirname_checkpoint': '',\n",
    "}\n",
    "\n",
    "params_model['loss_name'] = 'dice_n_mse'\n",
    "\n",
    "# instanciate model\n",
    "set_seed(1)\n",
    "model_container = ModelConainer(params_model)\n",
    "\n",
    "# inference\n",
    "model_container.inference(params_inference=params_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af256a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization of the predictions\n",
    "\n",
    "At this stage we can visualize the predictions made by my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1aaef2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d90acee2de4cc3be2c397ce573ba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=133), IntSlider(value=-1, description='label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_vis = 0\n",
    "im_real = np.load(os.path.join('.', 'images_true', f'{index_vis}.npy'))\n",
    "label_real = np.load(os.path.join('.', 'labels_true', f'{index_vis}.npy'))\n",
    "label_pred = np.load(os.path.join('.', 'Ensamble', 'Abhijit', f'{index_vis}.npy')).squeeze(0)\n",
    "\n",
    "label_pred = torch.argmax(torch.softmax(torch.tensor(label_pred), axis=0), axis=0)\n",
    "\n",
    "height, width, depth = label_pred.shape\n",
    "\n",
    "def visualize_depth(index=0, label=-1):\n",
    "    # cmap = 'gray'\n",
    "    cmap = 'viridis'\n",
    "    # cmap = 'inferno'\n",
    "    # cmap = 'plasma'\n",
    "\n",
    "    index_depth = index;\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title('height x width')\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(im_real[:, :, index], cmap=cmap)\n",
    "    plt.title('Real Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if label == 0:\n",
    "        current_label = ' (Background)'\n",
    "    elif label == 1:\n",
    "        current_label = ' (Vessel)'\n",
    "    elif label == 2:\n",
    "        current_label = ' (Tumour)'\n",
    "    else:\n",
    "        current_label = ''\n",
    "\n",
    "    plt.title(f'Real Label{current_label}')\n",
    "    if label < 0:\n",
    "        plt.imshow(label_real[:, :, index], cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(np.where(label_real[:, :, index] == label, 1, 0), cmap=cmap)\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(f'Predicted Label{current_label}')\n",
    "    if label < 0:\n",
    "        plt.imshow(label_pred[:, :, index], cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(np.where(label_pred[:, :, index] == label, 1, 0), cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "interact(visualize_depth, index=widgets.IntSlider(min=0, max=depth-1, step=1, value=0), label=widgets.IntSlider(min=-1, max=2, step=1, value=-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee972242",
   "metadata": {},
   "source": [
    "### Analysis of the visualization\n",
    "\n",
    "The interactive plot above presents a 2D slice through the volume. Here, for the labels, the cyan colour represents the hepatic vessels and the yellow colour represents the tumours. We can see that although our model converged based on the criteria we defined, the localozation capability of our model is severly restricted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5d556",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Team Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4b73e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 6: Ensemble all the models by averaging their probalility. You can achieve this by either sharing the models themselves among the team, or by sharing the probabilistic outputs of the models. Comment on the algorithmic performance of the ensemble compared to your own method. [10]\n",
    "Answer Marks:\n",
    "[ 5] Implementation of the average ensemble\n",
    "[ 5] Describe the differences in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5eb01f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "Although I performed full-sized volume predictions on `61` images of the validation set, my teammates performed prediction on subset of 30 images and a subsection of the volume which was `512x512x16`. The size `16` in the depth dimension was extracted by taking a center crop in the depth dimension. As different people saved their probabilistic predicitons in different formats (numpy, tensor, gpu tensor) and used different naming conventions, I manually renamed all the files, converted to standard numpy format and saved them as `[0-29].npy` format. We only shared the probabilistic outputs from the models among ourselves.\n",
    "\n",
    "The non-weighted ensamble model `(DICE+MSE: 1.098875)` performed better than three of the five group members performance in terms of DICE+MSE loss, while my and Piyalitt's models performed better. The performance of the average ensamble `(1.098875)` is also much lower than the average of all our losses `(1.1304388)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923b0768",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert predictions to numpy\n",
    "def prepare_npy_files(path_ensamble):\n",
    "    '''\n",
    "        Assumes that probabilistic predictions are placed in the Ensambled directiory,\n",
    "        with the files renamed with indices between 0 and 30 (done manually)\n",
    "    '''\n",
    "    name_list = os.listdir(path_ensamble)\n",
    "    for name in name_list:\n",
    "        if name == 'Abhijit':\n",
    "            continue\n",
    "        for index in tqdm(range(30), leave=False):\n",
    "            file_path_input = os.path.join(path_ensamble, name, f'{index}.pkl')\n",
    "            with open(file_path_input, 'rb') as pickle_file:\n",
    "                try:\n",
    "                    content = pickle.load(pickle_file)\n",
    "                    if name == 'Diego':\n",
    "                        content = content.squeeze(0).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "                    elif name == 'Traudi-Beatrice':\n",
    "                        content = content.cpu().detach().numpy()\n",
    "                    elif name == 'Kate':\n",
    "                        content = content.squeeze(0).cpu().detach().numpy()\n",
    "                    np.save(os.path.join(path_ensamble, name, f'{index}.npy'), content)\n",
    "                except Exception as e:\n",
    "                    print(f'({name}) Exception at: {index}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2f1f776",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensamble_losses(class_weights=None, save_condition=False):\n",
    "    path_ensamble = os.path.join('.', 'Ensamble')\n",
    "    convert_to_numpy = False\n",
    "\n",
    "    if convert_to_numpy:\n",
    "        prepare_npy_files(path_ensamble)\n",
    "\n",
    "    # names of all the group members\n",
    "    names_list = os.listdir(path_ensamble)\n",
    "\n",
    "    num_inference = 29  # not 30 because the last file of Piyalitt can not be read, thows exception\n",
    "\n",
    "    # equally weight all the ensambles if no weight is supplied\n",
    "    if class_weights is None:\n",
    "        class_weights = np.ones(len(names_list)) / len(names_list)\n",
    "\n",
    "    print(f'class_weights:\\t{class_weights}')\n",
    "\n",
    "    # directory to store the average ensambles\n",
    "    path_avg_ensamble = os.path.join('.', 'Ensamble_avg')\n",
    "    os.makedirs(path_avg_ensamble, exist_ok=True)\n",
    "\n",
    "    # define the losses\n",
    "    criterion_dice = GeneralizedDiceLoss()\n",
    "    criterion_mse = nn.MSELoss()\n",
    "\n",
    "    # arrays to hold the different losses\n",
    "    num_people = len(names_list)\n",
    "    loss_array_dice = np.zeros((num_inference, num_people+1))\n",
    "    loss_array_mse = np.zeros((num_inference, num_people+1))\n",
    "    loss_array_dice_n_mse = np.zeros((num_inference, num_people+1))\n",
    "\n",
    "    for index_filename in range(num_inference):\n",
    "        # placeholder to hold the data of each person of the current index\n",
    "        labels_pred_list = []\n",
    "\n",
    "        path_labels_true = os.path.join('.', 'labels_true', f'{index_filename}.npy')\n",
    "        labels_true = np.load(path_labels_true)\n",
    "\n",
    "        # convert the real labels to one-hot labels\n",
    "        labels_true_oh = np.zeros((1, 3, labels_true.shape[0], labels_true.shape[1], labels_true.shape[2]))\n",
    "        labels_true_oh[0, 0, :] = np.where(labels_true==0, 1, 0)\n",
    "        labels_true_oh[0, 1, :] = np.where(labels_true==1, 1, 0)\n",
    "        labels_true_oh[0, 2, :] = np.where(labels_true==2, 1, 0)\n",
    "\n",
    "        # getting the center crop of size 16 in the depth dimension to match with other's predictions\n",
    "        depth = labels_true_oh.shape[-1]\n",
    "        depth_center = (depth // 2)\n",
    "        depth_new = 16\n",
    "        depth_new_half = depth_new // 2\n",
    "\n",
    "        labels_true_oh = labels_true_oh[:, :, :, :, depth_center-depth_new_half:depth_center+depth_new_half]\n",
    "        labels_true_oh = torch.tensor(labels_true_oh, dtype=torch.float32).squeeze(0)\n",
    "\n",
    "        # read the current index file of each person and append to the list\n",
    "        for index_name, name in enumerate(names_list):\n",
    "            path_labels_pred = os.path.join(path_ensamble, name, f'{index_filename}.npy')\n",
    "\n",
    "            labels_pred_proba = np.load(path_labels_pred)\n",
    "\n",
    "            # getting the center crop of size 16 in the depth dimension to match with other's predictions\n",
    "            if name=='Abhijit':\n",
    "                labels_pred_proba = labels_pred_proba[:, :, :, :, depth_center-depth_new_half:depth_center+depth_new_half].squeeze(0)\n",
    "\n",
    "            labels_pred_proba = torch.softmax(torch.tensor(labels_pred_proba * class_weights[index_name]), dim=0).detach().cpu().numpy()\n",
    "            labels_pred_list.append(labels_pred_proba)\n",
    "\n",
    "            # convert to torch tensors for loss calculation\n",
    "            labels_pred_proba = torch.tensor(labels_pred_proba, dtype=torch.float32)\n",
    "\n",
    "            loss_dice = criterion_dice(labels_pred_proba, labels_true_oh).item()\n",
    "            loss_mse = criterion_mse(labels_pred_proba, labels_true_oh).item()\n",
    "            loss_dice_n_mse = loss_dice + loss_mse\n",
    "\n",
    "            loss_array_dice[index_filename, index_name] = loss_dice\n",
    "            loss_array_mse[index_filename, index_name] = loss_mse\n",
    "            loss_array_dice_n_mse[index_filename, index_name] = loss_dice_n_mse\n",
    "\n",
    "            # print(f'{name}\\t\\t\\tDICE:\\t{loss_dice:.5f}\\t\\tMSE:\\t{loss_mse:.5f}\\t\\tDICE+MSE:\\t{loss_dice_n_mse:.5f}')\n",
    "\n",
    "        # convert to array and calculate the mean\n",
    "        labels_pred_list = np.array(labels_pred_list)\n",
    "        labels_pred_mean = np.mean(labels_pred_list, axis=0)\n",
    "\n",
    "        # loss of the Ensamble\n",
    "        # convert to torch tensors for loss calculation\n",
    "        labels_pred_mean = torch.tensor(labels_pred_mean, dtype=torch.float32)\n",
    "\n",
    "        loss_dice = criterion_dice(labels_pred_mean, labels_true_oh).item()\n",
    "        loss_mse = criterion_mse(labels_pred_mean, labels_true_oh).item()\n",
    "        loss_dice_n_mse = loss_dice + loss_mse\n",
    "\n",
    "        loss_array_dice[index_filename, index_name+1] = loss_dice\n",
    "        loss_array_mse[index_filename, index_name+1] = loss_mse\n",
    "        loss_array_dice_n_mse[index_filename, index_name+1] = loss_dice_n_mse\n",
    "\n",
    "        # name = 'Ensamble'\n",
    "        # print(f'{name}\\t\\t\\tDICE:\\t{loss_dice:.5f}\\t\\tMSE:\\t{loss_mse:.5f}\\t\\tDICE+MSE:\\t{loss_dice_n_mse:.5f}')\n",
    "\n",
    "        # save the average of the ensamble\n",
    "        if save_condition:\n",
    "            path_out_current = os.path.join(path_avg_ensamble, f'{index_filename}.npy')\n",
    "            np.save(path_out_current, labels_pred_mean)\n",
    "\n",
    "    names_list_df = os.listdir(path_ensamble)\n",
    "    names_list_df.append('Ensamble')\n",
    "\n",
    "    # create dataframes of losses for easy interpretability\n",
    "    df_dice = pd.DataFrame(loss_array_dice, columns=names_list_df)\n",
    "    df_mse = pd.DataFrame(loss_array_mse, columns=names_list_df)\n",
    "    df_dice_n_mse = pd.DataFrame(loss_array_dice_n_mse, columns=names_list_df)\n",
    "\n",
    "    return df_dice, df_mse, df_dice_n_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59bad57e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights:\t[0.2 0.2 0.2 0.2 0.2]\n",
      "Mean of all the losses with uniform weighting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abhijit</th>\n",
       "      <th>Diego</th>\n",
       "      <th>Kate</th>\n",
       "      <th>Piyalitt</th>\n",
       "      <th>Traudi-Beatrice</th>\n",
       "      <th>Ensamble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>0.996092</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.995885</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.998366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.034254</td>\n",
       "      <td>0.193745</td>\n",
       "      <td>0.202906</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.194976</td>\n",
       "      <td>0.100509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE+MSE</th>\n",
       "      <td>1.030346</td>\n",
       "      <td>1.192475</td>\n",
       "      <td>1.201715</td>\n",
       "      <td>1.033799</td>\n",
       "      <td>1.193859</td>\n",
       "      <td>1.098875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Abhijit     Diego      Kate  Piyalitt  Traudi-Beatrice  Ensamble\n",
       "Dice      0.996092  0.998731  0.998809  0.995885         0.998883  0.998366\n",
       "MSE       0.034254  0.193745  0.202906  0.037914         0.194976  0.100509\n",
       "DICE+MSE  1.030346  1.192475  1.201715  1.033799         1.193859  1.098875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dice, df_mse, df_dice_n_mse = get_ensamble_losses()\n",
    "names_list_df = list(df_dice.columns)\n",
    "loss_names = ['Dice', 'MSE', 'DICE+MSE']\n",
    "\n",
    "df_mean_losses = pd.DataFrame(np.vstack((df_dice.mean().to_numpy(),\n",
    "                                      df_mse.mean().to_numpy(),\n",
    "                                      df_dice_n_mse.mean().to_numpy())))\n",
    "\n",
    "df_mean_losses.columns = names_list_df\n",
    "df_mean_losses.index = loss_names\n",
    "\n",
    "print(f'Mean of all the losses with uniform weighting')\n",
    "display(df_mean_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44131b49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# STEP 7: Sometimes, one or several of the methods used to ensemble can be underperforming, so a simple avegare might be non-ideal. Instead, you can chose to weight the different models. Do this either by manually chosing the weights between different models or by using the performance on the training set to define these. Does a weighted ensemble perform better? Describe why. [10]\n",
    "Answer Marks:\n",
    "(If followed the performance-based route)\n",
    "[ 7] Implementation of the performance-based weighted ensemble\n",
    "[ 3] Describe the differences in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398bc98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "I weighted our models based on the respective performances in the previous step, which is proportional to to `1-LOSS`. I used all three variants of losses (`DICE`, `MSE`, `DICE+MSE`) available at this stage and compared their performance against one another. Then I applied a `softmax` function on them to represent probabilities. As Piyalitt's model had the best (lowest) loss in the previous step, it was given the highest weight. These weights were them multiplied with the raw probabilities to obtain the final performance.\n",
    "\n",
    "From the table below it can be observed that regardless which loss we use to weight our models, the performance improves. But the highest gain (`0.2%`) is achieved when we use the `DICE+MSE` loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef665e75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three different sets of weights are displayed, based on each type of loss on the previous step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abhijit</th>\n",
       "      <th>Diego</th>\n",
       "      <th>Kate</th>\n",
       "      <th>Piyalitt</th>\n",
       "      <th>Traudi-Beatrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>0.200318</td>\n",
       "      <td>0.199790</td>\n",
       "      <td>0.199774</td>\n",
       "      <td>0.200359</td>\n",
       "      <td>0.199759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.220010</td>\n",
       "      <td>0.187575</td>\n",
       "      <td>0.185865</td>\n",
       "      <td>0.219206</td>\n",
       "      <td>0.187344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE+MSE</th>\n",
       "      <td>0.220335</td>\n",
       "      <td>0.187357</td>\n",
       "      <td>0.185634</td>\n",
       "      <td>0.219575</td>\n",
       "      <td>0.187098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Abhijit     Diego      Kate  Piyalitt  Traudi-Beatrice\n",
       "Dice      0.200318  0.199790  0.199774  0.200359         0.199759\n",
       "MSE       0.220010  0.187575  0.185865  0.219206         0.187344\n",
       "DICE+MSE  0.220335  0.187357  0.185634  0.219575         0.187098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_weights_dice = torch.softmax(torch.tensor(1-df_dice.mean()[:5]).unsqueeze(0), dim=1).detach().numpy()[0]\n",
    "name_weights_mse = torch.softmax(torch.tensor(1-df_mse.mean()[:5]).unsqueeze(0), dim=1).detach().numpy()[0]\n",
    "name_weights_dice_n_mse = torch.softmax(torch.tensor(1-df_dice_n_mse.mean()[:5]).unsqueeze(0), dim=1).detach().numpy()[0]\n",
    "\n",
    "df_weights = pd.DataFrame(np.vstack((name_weights_dice, name_weights_mse, name_weights_dice_n_mse)))\n",
    "df_weights.columns = names_list_df[:5]\n",
    "df_weights.index = loss_names\n",
    "\n",
    "print(f'Three different sets of weights are displayed, based on each type of loss on the previous step')\n",
    "display(df_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81eed050",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Current weighting selected based on:\tDice\n",
      "class_weights:\t[0.20031758 0.1997898  0.19977408 0.20035917 0.19975936]\n",
      "Mean of Different Losses after applying class weights to different models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abhijit</th>\n",
       "      <th>Diego</th>\n",
       "      <th>Kate</th>\n",
       "      <th>Piyalitt</th>\n",
       "      <th>Traudi-Beatrice</th>\n",
       "      <th>Ensamble</th>\n",
       "      <th>Ensamble_old</th>\n",
       "      <th>Ensamble_difference %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>0.996091</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.995874</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.998366</td>\n",
       "      <td>0.998366</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.034252</td>\n",
       "      <td>0.193775</td>\n",
       "      <td>0.202927</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.195009</td>\n",
       "      <td>0.100465</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>0.043896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE+MSE</th>\n",
       "      <td>1.030343</td>\n",
       "      <td>1.192505</td>\n",
       "      <td>1.201737</td>\n",
       "      <td>1.033649</td>\n",
       "      <td>1.193892</td>\n",
       "      <td>1.098830</td>\n",
       "      <td>1.098875</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Abhijit     Diego      Kate  Piyalitt  Traudi-Beatrice  Ensamble  \\\n",
       "Dice      0.996091  0.998731  0.998809  0.995874         0.998883  0.998366   \n",
       "MSE       0.034252  0.193775  0.202927  0.037775         0.195009  0.100465   \n",
       "DICE+MSE  1.030343  1.192505  1.201737  1.033649         1.193892  1.098830   \n",
       "\n",
       "          Ensamble_old  Ensamble_difference %  \n",
       "Dice          0.998366               0.000041  \n",
       "MSE           0.100509               0.043896  \n",
       "DICE+MSE      1.098875               0.004052  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Current weighting selected based on:\tMSE\n",
      "class_weights:\t[0.22000962 0.18757531 0.18586478 0.21920581 0.18734448]\n",
      "Mean of Different Losses after applying class weights to different models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abhijit</th>\n",
       "      <th>Diego</th>\n",
       "      <th>Kate</th>\n",
       "      <th>Piyalitt</th>\n",
       "      <th>Traudi-Beatrice</th>\n",
       "      <th>Ensamble</th>\n",
       "      <th>Ensamble_old</th>\n",
       "      <th>Ensamble_difference %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>0.996015</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.998815</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.998347</td>\n",
       "      <td>0.998366</td>\n",
       "      <td>0.001958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.204253</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.196682</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>2.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE+MSE</th>\n",
       "      <td>1.030216</td>\n",
       "      <td>1.194240</td>\n",
       "      <td>1.203068</td>\n",
       "      <td>1.026421</td>\n",
       "      <td>1.195565</td>\n",
       "      <td>1.096656</td>\n",
       "      <td>1.098875</td>\n",
       "      <td>0.201896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Abhijit     Diego      Kate  Piyalitt  Traudi-Beatrice  Ensamble  \\\n",
       "Dice      0.996015  0.998741  0.998815  0.995293         0.998883  0.998347   \n",
       "MSE       0.034201  0.195499  0.204253  0.031127         0.196682  0.098310   \n",
       "DICE+MSE  1.030216  1.194240  1.203068  1.026421         1.195565  1.096656   \n",
       "\n",
       "          Ensamble_old  Ensamble_difference %  \n",
       "Dice          0.998366               0.001958  \n",
       "MSE           0.100509               2.187900  \n",
       "DICE+MSE      1.098875               0.201896  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Current weighting selected based on:\tDICE+MSE\n",
      "class_weights:\t[0.22033462 0.18735747 0.18563431 0.2195752  0.18709839]\n",
      "Mean of Different Losses after applying class weights to different models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abhijit</th>\n",
       "      <th>Diego</th>\n",
       "      <th>Kate</th>\n",
       "      <th>Piyalitt</th>\n",
       "      <th>Traudi-Beatrice</th>\n",
       "      <th>Ensamble</th>\n",
       "      <th>Ensamble_old</th>\n",
       "      <th>Ensamble_difference %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>0.996014</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.998815</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.998366</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.195530</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>2.226377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE+MSE</th>\n",
       "      <td>1.030214</td>\n",
       "      <td>1.194271</td>\n",
       "      <td>1.203090</td>\n",
       "      <td>1.026291</td>\n",
       "      <td>1.195598</td>\n",
       "      <td>1.096617</td>\n",
       "      <td>1.098875</td>\n",
       "      <td>0.205448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Abhijit     Diego      Kate  Piyalitt  Traudi-Beatrice  Ensamble  \\\n",
       "Dice      0.996014  0.998741  0.998815  0.995281         0.998883  0.998346   \n",
       "MSE       0.034201  0.195530  0.204275  0.031009         0.196715  0.098271   \n",
       "DICE+MSE  1.030214  1.194271  1.203090  1.026291         1.195598  1.096617   \n",
       "\n",
       "          Ensamble_old  Ensamble_difference %  \n",
       "Dice          0.998366               0.001995  \n",
       "MSE           0.100509               2.226377  \n",
       "DICE+MSE      1.098875               0.205448  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, name_weights in enumerate([name_weights_dice, name_weights_mse, name_weights_dice_n_mse]):\n",
    "    print(f'{\"*\"*100}')\n",
    "    print(f'Current weighting selected based on:\\t{loss_names[index]}')\n",
    "    df_dice_w, df_mse_w, df_dice_n_mse_w = get_ensamble_losses(class_weights=name_weights)\n",
    "    names_list_df = list(df_dice_w.columns)\n",
    "\n",
    "    print(f'Mean of Different Losses after applying class weights to different models')\n",
    "\n",
    "    df_mean_losses_w = pd.DataFrame(np.vstack((df_dice_w.mean().to_numpy(),\n",
    "                                      df_mse_w.mean().to_numpy(),\n",
    "                                      df_dice_n_mse_w.mean().to_numpy())))\n",
    "    df_mean_losses_w.columns = df_dice_w.columns\n",
    "    df_mean_losses_w.index = loss_names\n",
    "\n",
    "    df_mean_losses_w['Ensamble_old'] = df_mean_losses['Ensamble']\n",
    "    df_mean_losses_w['Ensamble_difference %'] = ((df_mean_losses['Ensamble'] - df_mean_losses_w['Ensamble']) / df_mean_losses['Ensamble']) * 100\n",
    "\n",
    "    display(df_mean_losses_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ee39e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}